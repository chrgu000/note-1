<!DOCTYPE html>
<html lang="zh-cn">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>零零碎碎</title>
<meta name="description" content=" John Doe&#39;s Personal blog about everything">
<meta name="generator" content="Hugo 0.17" />
<meta property="og:title" content="零零碎碎" />
<meta property="og:description" content=" John Doe&#39;s Personal blog about everything" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/" />













<link rel="stylesheet" href="/css/google-font.css?family=Open+Sans:400,400italic,700,600" type="text/css" media="all" />

<link rel="stylesheet" href="/css/railscasts.css">
<link rel="stylesheet" href="/css/style.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/custom.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/jquery.bigautocomplete.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/asciinema-player.css" type="text/css" media="all" />
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/fonts/fontawesome-webfont.svg" rel="stylesheet">

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript" src="/js/scripts.js"></script>
<!--[if lt IE 9]>
	<script src="/js/css3-mediaqueries.js"></script>
<![endif]-->

</head>
<body id="mr-mobile" class="home blog mr-right-sb" itemscope="itemscope" itemtype="http://schema.org/WebPage">
	<div class="mr-container mr-container-outer">
		<div class="mr-header-mobile-nav clearfix"></div>
			<header class="mr-header" itemscope="itemscope" itemtype="http://schema.org/WPHeader">
				<div class="mr-container mr-container-inner mr-row clearfix">
					<div class="mr-custom-header clearfix">
						<div class="mr-site-identity">
							<div class="mr-site-logo" role="banner" itemscope="itemscope" itemtype="http://schema.org/Brand">
								<div class="mr-header-text">
									<a class="mr-header-text-link" href="/" title="零零碎碎" rel="home">
										<h1 class="mr-header-title">零零碎碎</h1>
										<h2 class="mr-header-tagline">点滴记录</h2>
									</a>
								</div>
							</div>
						</div>
					</div>
				</div>
				<div class="mr-main-nav-wrap">
					<nav class="menu" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
	<ul class="menu__list">
        
            <li class="menu__item"><a class="menu__link" href="/categories/docker">docker</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/hadoop">hadoop</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/scala">scala</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/spark">spark</a></li>
        
	</ul>
</nav>
				</div>
			</header>
		<div class="mr-wrapper clearfix">


	<div id="main-content" class="mr-loop mr-content" role="main">
		
		
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/djt/%E4%BD%9C%E4%B8%9A/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA3%E8%8A%82%E7%82%B9%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						Contents1. 对主机、用户、目录、软件的规划1.1. 主机规划1.2. 软件规划1.3. 用户规划1.4. 目录规划2. 集群安装前的环境检查，比如时钟同步、hosts文件检查、禁用防火墙等3. Ansible 批量搭建hadoop环境4. 运行 Hadoop 环境5. 运行 wordcount1. 对主机、用户、目录、软件的规划1.1. 主机规划djt11/192.168.137.21djt12/192.168.137.22djt13/192.168.137.23namenode
是
是
否
datanode
是
是
是
resourcemanager
是
是
否
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/djt/%E9%A1%B9%E7%9B%AE/%E9%9D%A2%E8%AF%95/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						数据结构：所有种类的数据都是记录在同一个文件中，比如pv、play等数据。每个种类的数据的数据格式都是不一样的，需要通过url区分每个种类的数据参数顺序不一样，需要我们对每个种类的数据定义元数据，数据拆分需要此元数据
数据采集规范：日志数据记录在多台日志服务器上，每个小时会生成一个文件，文件命名为2017052412.log文件会放到固定的目录，以便flume采集采集数据的时候需要添加文件名头信息，根据文件头解析出天和小时，并设置天和小时的头，在写hdfs时需要用到这些头信息。
YARN分布式缓存工作流程具体如下:步骤1客户端将应用程序所需的文件资源(外部字典、JAR包、二进制文件等)提交到HDFS上。步骤2客户端将应用程序提交到ResourceManager上。步骤3 ResourceManager与某个NodeManager通信，启动应用程序ApplicationMaster,NodeManager收到命令后，首先从HDFS下载文件(缓存)，然后启动ApplicationMaster步骤4 ApplicationMaster与ResourceManager通信，以请求和获取计算资源。步骤5 ApplicationMaster收到新分配的计算资源后，与对应的NodeManager通信，以启动任务。步骤6如果该应用程序第一次在该节点上启动任务，则NodeManager首先从HDFS上下载文件缓存到本地，然后启动任务。步骤7 NodeManager后续收到启动任务请求后，如果文件以在本地缓存，则直接运行任务，否则等待文件缓存完成后再启动。各节点上的缓存文件由对应的NodeManager管理和维护。考虑到磁盘空间的有限性，NodeManager采用了一定的缓存置换算法定期清理失效文件。
1、有哪些数据（见excel表格）、总体流程
pv页面点击
flum 24台日志机器，24个日志采集agent, 5台聚合agent高可用的拓扑结构
2、采集的细节3、mapreduce、hdfs、资源管理器
block 64M 2个10M的文件上传后会有几个block 2个文件上传流程、高可用
应用程序设计流程、分布式缓存资源管理器种类、队列资源抢占
4、hive sql
5.数据量
每条是0.39K 1*60*24*5000
hadoop 75节点 8核 32G 4T500G+ 20几种日志清洗计算(1小时之内) 500G * 1024 / 64M = 8000 map8000 / 75 = 107 map / 台107 / 16 = 7 并行map64M / 0.
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/hadoop/yarn/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						ResourceManagerResourceTrackerNodeManager 通过RPC协议向 ResourceManager 注册,汇报节点健康状况和 Container运行状态,并领取ResourceManager下达的命令,这些命令包括重新初始化,清理Container 等,在该 RPC 协议中, ResourceManager扮演RPC Server的角色(由内部组件ResourceTrackerService实现),而NodeManager扮演RPC Client的角色,换句话说,NodeManager与ResourceManager之间采用了"pull模型", NodeManager 总是周期性地主动向 ResourceManager 发起请求,并通过领取下达给自己的命令ApplicationMasterProtocol应用程序的 ApplicationMaster 通过该 RPC 协议向 ResourceManager 注册,申请资源和释放资源.在该协议中, ApplicationMaster 扮演 RPC Client的角色,而 ResourceManager 扮演 RPC Server 的角色,换句话说, ResourceManager 与 ApplicationMaster 之间也采用了 "pull 模型"ApplicationClientProtocol应用程序的客户端通过该RPC协议向 ResourceManager 提交应用程序,查询应用程序状态和控制应用程序
yarn 命令application 列表yarn application -listapplicationattempt 列表yarn applicationattempt -list &lt;Application-Id&gt;container 列表yarn container -list &lt;ApplicationAttempt-Id&gt;yarn logs -applicationId application_1531923430869_511705
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/01/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						RDDAction操作(1)–first、count、reduce、collect 算子 算子是一个函数空间到函数空间上的映射O: X -&gt; X。
广义上的算子可以推广到任何空间，如内积空间等。
first def first(): T
first返回RDD中的第一个元素，不排序
scala&gt; var rdd1 = sc.makeRDD(Array((&quot;a&quot;,1),(&quot;b&quot;,2),(&quot;c&quot;,3),4)) rdd1: org.apache.spark.rdd.RDD[Any] = ParallelCollectionRDD[0] at makeRDD at &lt;console&gt;:27 scala&gt; rdd1.first res0: Any = (a,1) var rdd1 = sc.makeRDD(Seq(10, 4, 2, 12, 3)) rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[1] at makeRDD at &lt;console&gt;:27 scala&gt; rdd1.first res1: Int = 10  count def count(): Long
count返回RDD中元素数量
scala&gt; var rdd1 = sc.makeRDD(Array((&quot;A&quot;,&quot;1&quot;),(&quot;B&quot;,&quot;2&quot;),(&quot;C&quot;,&quot;3&quot;)),2) rdd1: org.apache.spark.rdd.RDD[(String, String)] = ParallelCollectionRDD[34] at makeRDD at :21 scala&gt; rdd1.
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/02/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						take、top、takeOrdered take def take(num: Int): Array[T]
take用于获取RDD中从0到num-1下标的元素，不排序
scala&gt; var rdd1 = sc.makeRDD(Seq(10, 4, 2, 12, 3)) rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[40] at makeRDD at :21 scala&gt; rdd1.take(1) res0: Array[Int] = Array(10) scala&gt; rdd1.take(2) res1: Array[Int] = Array(10, 4)  top def top(num: Int)(implicit ord: Ordering[T]):Array[T]
top函数用于从RDD中，按照默认（降序）或者指定的排序规则，返回前num个元素
scala&gt; var rdd1 = sc.makeRDD(Seq(10, 4, 2, 12, 3)) rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[40] at makeRDD at :21 scala&gt; rdd1.top(1) res2: Array[Int] = Array(12) scala&gt; rdd1.
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/03/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						aggregate、fold、lookup aggregate def aggregateU(seqOp:(U,T)) =&gt; U,combOp:(U,U) =&gt; U)(implicit arg0: ClassTag[U]):U
aggregate用户聚合RDD中的元素，先使用seqOp将RDD中每个分区中的T类型元素聚合成U类型，再使用combOp将之前每个分区聚合后的U类型聚合成U类型，特别注意seqOp和comOp都会使用zeroValue的值，zeroValue的类型为U。
var rdd1 = sc.makeRDD(1 to 10,2) rdd1.mapPartitionsWithIndex{ (partIdx,iter) =&gt; { var part_map = scala.collection.mutable.Map[String,List[Int]]() while(iter.hasNext){ var part_name = &quot;part_&quot; + partIdx; var elem = iter.next() if(part_map.contains(part_name)) { var elems = part_map(part_name) elems ::= elem part_map(part_name) = elems } else { part_map(part_name) = List[Int]{elem} } } part_map.iterator } }.collect res16: Array[(String, List[Int])] = Array((part_0,List(5, 4, 3, 2, 1)), (part_1,List(10, 9, 8, 7, 6)))  第一个分区中包含5,4,3,2,1 第二个分区中包含10,9,8,7,6
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/04/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						countByKey、foreach、foreachPartition、sortBy countByKey def countByKey(): Map[K, Long]
countByKey用于统计RDD[K,V]中每个K的数量。
scala&gt; var rdd1 = sc.makeRDD(Array((&quot;A&quot;,0),(&quot;A&quot;,2),(&quot;B&quot;,1),(&quot;B&quot;,2),(&quot;B&quot;,3))) rdd1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[7] at makeRDD at :21 scala&gt; rdd1.countByKey res5: scala.collection.Map[String,Long] = Map(A -&gt; 2, B -&gt; 3)  foreach def foreach(f: (T) ⇒ Unit): Unit
foreach用于遍历RDD,将函数f应用于每一个元素。
但要注意，如果对RDD执行foreach，只会在Executor端有效，而并不是Driver端。
在Spark1.4中是这样，不知道是否真如此。
这时候，使用accumulator共享变量与foreach结合，倒是个不错的选择。
scala&gt; var cnt = sc.accumulator(0) cnt: org.apache.spark.Accumulator[Int] = 0 scala&gt; var rdd1 = sc.makeRDD(1 to 10,2) rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[5] at makeRDD at :21 scala&gt; rdd1.
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/05/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						 saveAsSequenceFile、saveAsObjectFile saveAsTextFile def saveAsTextFile(path: String): Unit
def saveAsTextFile(path: String, codec: Class[_ &lt;: CompressionCodec]): Unit
saveAsTextFile用于将RDD以文本文件的格式存储到文件系统中。
codec参数可以指定压缩的类名。
var rdd1 = sc.makeRDD(1 to 10,2) scala&gt; rdd1.saveAsTextFile(&quot;hdfs:///user/apple/testspark&quot;) //保存到HDFS scala&gt; rdd1.saveAsTextFile(&quot;file:///Users/apple/testspark&quot;) //保存到本地 //由于设置为两个分区，因此保存的路径中，有part-00000,part-00000  指定压缩格式保存
//需要将使用的压缩工具包导入 rdd1.saveAsTextFile(&quot;hdfs:///user/apple/testspark1&quot;,classOf[com.hadoop.compression.lzo.LzopCodec])  saveAsSequenceFile saveAsSequenceFile用于将RDD以SequenceFile的文件格式保存到HDFS上。
用法同saveAsTextFile。
spark 1.6.1 没有改方法
saveAsObjectFile def saveAsObjectFile(path: String): Unit
saveAsObjectFile用于将RDD中的元素序列化成对象，存储到文件中。
对于HDFS，默认采用SequenceFile保存。
rdd1.saveAsObjectFile(&quot;/user/apple/sparktest02&quot;) hadoop fs -cat /user/apple/sparktest02/part-00000 SEQ !org.apache.hadoop.io.NullWritable&quot;org.apache.hadoop.io.BytesWritableT  
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/06/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						saveAsHadoopFile、saveAsHadoopDataset saveAsHadoopFile def saveAsHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[_, ]], codec: Class[ &lt;: CompressionCodec]): Unit
def saveAsHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[_, ]], conf: JobConf = …, codec: Option[Class[ &lt;: CompressionCodec]] = None): Unit
saveAsHadoopFile是讲RDD存储在HDFS上的文件中，支持老版本Hadoop API。
每个分区输出一个文件。
var rdd1 = sc.makeRDD(Array((&quot;A&quot;,2),(&quot;A&quot;,1),(&quot;B&quot;,6),(&quot;B&quot;,3),(&quot;B&quot;,7))) import org.apache.hadoop.mapred.TextOutputFormat import org.apache.hadoop.io.Text import org.apache.hadoop.io.IntWritable rdd1.saveAsHadoopFile(&quot;/tmp/lxw1234.com/&quot;,classOf[Text],classOf[IntWritable],classOf[TextOutputFormat[Text,IntWritable]]) rdd1.saveAsHadoopFile(&quot;/tmp/lxw1234.com/&quot;,classOf[Text],classOf[IntWritable],classOf[TextOutputFormat[Text,IntWritable]], classOf[com.hadoop.compression.lzo.LzopCodec])  saveAsHadoopDataset def saveAsHadoopDataset(conf: JobConf): Unit
saveAsHadoopDataset用于将RDD保存到除了HDFS的其他存储中，比如HBase。
在JobConf中，通常需要关注或者设置五个参数：
 文件的保存路劲 key值的class类型 value值的class类型 RDD的输出格式（OutputFormat） 压缩的相关参数  使用saveAsHadoopDataset将RDD保存到HDFS中
					</div>
				</div>
			</div>
		</article>
		
		<article class="mr-loop-item post type-post hentry clearfix">
			
			<div class="mr-loop-content clearfix">
				<header class="mr-loop-header">
					<h3 class="entry-title mr-loop-title">
						<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/07/" rel="bookmark"></a>
					</h3>
					<div class="mr-meta mr-loop-meta">
						<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
						<time class="mr-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
					</div>
				</header>
				<div class="mr-loop-excerpt">
					<div class="mr-excerpt">
						saveAsNewAPIHadoopFile、saveAsNewAPIHadoopDataset saveAsNewAPIHadoopFile def saveAsNewAPIHadoopFileF &lt;: OutputFormat[K, V](implicit fm: ClassTag[F]): Unit
def saveAsNewAPIHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[_, _]], conf: Configuration = self.context.hadoopConfiguration): Unit
saveAsNewAPIHadoopFile用于将RDD数据保存到HDFS上，使用新版本Hadoop API。 用法基本同saveAsHadoopFile。
import org.apache.spark.SparkConf import org.apache.spark.SparkContext import SparkContext._ import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat import org.apache.hadoop.io.Text import org.apache.hadoop.io.IntWritable var rdd1 = sc.makeRDD(Array((&quot;A&quot;,2),(&quot;A&quot;,1),(&quot;B&quot;,6),(&quot;B&quot;,3),(&quot;B&quot;,7))) rdd1.saveAsNewAPIHadoopFile(&quot;/tmp/lxw1234/&quot;,classOf[Text],classOf[IntWritable],classOf[TextOutputFormat[Text,IntWritable]])  saveAsNewAPIHadoopDataset def saveAsNewAPIHadoopDataset(conf: Configuration): Unit
作用同saveAsHadoopDataset,只不过采用新版本Hadoop API。
以写入HBase为例：
HBase建表：
create ‘lxw1234′,{NAME =&gt; ‘f1′,VERSIONS =&gt; 1},{NAME =&gt; ‘f2′,VERSIONS =&gt; 1},{NAME =&gt; ‘f3′,VERSIONS =&gt; 1}
					</div>
				</div>
			</div>
		</article>
		

		
<div class="mr-loop-pagination clearfix">
	
	<a class="page-numbers" href="/page/23/">«</a>
	
	<span class="page-numbers current">24/31</span>
	
	<a class="page-numbers" href="/page/25/">»</a>
	
</div>

	</div>

<aside class="mr-sidebar" itemscope="itemscope" itemtype="http://schema.org/WPSideBar">
	
<div class="mr-widget widget_search navbar-wrapper" >
	<div class="search-form" role="search" >
		<label>
			<span class="screen-reader-text">Search for:</span>
			<input id="lanren" type="text" class="search-field" placeholder="Search..." autocomplete="off" value="" />
		</label>
		
        <div id="list-container" class="bdsug" style="height: auto; display: block;">
        </div>
	</div>
</div>

	
	


<div class="mr-widget widget_categories">
	<h4 class="mr-widget-title"><span class="mr-widget-title-inner">Categories</span></h4>
	<ul>
		
		<li class="cat-item"><a href="/categories/algorithm">Algorithm</a></li>
		
		<li class="cat-item"><a href="/categories/bug">Bug</a></li>
		
		<li class="cat-item"><a href="/categories/djt">Djt</a></li>
		
		<li class="cat-item"><a href="/categories/docker">Docker</a></li>
		
		<li class="cat-item"><a href="/categories/dw">Dw</a></li>
		
		<li class="cat-item"><a href="/categories/go">Go</a></li>
		
		<li class="cat-item"><a href="/categories/hadoop">Hadoop</a></li>
		
		<li class="cat-item"><a href="/categories/java">Java</a></li>
		
		<li class="cat-item"><a href="/categories/js">Js</a></li>
		
		<li class="cat-item"><a href="/categories/jvm">Jvm</a></li>
		
		<li class="cat-item"><a href="/categories/linux">Linux</a></li>
		
		<li class="cat-item"><a href="/categories/mailiqng-app">Mailiqng-App</a></li>
		
		<li class="cat-item"><a href="/categories/mysql">Mysql</a></li>
		
		<li class="cat-item"><a href="/categories/scala">Scala</a></li>
		
		<li class="cat-item"><a href="/categories/spark">Spark</a></li>
		
		<li class="cat-item"><a href="/categories/storm">Storm</a></li>
		
		<li class="cat-item"><a href="/categories/virtualbox">Virtualbox</a></li>
		
		<li class="cat-item"><a href="/categories/work">Work</a></li>
		
		<li class="cat-item"><a href="/categories/zookeeper">Zookeeper</a></li>
		
		<li class="cat-item"><a href="/categories/%e7%ae%97%e6%b3%95">算法</a></li>
		
		<li class="cat-item"><a href="/categories/%e9%ab%98%e6%95%b0">高数</a></li>
		
	</ul>
</div>



    


<div class="mr-widget widget_tag_cloud">
	<h4 class="mr-widget-title"><span class="mr-widget-title-inner">Tags</span></h4>
	<div class="tagcloud">
		
			<a href="/tags/docker" class="tag-link" title="docker" style="font-size: 12px;">docker</a>
		
			<a href="/tags/elasticsearch" class="tag-link" title="elasticsearch" style="font-size: 12px;">elasticsearch</a>
		
			<a href="/tags/git" class="tag-link" title="git" style="font-size: 12px;">git</a>
		
			<a href="/tags/hugo" class="tag-link" title="hugo" style="font-size: 12px;">hugo</a>
		
			<a href="/tags/latex" class="tag-link" title="latex" style="font-size: 12px;">latex</a>
		
			<a href="/tags/neo4j" class="tag-link" title="neo4j" style="font-size: 12px;">neo4j</a>
		
			<a href="/tags/sublime" class="tag-link" title="sublime" style="font-size: 12px;">sublime</a>
		
			<a href="/tags/vagrant" class="tag-link" title="vagrant" style="font-size: 12px;">vagrant</a>
		
			<a href="/tags/windows" class="tag-link" title="windows" style="font-size: 12px;">windows</a>
		
			<a href="/tags/wuliu" class="tag-link" title="wuliu" style="font-size: 12px;">wuliu</a>
		
			<a href="/tags/%e6%ba%90%e7%a0%81%e5%88%86%e6%9e%90" class="tag-link" title="源码分析" style="font-size: 12px;">源码分析</a>
		
			<a href="/tags/%e8%bf%9b%e7%a8%8b%e7%ae%a1%e7%90%86" class="tag-link" title="进程管理" style="font-size: 12px;">进程管理</a>
		
	</div>
</div>



</aside>
	</div>
		<div class="mr-copyright-wrap">
			<div class="mr-container mr-container-inner clearfix">
				<p class="mr-copyright">&copy; 2018 零零碎碎. <a href="https://git.oschina.net/dishui/dishui" target="_blank" rel="nofollow noopener noreferrer">dishui</a>.</p>
			</div>
		</div>
	</div>

<script>
	var navigation = responsiveNav(".menu", {
		navClass: "menu--collapse",
	});
</script>
<script src="/js/asciinema-player.js"></script>
<script data-main="/js/app.js" src="/js/require.js"></script>


</body>
</html>
