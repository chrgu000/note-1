<!DOCTYPE html>
<html lang="zh-cn">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title></title>
<meta name="description" content=" John Doe&#39;s Personal blog about everything">
<meta name="generator" content="Hugo 0.17" />
<meta property="og:title" content="" />
<meta property="og:description" content="description = &#34;&#34;date = &#34;2017-05-05T15:39:55&#34;categories = []tags = [&#34;tmp&#34;]thumbnail = &#34;&#34;title = &#34;tmp&#34;
&#43;
基本技能1. 熟悉Hadoop生态圈相关技术，如Hbase，Hive，Zookeeper，Flume，Kafka；2. 熟悉Spark运行机制，研读Spark部分内核源码；3. 熟悉（Elasticsearch、Logstash）的使用4. 熟悉Linux系统的基本操作和集群环境的搭建和部署5. 熟悉Docker的基本操作和容器管理Rancher的搭建、部署和使用6. 熟悉JavaEE的开发及常用框架使用，如：Spring、Mybatis、SpringMVC、Jesery、Hibernate、Struts2等
Mai沥青网电商平台 2015.5-2016.3 Java工程师开发工具&amp;环境：Eclipse &#43; Linux &#43; Java &#43; Hadoop &#43; Hbase &#43; Hive &#43; Redis项目描述：采集&#43;梳理，集中运营系统中记录的用户业务使用日志数据，对数据进行分类处理，内容分析，挖掘出用户的行为轨迹，分析用户访问互联网内容的类型&#43;频率等行为习惯，分析用户使用手机APP的行为特征等，对移动客户进行用户画像，为公司营销策划和各类业务模型报表统计做数据支持；职责描述：1，参与“预处理”模块功能开发及技术支持，对运营商接口机进行数据采集，对采集数据进行粗粒度分类，并将分类数据合并到相应的目标大数据平台；2，利用zookeeper的分布式锁功能实现采集机和数据接口机的一一对应绑定及机器的故障转移切换。
商品搜索,采用ElasticSearch根据店铺和商品的权重值,根据自定义算法实现排名.采用Logstash把店铺,商品,单品的数据从Mysql数据库中,增量导入到ElasticSearch.
前期配合运营需求调研,技术选型
大数据环境搭建: Hadoop &#43; Hbase &#43; Hive &#43; Flume &#43; Sqoop &#43; Azkaban" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/tmp/tmp2017-01-08/" />














<link rel="stylesheet" href="/css/google-font.css?family=Open+Sans:400,400italic,700,600" type="text/css" media="all" />

<link rel="stylesheet" href="/css/railscasts.css">
<link rel="stylesheet" href="/css/style.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/custom.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/jquery.bigautocomplete.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/asciinema-player.css" type="text/css" media="all" />
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/fonts/fontawesome-webfont.svg" rel="stylesheet">

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript" src="/js/scripts.js"></script>
<!--[if lt IE 9]>
	<script src="/js/css3-mediaqueries.js"></script>
<![endif]-->

</head>
<body id="mr-mobile" class="home blog mr-right-sb" itemscope="itemscope" itemtype="http://schema.org/WebPage">
	<div class="mr-container mr-container-outer">
		<div class="mr-header-mobile-nav clearfix"></div>
			<header class="mr-header" itemscope="itemscope" itemtype="http://schema.org/WPHeader">
				<div class="mr-container mr-container-inner mr-row clearfix">
					<div class="mr-custom-header clearfix">
						<div class="mr-site-identity">
							<div class="mr-site-logo" role="banner" itemscope="itemscope" itemtype="http://schema.org/Brand">
								<div class="mr-header-text">
									<a class="mr-header-text-link" href="/" title="零零散散" rel="home">
										<h1 class="mr-header-title">零零散散</h1>
										<h2 class="mr-header-tagline">点滴记录</h2>
									</a>
								</div>
							</div>
						</div>
					</div>
				</div>
				<div class="mr-main-nav-wrap">
					<nav class="menu" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
	<ul class="menu__list">
        
            <li class="menu__item"><a class="menu__link" href="/categories/docker">docker</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/hadoop">hadoop</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/scala">scala</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/spark">spark</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/storm">storm</a></li>
        
	</ul>
</nav>
				</div>
			</header>
		<div class="mr-wrapper clearfix">


<div class="mr-content" id="main-content" role="main" itemprop="mainContentOfPage">
	<article class="post">
		<header class="entry-header clearfix">
			<h1 class="entry-title"></h1>
			<p class="mr-meta entry-meta">
				<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
				<time class="entry-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
			</p>
		</header>
		<div class="entry-content clearfix">
			
			<div class="paragraph">
<p>description = ""
date = "2017-05-05T15:39:55"
categories = [
]
tags = [
    "tmp"
]
thumbnail = ""
title = "tmp"</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="paragraph">
<p>基本技能
1.  熟悉Hadoop生态圈相关技术，如Hbase，Hive，Zookeeper，Flume，Kafka；
2.  熟悉Spark运行机制，研读Spark部分内核源码；
3.  熟悉（Elasticsearch、Logstash）的使用
4.  熟悉Linux系统的基本操作和集群环境的搭建和部署
5.  熟悉Docker的基本操作和容器管理Rancher的搭建、部署和使用
6.  熟悉JavaEE的开发及常用框架使用，如：Spring、Mybatis、SpringMVC、Jesery、Hibernate、Struts2等</p>
</div>
<div class="paragraph">
<p>Mai沥青网电商平台   2015.5-2016.3   Java工程师
开发工具&amp;环境：Eclipse + Linux + Java + Hadoop + Hbase + Hive + Redis
项目描述：
采集+梳理，集中运营系统中记录的用户业务使用日志数据，对数据进行分类处理，内容分析，挖掘出用户的行为轨迹，分析用户访问互联网内容的类型+频率等行为习惯，分析用户使用手机APP的行为特征等，对移动客户进行用户画像，为公司营销策划和各类业务模型报表统计做数据支持；
职责描述：
1，参与“预处理”模块功能开发及技术支持，对运营商接口机进行数据采集，对采集数据进行粗粒度分类，并将分类数据合并到相应的目标大数据平台；
2，利用zookeeper的分布式锁功能实现采集机和数据接口机的一一对应绑定及机器的故障转移切换。</p>
</div>
<div class="paragraph">
<p>商品搜索,采用ElasticSearch根据店铺和商品的权重值,根据自定义算法实现排名.
采用Logstash把店铺,商品,单品的数据从Mysql数据库中,增量导入到ElasticSearch.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>前期配合运营需求调研,技术选型</p>
</li>
<li>
<p>大数据环境搭建: Hadoop + Hbase + Hive + Flume + Sqoop + Azkaban</p>
</li>
<li>
<p>采集日志数据到HDFS</p>
</li>
<li>
<p>预处理清洗数据</p>
</li>
<li>
<p>加载数据到ODS</p>
</li>
<li>
<p>ETL处理数据</p>
</li>
<li>
<p>Sqoop导出数据到Mysql</p>
</li>
<li>
<p>Azkaban调度任务</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>兆华领先供应链管理信息系统是天津兆华领先集团的发货,物流,仓储信息系统。</p>
</div>
<div class="paragraph">
<p>2015 5 4</p>
</div>
<div class="paragraph">
<p>由于个人原因,提出离职申请</p>
</div>
<div class="paragraph">
<p>笔记本</p>
</div>
<div class="paragraph">
<p>刘艳芳</p>
</div>
<div class="paragraph">
<p><a href="http://blog.csdn.net/lovehuangjiaju/article/details/49227919" class="bare">http://blog.csdn.net/lovehuangjiaju/article/details/49227919</a></p>
</div>
<div class="paragraph">
<p>spark-submit --name MyApp \
--class org.apache.spark.examples.streaming.NetworkWordCount \
--master spark://sparkmaster:7077 \
--conf spark.driver.extraJavaOptions="agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005" \
$SPARK_HOME/lib/spark-examples-1.6.3-hadoop2.6.0.jar hadoop-master 9999</p>
</div>
<div class="paragraph">
<p>docker volume create -d nfs --name myvol -o share=192.168.137.2:/d/share/spark16</p>
</div>
<div class="paragraph">
<p>docker volume create -d nfs --name myvol -o share=192.168.137.2:/d/share/spark16</p>
</div>
<div class="paragraph">
<p>def withScope[U](body: &#8658; U): U = body</p>
</div>
<div class="paragraph">
<p>curl -i -X POST \
  --url <a href="http://196.168.1.31:8001/apis/" class="bare">http://196.168.1.31:8001/apis/</a> \
  --data 'name=koto-api' \
  --data 'hosts=koto.com' \
  --data 'upstream_url=http://koto:8080'</p>
</div>
<div class="paragraph">
<p>curl -i -X GET \
  --url <a href="http://196.168.1.31:8000/" class="bare">http://196.168.1.31:8000/</a> \
  --header 'Host: koto.com'</p>
</div>
<div class="paragraph">
<p>create table t_pp(id string,name string)
clustered by (id)
sorted by (id)
into 4 buckets
row format delimited fields terminated by ',';</p>
</div>
<div class="paragraph">
<p>create table if not exists student(
 id INT,
 age INT,
 name STRING
) partitioned by(stat_date STRING)
clustered by(id) sorted by(age) into 2 buckets
row format delimited fields terminated by ',';</p>
</div>
<div class="paragraph">
<p>&lt;properties&gt;
    &lt;sbt.project.name&gt;examples&lt;/sbt.project.name&gt;
    &lt;scala.binary.version&gt;2.10.6&lt;/scala.binary.version&gt;
    &lt;project.version&gt;1.6.1&lt;/project.version&gt;
&lt;/properties&gt;</p>
</div>
<div class="paragraph">
<div class="title">/svn.exe co <a href="https://github.com/dishuiGit/codes.git/trunk/Spring-test" class="bare">https://github.com/dishuiGit/codes.git/trunk/Spring-test</a> /d/IdeaProject/spark-examples-1.6.1</div>
<p>svn.exe co <a href="https://github.com/apache/spark.git/trunk/examples" class="bare">https://github.com/apache/spark.git/trunk/examples</a> /d/IdeaProject/spark-examples-1.6.1</p>
</div>
<div class="paragraph">
<p>svn.exe co <a href="https://github.com/apache/spark.git/branches/branch-1.6/examples" class="bare">https://github.com/apache/spark.git/branches/branch-1.6/examples</a> /d/IdeaProject/bigdata/spark-examples-1.6</p>
</div>
<div class="paragraph">
<p>/e/Program\ Files/TortoiseSVN/</p>
</div>
<div class="paragraph">
<p>tcpdump -i eno1 -nn 'host 196.168.1.31'
tcpdump -i eno1 -nn 'src 196.168.1.31'</p>
</div>
<div class="paragraph">
<p>sqoop import \
  --driver com.mysql.jdbc.Driver \
  --connect jdbc:mysql://196.168.1.66:3306/wuliu \
  --username root \
  --password 111111 \
  --table zh_track_201702 \
  --hive-import \
  --hive-table zh_track_201703 \
  --m 4</p>
</div>
<div class="paragraph">
<p>export HADOOP_COMMON_HOME=/usr/local/hadoop
export HADOOP_MAPRED_HOME=/usr/local/hadoop
export HIVE_HOME=/usr/local/apache-hive-2.1.1-bin</p>
</div>
<div class="paragraph">
<p>/usr/local/spark-1.5.3/bin/spark-submit --properties-file /tmp/spark-submit.2641174306145842738.properties --class org.apache.hive.spark.client.RemoteDriver /usr/local/apache-hive-1.2.1-bin/lib/hive-exec-2.1.1.jar --remote-host master --remote-port 33195 --conf hive.spark.client.connect.timeout=1000 --conf hive.spark.client.server.connect.timeout=90000 --conf hive.spark.client.channel.log.level=null --conf hive.spark.client.rpc.max.size=52428800 --conf hive.spark.client.rpc.threads=8 --conf hive.spark.client.secret.bits=256 --conf hive.spark.client.rpc.server.address=null</p>
</div>
<div class="paragraph">
<p>create table if not exists mytable(sid int,name string)
row format delimited fields terminated by '\005'
stored as textfile;</p>
</div>
<div class="paragraph">
<p>create table if not exists pageview(
    pageid int,
    page_url string comment 'The page URL'
)
row format delimited fields terminated by ','
location 'hdfs://master:9000/user/hive/warehouse/';</p>
</div>
<div class="paragraph">
<p>创建分区表invites</p>
</div>
<div class="paragraph">
<p>create table if not exists invites(
    id int,
    name string
) partitioned by (ds string)
row format delimited fields terminated by ','
lines terminated by '\n'
stored as textfile;</p>
</div>
<div class="paragraph">
<p>create table if not exists student(
  id INT,
  age INT,
  name STRING
) partitioned by(stat_date STRING)
clustered by(id) sorted by(age) into 2 buckets
row format delimited fields terminated by ',';</p>
</div>
<div class="paragraph">
<p>create table student_p(
  Sno int,
  Sname string,
  Sex string,
  Sage int,
  Sdept string
) partitioned by(part string)
row format delimited fields terminated by ','
stored as textfile;</p>
</div>
<div class="paragraph">
<p>创建带桶的表student</p>
</div>
<div class="paragraph">
<p>set mapreduce.map.memory.mb=4096;
set mapreduce.reduce.memory.mb=5120;</p>
</div>
<div class="paragraph">
<p>asciinema rec -c bash /dishui/content/src/records/hive/cluster.json</p>
</div>
<div class="paragraph">
<p>ssh 192.168.123.123</p>
</div>
<div class="paragraph">
<p>$HIVE_HOME/bin/beeline -u jdbc:hive2://master:10000 -n root</p>
</div>
<div class="literalblock">
<div class="content">
<pre> #测试数据
cat &gt; sz.data &lt;&lt;_EOF_
1,a
2,b
3,cdd
4,rrt
5,eex
6,iio
7,haha
8,lslls
_EOF_</pre>
</div>
</div>
<div class="paragraph">
<p>select avg(s.Grade) from sc s group by s.Cno;</p>
</div>
<div class="paragraph">
<p>asciinema rec -c bash /dishui/content/src/records/hive/practice.json</p>
</div>
<div class="paragraph">
<p>ssh 196.168.1.31</p>
</div>
<div class="literalblock">
<div class="content">
<pre> #创建表student
create table student(
  Sno int,
  Sname string,
  Sex string,
  Sage int,
  Sdept string
)
row format delimited fields terminated by ','stored as textfile;
 #创建表course
create table course(
  Cno int,
  Cname string
)
row format delimited fields terminated by ',' stored as textfile;
 #创建表sc
create table sc(
  Sno int,
  Cno int,
  Grade int
)
row format delimited fields terminated by ',' stored as textfile;</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre> #测试数据
load data local inpath '/root/dishui/data/test/students.txt' overwrite into table student;
load data local inpath '/root/dishui/data/test/sc.txt' overwrite into table sc;
load data local inpath '/root/dishui/data/test/course.txt' overwrite into table course;</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>load data local inpath '/root/sz.data' into table t_p;</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre> #创建分桶表t_pp
create table t_pp(id string,name string)
clustered by (id)
sorted by (id)
into 4 buckets
row format delimited fields terminated by ',';</pre>
</div>
</div>
<div class="paragraph">
<p>insert into table t_pp
select id,name from t_p;</p>
</div>
<div class="paragraph">
<p>set hive.enforce.bucketing = true;
set mapreduce.job.reduces = 4;</p>
</div>
<div class="paragraph">
<p>insert into table t_pp
select id,name from t_p distribute by (id) sort by (id);</p>
</div>
<div class="paragraph">
<p>truncate table t_pp</p>
</div>
<div class="paragraph">
<p>#如果distribute和sort的字段一样可以直接用cluster
insert into table t_pp
select id,name from t_p cluster by (id);</p>
</div>
<div class="paragraph">
<p>#查看分区数据
dfs -cat /user/hive/warehouse/t_pp/000000_0;</p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/profile.d/bigdata.sh &lt;&lt;_EOF_
export JAVA_HOME=/usr/local/jdk1.7.0_79
export HADOOP_HOME=/usr/local/hadoop
export SPARK_HOME=/usr/local/spark-1.5.3
export HIVE_HOME=/usr/local/apache-hive-1.2.1-bin
export PATH=\$PATH:\$JAVA_HOME/bin:\$HADOOP_HOME/bin:\$SPARK_HOME/bin:\$HADOOP_HOME/sbin:\$SPARK_HOME/sbin:\$HIVE_HOME/bin
<em>EOF</em></p>
</div>
<div class="paragraph">
<p><a href="http://blog.csdn.net/cheersu/article/details/8191743" class="bare">http://blog.csdn.net/cheersu/article/details/8191743</a></p>
</div>
<div class="paragraph">
<p><a href="http://196.168.1.31:9200/_sql?sql=SELECT" class="bare">http://196.168.1.31:9200/_sql?sql=SELECT</a> * FROM b2b/ti_procurement</p>
</div>
<div class="paragraph">
<p>ENTRYPOINT ["sh","-c","/docker-entrypoint.sh"]</p>
</div>
<div class="paragraph">
<p>bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client --executor-memory 512M --total-executor-cores 1 lib/spark-examples-*.jar 10</p>
</div>
<div class="paragraph">
<p>spark.master                     yarn-cluster
spark.home                       /usr/local/spark-1.5.3
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://hadoop-master:9000/hive-spark-log
spark.serializer                 org.apache.spark.serializer.KryoSerializer
spark.executor.memory            512m
spark.driver.memory              512m
spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"</p>
</div>
<div class="paragraph">
<p>export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_DIST_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath)
export SPARK_MASTER_IP=hadoop-master
export SPARK_MASTER_PORT=7077</p>
</div>
<div class="paragraph">
<p>select count(*) from test;</p>
</div>
<div class="paragraph">
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstream
cat &gt; /root/dnsmasq.hosts &lt;&lt;_EOF_
172.17.76.3 hadoop-master
172.17.76.4 hadoop-slave1
172.17.76.2 mysql
172.17.87.2 hadoop-slave2</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>cat &gt; /root/dishui/data/conf/dnsmasq.hosts <a href="#_EOF_
172.17.80.5 hadoop-master
172.17.80.4 hadoop-slave1
172.17.80.2 mariadb
172.17.80.6 mysql
172.17.17.2 hadoop-slave2">[_EOF_
172.17.80.5 hadoop-master
172.17.80.4 hadoop-slave1
172.17.80.2 mariadb
172.17.80.6 mysql
172.17.17.2 hadoop-slave2]</a>&gt;&gt;&gt;&gt;&gt; Stashed changes
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>dfs.datanode.address</p>
</div>
<div class="paragraph">
<p>cat &gt;&gt; /etc/profile &lt;&lt;_EOF_
export JAVA_HOME=/usr/local/jdk1.7.0_71
export HADOOP_HOME=/usr/local/hadoop-2.6.5
export SPARK_HOME=/usr/local/spark-1.5.3
export HIVE_HOME=/usr/local/apache-hive-1.2.1-bin
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$SPARK_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/sbin:$HIVE_HOME/bin
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>root@hadoop-master:/usr/local/spark-1.5.3# sbin/start-all.sh
starting org.apache.spark.deploy.master.Master, logging to
/usr/local/spark-1.5.3/sbin/../logs/spark&#8212;&#8203;org.apache.spark.deploy.master.Master-1-hadoop-master.out</p>
</div>
<div class="paragraph">
<p>hadoop-master: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/spark-1.5.3/sbin/../logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop-master.out
hadoop-slave3: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/spark-1.5.3/sbin/../logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop-slave3.out
hadoop-slave1: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/spark-1.5.3/sbin/../logs/spark-root-org.apache.spark.deploy.worker.Worker-1-hadoop-slave1.out</p>
</div>
<div class="paragraph">
<p>FROM kiwenlau/hadoop-hive-spark:1.0</p>
</div>
<div class="paragraph">
<p>COPY spark-1.5.3.tar.gz /
COPY hive-site.xml /apache-hive-1.2.1-bin/conf/
COPY yarn-site.xml /usr/local/hadoop/etc/hadoop/
ENV SPARK_HOME=/usr/local/spark-1.5.3
ENV PATH="$SPARK_HOME/bin:${PATH}"</p>
</div>
<div class="paragraph">
<p>RUN tar -zxf spark-1.5.3.tar.gz -C /usr/local \
    &amp;&amp; rm -f /spark-1.5.3.tar.gz</p>
</div>
<div class="paragraph">
<p>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
  &lt;value&gt;jdbc:mysql://mysql:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;
&lt;/property&gt;</p>
</div>
<div class="paragraph">
<p>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
&lt;/property&gt;</p>
</div>
<div class="paragraph">
<p>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
  &lt;value&gt;root&lt;/value&gt;
&lt;/property&gt;</p>
</div>
<div class="paragraph">
<p>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
  &lt;value&gt;111111&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;spark.yarn.jars&lt;/name&gt;
  &lt;value&gt;hdfs://hadoop-master:9000/spark-assembly-1.5.3.jar&lt;/value&gt;
&lt;/property&gt;</p>
</div>
<div class="paragraph">
<p>&lt;property&gt;
  &lt;name&gt;hive.execution.engine&lt;/name&gt;
  &lt;value&gt;spark&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;spark.enentLog.enabled&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;spark.enentLog.dir&lt;/name&gt;
  &lt;value&gt;hdfs://master:9000/hive-spark-log&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;spark.serializer&lt;/name&gt;
  &lt;value&gt;org.apache.spark.serializer.KryoSerializer&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;spark.executor.memeory&lt;/name&gt;
  &lt;value&gt;512m&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;spark.driver.memeory&lt;/name&gt;
  &lt;value&gt;512m&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;spark.executor.extraJavaOptions&lt;/name&gt;
  &lt;value&gt;-XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"&lt;/value&gt;
&lt;/property&gt;</p>
</div>
<div class="paragraph">
<p>set hive.execution.engine=spark;
set spark.master=spark://hadoop-master:7077;
set spark.eventLog.enabled=true;
set spark.eventLog.dir=hdfs://hadoop-master:9000/hive-spark-log;
set spark.executor.memory=512m;
set spark.serializer=org.apache.spark.serializer.KryoSerializer;</p>
</div>
<div class="paragraph">
<p>set hive.execution.engine=spark;
set spark.master=spark://master:7077;
set spark.eventLog.enabled=true;
set spark.eventLog.dir=hdfs://master:9000/hive-spark-log;
set spark.executor.memory=512m;
set spark.serializer=org.apache.spark.serializer.KryoSerializer;</p>
</div>
<div class="paragraph">
<p>set spark.master=yarn-cluster;
set hive.execution.engine=spark;
set spark.eventLog.enabled=true;
set spark.eventLog.dir=hdfs://master:9000/hive-spark-log;
set spark.executor.memory=1g;
set spark.serializer=org.apache.spark.serializer.KryoSerializer;</p>
</div>
<div class="paragraph">
<p>set spark.master=yarn-cluster;
set hive.execution.engine=spark;
set spark.eventLog.enabled=true;
set spark.eventLog.dir=hdfs://master:9000/hive-spark-log;
set spark.executor.memory=1g;
set spark.serializer=org.apache.spark.serializer.KryoSerializer;</p>
</div>
<div class="paragraph">
<p>create table test2(ts BIGINT,line STRING);
select count(*) from test2;</p>
</div>
<div class="paragraph">
<p>bin/spark-submit --class org.apache.spark.examples.SparkPi \
    --master yarn \
    --deploy-mode cluster \
    --driver-memory 1g \
    --executor-memory 1g \
    --executor-cores 1 \
    --queue thequeue \
    lib/spark-examples*.jar \
    10</p>
</div>
<div class="paragraph">
<p>bin/spark-submit --class org.apache.spark.examples.streaming.NetworkWordCount \
  --master spark://hadoop-master:7077 \
  --driver-memory 1g \
  --executor-memory 1g \
  lib/spark-examples*.jar \
  localhost 9999</p>
</div>
<div class="paragraph">
<p>bin/spark-submit --class org.apache.spark.examples.streaming.StatefulNetworkWordCount \
  --master spark://hadoop-master:7077 \
  --driver-memory 1g \
  --executor-memory 1g \
  lib/spark-examples*.jar \
  localhost 9999</p>
</div>
<div class="paragraph">
<p>docker run -it --rm --dns 192.168.123.123 alpine:3.5 /bin/sh</p>
</div>
<div class="paragraph">
<p>mkdir -p /etc/dnsmasq.d</p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/dnsmasq.conf &lt;&lt;_EOF_
cache-size=10000
resolv-file=/etc/dnsmasq-resolv.conf
addn-hosts=/etc/dnsmasq.hosts
log-queries
log-facility=/var/log/dnsmasq.log
local-ttl=600
conf-dir=/etc/dnsmasq.d
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/dnsmasq.conf &lt;&lt;_EOF_
log-queries
log-facility=/var/log/dnsmasq.log
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/dnsmasq-resolv.conf &lt;&lt;_EOF_
nameserver 114.114.114.114
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>cat &gt; /usr/lib/systemd/system/flanneld.service &lt;&lt;_EOF_</p>
</div>
<div class="paragraph">
<p>After=network.target
After=network-online.target docker.service
Description=flannel</p>
</div>
<div class="paragraph">
<p>ExecStart=/root/bin/flanneld \
-iface=eth1 \
-etcd-endpoints=http://196.168.1.34:2379</p>
</div>
<div class="paragraph">
<p>WantedBy=multi-user.target
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>cat &gt;&gt; /etc/hosts &lt;&lt;_EOF_
192.168.123.123 master
192.168.123.124 slave1
192.168.123.125 slave2
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>docker rm -f hadoop-slave2 hadoop-slave1 hadoop-master</p>
</div>
<div class="paragraph">
<p>docker run -d -v /root/dishui/data/conf/dnsmasq.hosts:/etc/hosts -p 53:53/tcp -p 53:53/udp --cap-add=NET_ADMIN --name dns-server andyshinn/dnsmasq:2.75</p>
</div>
<div class="paragraph">
<p>resolv-file=/etc/resolv.dnsmasq</p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/dnsmasq.conf &lt;&lt;_EOF_
addn-hosts=/etc/dnsmasqhosts
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>dns: 172.17.80.3</p>
</div>
<div class="paragraph">
<p>#!/bin/bash</p>
</div>
<div class="paragraph">
<p>DOMAIN=dishui.io:5000</p>
</div>
<div class="paragraph">
<p>mkdir -p /etc/docker/certs.d/$DOMAIN</p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/docker/certs.d/$DOMAIN/registry.crt &lt;&lt;_EOF_
-----BEGIN CERTIFICATE-----
MIIC+zCCAeOgAwIBAgIJAOxktzjYRccOMA0GCSqGSIb3DQEBCwUAMBQxEjAQBgNV
BAMMCWRpc2h1aS5pbzAeFw0xNjA4MjcxMjQ5MTBaFw0yNjA4MjUxMjQ5MTBaMBQx
EjAQBgNVBAMMCWRpc2h1aS5pbzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoC
ggEBAMlDw1mAzZG5OX4leFytRLjzvQWZzpNXGQ9T290nLVK2/4v5lKHdJkF9gva6
ljpEJ362AxBmXw9ZWRKuDXaWtst5r6Xz1hyrHdaQ3/TP3SeBCpVMj+P2XM0mjo6r
J2eo8u7YTQoTcjZz0iSTprVvPLsutyKPTxT+Mj2wSvf29R4NyGTQ1XGM1eyt4xEM
xwf3VpHqw2UvhdpYT2mnv/SGqQu39n9fSABRlKnfNMx/jaTnE04p1lHQpvW1aJcj
unS9zxsDDsWuwO8U+/WQhVtfNLLecuShcgiIibE14VxKWIPe3X/pcYmF25oPJVL+
VtnlCaqlhvu3PkgDFBI8n7PAoVUCAwEAAaNQME4wHQYDVR0OBBYEFCgHv8jqKSHV
KXEnz87Y/48Dp7PXMB8GA1UdIwQYMBaAFCgHv8jqKSHVKXEnz87Y/48Dp7PXMAwG
A1UdEwQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAHGhcUFIqVxMgZ7jY0y/o4DK
gIELCes6O3ruVQNnyK2wHpqsfV0PG3Mcn4UDwk5iqSXrAULi677dUzeZ1BLI2HHi
XJLdmEj9KLq38ktrLAPjhFUKoUhWCehtEuR0JMj/wjSdRN/5/yI5Ki1+Rk42M2Ld
CD5j9+kuk4wtCy4wxi4CRQZQEHn4FyjXdVMJZJ2nn5QwFkjZzhvW9ze9RbrZ3dii
HAES9laZx3AwKjmMi/wjY3qNoqlpho61DMrTD872xy57/ajh86YV3yb4+78D/aUl
5I4JUvkqcayVlxVDmpU0sppq5M4u8t/iiB8TvGmi2utG0j4xSLGKSM03WL+rWdA=
-----END CERTIFICATE-----
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>echo 196.168.1.86 dishui.io &gt;&gt; /etc/hosts</p>
</div>
<div class="paragraph">
<p>UPDATE <code>jbpm4_task</code> SET <code>STATE_</code> = 'close' WHERE <code>DBID_</code> in ('690315', '550562', '550562', '420663', '330248', '300013', '280089', '200085', '160036', '150096', '150083', '150012', '140007', '120035', '110035', '60215', '90121');</p>
</div>
<div class="paragraph">
<p>'260080', '260070', '150036', '130051', '130108', '130034'</p>
</div>
<div class="paragraph">
<p>'150036', '130051', '130108', '130034', '130036', '130038'</p>
</div>
<div class="paragraph">
<p>'690315', '550562', '550562', '420663', '330248', '300013', '280089', '200085', '160036', '150096', '150083', '150012', '140007', '120035', '110035', '60215', '90121'</p>
</div>
<div class="paragraph">
<p>发货申请审批 + 合同类型</p>
</div>
<div class="paragraph">
<p>未审核最上面</p>
</div>
<div class="paragraph">
<p>检索  项目名称 销售公司 客户名称 申请人</p>
</div>
<div class="paragraph">
<p>String projectName = request.getParameter("projectName");
String sellCompanyOutName = request.getParameter("sellCompanyOutName");
String customName = request.getParameter("customName");
String documentMaker = request.getParameter("documentMaker");</p>
</div>
<div class="paragraph">
<p>projectName
sellCompanyOutName
customName
documentMaker</p>
</div>
<div class="paragraph">
<p>import org.casic.javaframework.web.sendoutgoodscheck.service;
 //判断如果办理类型是完成的情况
if(context.getAttribute("transactType").equals("2")){
  ISendGoodsCheckService service =(ISendGoodsCheckService)applicationContext.getBean("sendGoodsCheckService");
  String id=context.getAttribute("bussinessNo");
  String wfmId= context.getAttribute("transactIdea");
  service.passShenpi(3,wfmId,id);
}
if(context.getAttribute("transactType").equals("4")){
  ISendGoodsCheckService service =(ISendGoodsCheckService)applicationContext.getBean("sendGoodsCheckService");
  String id=context.getAttribute("bussinessNo");
  String wfmId= context.getAttribute("transactIdea");
  service.passShenpi(5,wfmId,id);
}</p>
</div>
<div class="paragraph">
<p>if(ObjUtils.notEmpty(projectName)) whereStr.append(" and project_name like '%"projectName"%'");
if(ObjUtils.notEmpty(sellCompanyOutName)) whereStr.append(" and sell_company_out_name like '%"sellCompanyOutName"%'");
if(ObjUtils.notEmpty(customName)) whereStr.append(" and custom_name like '%"customName"%'");
if(ObjUtils.notEmpty(documentMaker)) whereStr.append(" and document_maker like '%"documentMaker"%'");</p>
</div>
<div class="listingblock">
<div class="content">
<pre>VirtualBox - Error In supR3HardenedWinReSpawn</pre>
</div>
</div>
<div class="paragraph">
<p>&lt;html&gt;&lt;b&gt;NtCreateFile(\Device\VBoxDrvStub) failed: 0xc0000034 STATUS_OBJECT_NAME_NOT_FOUND (0 retries) (rc=-101)&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;Make sure the kernel module has been loaded successfully.&lt;br&gt;&lt;br&gt;&lt;!--EOM-&#8594;where: supR3HardenedWinReSpawn
what:  3
VERR_OPEN_FAILED (-101) - File/Device open failed.</p>
</div>
<div class="paragraph">
<p>Driver is probably stuck stopping/starting. Try 'sc.exe query vboxdrv' to get more information about its state. Rebooting may actually help.&lt;/html&gt;</p>
</div>
<div class="listingblock">
<div class="content">
<pre>OK</pre>
</div>
</div>
<div class="paragraph">
<p>nohup flanneld -iface=eno1 -etcd-endpoints=http://196.168.1.34:2379 &amp;
nohup flanneld -iface=eth1 -etcd-endpoints=http://196.168.1.34:2379 &amp;</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Error (Couldn't bring up network: failed to find plugin "rancher-bridge" in path [/opt/cni/bin /var/lib/cni/bin /usr/local/sbin /usr/sbin /sbin /usr/local/bi</pre>
</div>
</div>
<div class="paragraph">
<p>-e CATTLE_AGENT_IP=&lt;</p>
</div>
<div class="paragraph">
<p>sudo docker run --rm --privileged -e CATTLE_AGENT_IP=192.168.1.55 -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/rancher:/var/lib/rancher rancher/agent:v1.2.2 <a href="http://192.168.1.55:8080/v1/scripts/4E42E0DCA5755FA4E9C7:1483142400000:iFFrEd1fYz0mxK7ElC63n6X5Kw" class="bare">http://192.168.1.55:8080/v1/scripts/4E42E0DCA5755FA4E9C7:1483142400000:iFFrEd1fYz0mxK7ElC63n6X5Kw</a></p>
</div>
<div class="paragraph">
<p>sudo docker run --rm --privileged -e CATTLE_AGENT_IP=192.168.1.54 -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/rancher:/var/lib/rancher rancher/agent:v1.2.2 <a href="http://192.168.1.55:8080/v1/scripts/4E42E0DCA5755FA4E9C7:1483142400000:iFFrEd1fYz0mxK7ElC63n6X5Kw" class="bare">http://192.168.1.55:8080/v1/scripts/4E42E0DCA5755FA4E9C7:1483142400000:iFFrEd1fYz0mxK7ElC63n6X5Kw</a></p>
</div>
<div class="paragraph">
<p>nmcli connection modify docker0 connection.zone trusted
systemctl stop NetworkManager.service
firewall-cmd --permanent --zone=trusted --change-interface=docker0
systemctl start NetworkManager.service
nmcli connection modify docker0 connection.zone trusted
systemctl restart docker.service</p>
</div>
<div class="paragraph">
<p>关闭 selinux</p>
</div>
<div class="paragraph">
<p>sed -i 's#SELINUX=enforcing#SELINUX=disabled#' /etc/selinux/config</p>
</div>
<div class="paragraph">
<p>/etc/yum.repos.d/Local-rpm.repo</p>
</div>
<div class="paragraph">
<p>yum install -y yum-plugin-downloadonly
yum install docker-engine-1.12.1-1.el7.centos --downloadonly --downloaddir=/var/www/html/data/yum-repo/
createrepo -p -d -o /var/www/html/data/yum-repo/ /var/www/html/data/yum-repo/</p>
</div>
<div class="paragraph">
<p>systemctl start httpd</p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/yum.repos.d/CentOS-Base.repo &lt;&lt;_EOF_</p>
</div>
<div class="paragraph">
<p>name=Local-rpm
baseurl=http://jzlh.com/data/yum-repo
enabled=1
gpgcheck=0
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>yum install -y docker-engine-1.12.1-1.el7.centos</p>
</div>
<div class="paragraph">
<p>echo 196.168.1.34 hadoop-34 &gt;&gt; /etc/hosts
echo 196.168.1.35 spark-35 &gt;&gt; /etc/hosts</p>
</div>
<div class="paragraph">
<p>echo 192.168.1.54 pro-54 &gt;&gt; /etc/hosts
echo 192.168.1.55 jzlh.com &gt;&gt; /etc/hosts
echo 192.168.1.53 pro-53 &gt;&gt; /etc/hosts
echo 192.168.1.52 pro-52 &gt;&gt; /etc/hosts
echo 192.168.1.51 pro-51 &gt;&gt; /etc/hosts</p>
</div>
<div class="paragraph">
<p>echo pro-53 &gt;&gt; /etc/hostname
echo pro-52 &gt;&gt; /etc/hostname
echo pro-51 &gt;&gt; /etc/hostname</p>
</div>
<div class="paragraph">
<p>export HIVE_HOME=/apache-hive-1.2.1-bin/</p>
</div>
<div class="paragraph">
<p>load data inpath '$click_pvout/$day_01' into table $ods_click_pageviews partition(datestr='$day_01')"</p>
</div>
<div class="paragraph">
<p>set hive.execution.engine=spark;
set spark.master=spark://192.168.123.90:7077;
set spark.eventLog.enabled=true;
set spark.eventLog.dir=hdfs://hadoop-master:9000/spark-hive-log;
set spark.executor.memory=512m;
set spark.serializer=org.apache.spark.serializer.KryoSerializer;</p>
</div>
<div class="paragraph">
<p>FROM registry.cn-hangzhou.aliyuncs.com/dishui/java:1.0
ENV MAVEN_HOME="/usr/local/apache-maven-3.0.5"
ENV PATH="${MAVEN_HOME}/bin:${PATH}"
COPY ./apache-maven-3.0.5.tar /
RUN tar -xf /apache-maven-3.0.5.tar -C /usr/local/ \
  &amp;&amp; rm -f /apache-maven-3.0.5.tar</p>
</div>
<div class="paragraph">
<p>mvn -DskipTests clean package -Phive -Phive-thriftserver</p>
</div>
<div class="paragraph">
<p>60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] "GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0" 200 185524 "http://cos.name/category/software/packages/" "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36"</p>
</div>
<div class="paragraph">
<p>private String remoteAddr;
private String remoteUser;
private String timeLocal;
private String request;
private String status;
private String bodyBytesSent;
private String httpReferer;
private String httpUserAgent;</p>
</div>
<div class="paragraph">
<p>60.208.6.156
- -</p>
</div>
<div class="paragraph">
<p>"GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0"
200
185524
"http://cos.name/category/software/packages/"
"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36"</p>
</div>
<div class="literalblock">
<div class="content">
<pre>background-color: lightsteelblue;</pre>
</div>
</div>
<div class="paragraph">
<p>tableblock frame-all grid-all spread</p>
</div>
<div class="paragraph">
<p>select a.month as month,a.day as day,a.hour as hour,count(1) as pvs from shizhan.ods_weblog_detail a
where a.datestr=2017-05-27 group by a.month,a.day,a.hour;</p>
</div>
<div class="paragraph">
<p>mount -t cifs --verbose -o user=dishui,password=dishui,vers=2.1,sec=krb5 //192.168.123.199/dishui /root/dishui/mount/</p>
</div>
<div class="paragraph">
<p>z%5ge303Np!h</p>
</div>
<div class="paragraph">
<p>iDc@5bG8tah5!
sqoop import \
  --driver com.mysql.jdbc.Driver \
  --connect jdbc:mysql://mysql:3306/wuliu3 \
  --username root \
  --password 111111 \
  --table zh_goods_info   \
  --m 1</p>
</div>
<div class="paragraph">
<p>sqoop export \
  --driver com.mysql.jdbc.Driver \
  --connect "jdbc:mysql://mysql:3306/shizhan" \
  --username root \
  --password 111111 \
  --table "dw_pvs_hour1" \
  --fields-terminated-by '\001' \
  --export-dir /user/hive/warehouse/shizhan.db/dw_pvs_hour/datestr=2017-05-27</p>
</div>
<div class="paragraph">
<p>docker run -itd \
  --net=hadoop \
  --name sqoop \
  --hostname sqoop \
  kiwenlau/hadoop-sqoop:1.0</p>
</div>
<div class="paragraph">
<p>SELECT a.<strong>,b.</strong>
FROM ods_origin_weblog a LATERAL VIEW parse_url_tuple(regexp_replace(http_referer, "\"", ""), 'HOST', 'PATH','QUERY', 'QUERY:id') b as host, path, query, query_id;</p>
</div>
<div class="paragraph">
<p>SELECT
a.valid,a.remote_addr,a.remote_user,a.time_local,
a.request,a.status,a.body_bytes_sent,a.http_referer,
a.http_user_agent,b.ref_host,b.ref_path,b.ref_query,b.ref_query_id
FROM ods_weblog_origin a LATERAL VIEW parse_url_tuple(regexp_replace(http_referer, "\"", ""), 'HOST', 'PATH','QUERY', 'QUERY:id') b as ref_host, ref_path, ref_query, ref_query_id;</p>
</div>
<div class="paragraph">
<p>hadoop fs -rm -r /data/weblog/preprocess/output/2017-05-25 /data/weblog/preprocess/valid_output/2017-05-25 /data/weblog/preprocess/click_pv_out/2017-05-25 /data/weblog/preprocess/click_visit_out/2017-05-25</p>
</div>
<div class="paragraph">
<p>hadoop jar /weblog.jar cn.itcast.bigdata.hive.mr.ClickStreamThree /data/weblog/preprocess/output/2017-05-25 /data/weblog/preprocess/click_pv_out/2017-05-25</p>
</div>
<div class="paragraph">
<p>${HADOOP_PRE}/hadoop jar /${FILE_NAME} $click_pv_class $log_pre_output/$day_01 $click_pvout/$day_01
fi</p>
</div>
<div class="paragraph">
<p>今:
  借朗锐科服务器(AQR-2181)一台</p>
</div>
<div class="paragraph">
<p>/web/bpm/setting/sendgoods_check_update.jsp</p>
</div>
<div class="paragraph">
<p>/bpm/jbpmAction!submitJbpm.action",transacTask_taskid,"",name,type,idea,""</p>
</div>
<div class="paragraph">
<p>version: '2'
services:
  mysql5.5:
    image: dishui.io:5000/asosso/mysql:5.5.52
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: '111111'
    ports:
      - '3307:3306'
    networks:
      - hadoop
  zoo1:
    image: dishui.io:5000/zookeeper:3.4
    restart: always
    ports:
      - 2181:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zoo1:2888:3888
    networks:
      - hadoop
networks:
  hadoop:
    external: true</p>
</div>
<div class="paragraph">
<p>set hive.support.concurrency = true;
set hive.enforce.bucketing = true;
set hive.exec.dynamic.partition.mode = nonstrict;
set hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
set hive.compactor.initiator.on = true;
set hive.compactor.worker.threads = 1;
set hive.zookeeper.quorum = zoo1;</p>
</div>
<div class="paragraph">
<p>CREATE TABLE college(clg_id int,clg_name string,clg_loc string) clustered by (clg_id) into 5 buckets stored as orc TBLPROPERTIES('transactional'='true');</p>
</div>
<div class="paragraph">
<p>INSERT INTO table college values(1,'nec','nlr'),(2,'vit','vlr'),(3,'srm','chen'),(4,'lpu','del'),(5,'stanford','uk'),(6,'JNTUA','atp'),(7,'cambridge','us');</p>
</div>
<div class="paragraph">
<p>&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
    &lt;value&gt;jdbc:mysql://mysql:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;
    &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;
  &lt;/property&gt;</p>
</div>
<div class="literalblock">
<div class="content">
<pre>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
&lt;/property&gt;</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
  &lt;value&gt;root&lt;/value&gt;
  &lt;description&gt;username to use against metastore database&lt;/description&gt;
&lt;/property&gt;</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
    &lt;value&gt;111111&lt;/value&gt;
    &lt;description&gt;password to use against metastore database&lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.support.concurrency&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.enforce.bucketing&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.exec.dynamic.partition.mode&lt;/name&gt;
    &lt;value&gt;nonstrict&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.txn.manager&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.hive.ql.lockmgr.DbTxnManager&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.compactor.initiator.on&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.compactor.worker.threads&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;zoo1&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>hive.support.concurrency –true
hive.zookeeper.quorum - 192.168.2.233 (自己添加)
hive.enforce.bucketing – true (Hive 2.0之后不需要设置)
hive.exec.dynamic.partition.mode – nonstrict
hive.txn.manager – org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
hive.compactor.initiator.on – true
hive.compactor.worker.threads – 5</p>
</div>
<div class="paragraph">
<p>&lt;property&gt;
  &lt;name&gt;hive.support.concurrency&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.enforce.bucketing&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.exec.dynamic.partition.mode&lt;/name&gt;
  &lt;value&gt;nonstrict&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.txn.manager&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.hive.ql.lockmgr.DbTxnManager&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.compactor.initiator.on&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.compactor.worker.threads&lt;/name&gt;
  &lt;value&gt;5&lt;/value&gt;
&lt;/property&gt;</p>
</div>
<div class="paragraph">
<p>CREATE TABLE users (
  id int,
  name string
)
CLUSTERED BY (id) INTO 2 BUCKETS STORED AS ORC
TBLPROPERTIES ("transactional"="true",
"compactor.mapreduce.map.memory.mb"="400",
"compactorthreshold.hive.compactor.delta.num.threshold"="2",
"compactorthreshold.hive.compactor.delta.pct.threshold"="0.5"
);</p>
</div>
<div class="paragraph">
<p>INSERT INTO TABLE users VALUES (1,'11'), (2,'22');
INSERT INTO TABLE users VALUES (3,'xx'), (4,'yy');
INSERT INTO TABLE users VALUES (5,'xx1'), (6,'yy2');</p>
</div>
<div class="paragraph">
<p>hive --service metastore</p>
</div>
<div class="paragraph">
<p>ALTER TABLE users COMPACT 'minor';
show compactions;</p>
</div>
<div class="paragraph">
<p>drop table if exists ods_weblog_origin;
drop table if exists ods_weblog_origin;
drop table if exists ods_weblog_origin;</p>
</div>
<div class="paragraph">
<p>drop table if exists mytable;
drop table if exists pageview;
drop table if exists student;
drop table if exists student_p;
drop table if exists trade_detail;</p>
</div>
<div class="paragraph">
<p>drop table if exists ods_click_pageviews;
create table ods_click_pageviews(
Session string,
remote_addr string,
user string,
time_local string,
request string,
visit_step string,
page_staylong string,
http_referer string,
http_user_agent string,
body_bytes_sent string,
status string)
partitioned by (datestr string)
row format delimited
fields terminated by '\001';</p>
</div>
<div class="paragraph">
<p>后台启动hiveserver
nohup hiveserver2 1&gt;/var/log/hiveserver.log 2&gt;/var/log/hiveserver.err &amp;</p>
</div>
<div class="paragraph">
<p>asciinema rec -c bash 1.json</p>
</div>
<div class="paragraph">
<p>ssh root@196.168.1.34</p>
</div>
<div class="paragraph">
<p>docker exec -it hadoop-master /bin/bash
docker exec -it hadoop-slave1 /bin/bash</p>
</div>
<div class="paragraph">
<p>连接hive
beeline -u jdbc:hive2://hadoop-master:10000 -n root</p>
</div>
<div class="paragraph">
<p>beeline -u jdbc:hive2://hadoop-master:10000/default -n root</p>
</div>
<div class="paragraph">
<p>!connect jdbc:hive2://hadoop-master:10000 root</p>
</div>
<div class="paragraph">
<p>create table if not exists mytable3(sid int, sname string) row format delimited fields terminated by '\005' stored as textfile;</p>
</div>
<div class="paragraph">
<p>create external table if not exists pageview(pageid int,page_url string comment 'The page URL') row format delimited fields terminated by ',' location 'hdfs://hadoop-master:9000/user/hive/warehouse/';</p>
</div>
<div class="paragraph">
<p>create table student_p(Sno int,Sname string,Sex string,Sage int,Sdept string) partitioned by(part string) row format delimited fields terminated by ',' stored as textfile;</p>
</div>
<div class="paragraph">
<p>create table student(id INT,age INT,name STRING) partitioned by(stat_date STRING) clustered by(id) sorted by(age) into 2 buckets row format delimited fields terminated by ',';</p>
</div>
<div class="paragraph">
<p>asciidoctor-pdf -r asciidoctor-pdf-cjk-kai_gen_gothic -a pdf-style=KaiGenGothicCN</p>
</div>
<div class="paragraph">
<p>持续化构建,部署
版本管理
编译
数据库
反向代理
大物流
禅道</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/chloerei/asciidoctor-pdf-cjk-kai_gen_gothic/releases/download/v0.1.0-fonts/KaiGenGothicCN-Bold-Italic.ttf" class="bare">https://github.com/chloerei/asciidoctor-pdf-cjk-kai_gen_gothic/releases/download/v0.1.0-fonts/KaiGenGothicCN-Bold-Italic.ttf</a></p>
</div>
<div class="paragraph">
<p>rancher stop wuliu-dev/wuliu &amp;&amp;
rancher exec wuliu-dev/ant rm -rf /svn-data/code/tky/WebRoot/WEB-INF/classes &amp;&amp;
rancher exec wuliu-dev/svn svn up /svn-data/code/tky/ &amp;&amp;
rancher exec wuliu-dev/ant /apache-ant-1.9.7/bin/ant -f /svn-data/code/tky/build.xml &amp;&amp;
rancher restart wuliu-dev/wuliu</p>
</div>
<div class="paragraph">
<p>/home/wuliu/opt/src/version2/web.conf:/etc/nginx/conf.d/default.conf</p>
</div>
<div class="paragraph">
<p>/home/wuliu/opt/src/version2/server.xml:/apache-tomcat-7.0.62/conf/server.xml
/home/wuliu/opt/src/version2/data/svn/code/tky/WebRoot:/apache-tomcat-7.0.62/webapps/wuliu
/home/wuliu/opt/src/version2/data/tmp:/tmp</p>
</div>
<div class="paragraph">
<p>/home/wuliu/opt/src/version2/cnf/mysql/mysql-m.cnf:/etc/mysql/conf.d/mysqld.cnf</p>
</div>
<div class="paragraph">
<p>/home/wuliu/opt/src/version2/data/svn:/svn-data
/home/wuliu/opt/src/version2/data/ecj-4.4.jar:/apache-ant-1.9.7/lib/ecj-4.4.jar
/home/wuliu/opt/src/version2/data/servlet-api-2.5.jar:/apache-ant-1.9.7/lib/servlet-api-2.5.jar
/home/wuliu/opt/src/version2/data/wuliu:/wuliu</p>
</div>
<div class="paragraph">
<p>/home/wuliu/opt/src/version2/data/svn:/svn-data</p>
</div>
<div class="paragraph">
<p>/home/wuliu/opt/src/version2/data/start.sh:/start.sh
/home/wuliu/opt/src/version2/data/zbox:/opt/zbox</p>
</div>
<div class="paragraph">
<p>svn co svn://196.168.1.33/wuliu/code/tky</p>
</div>
<div class="literalblock">
<div class="content">
<pre>/root/.jenkins:/root/.jenkins</pre>
</div>
</div>
<div class="paragraph">
<p>mailiqing.com:5000/jenkins:1.0</p>
</div>
<div class="paragraph">
<p>svn switch --relocate</p>
</div>
<div class="paragraph">
<p>mailiqing-app-stable /root/.jenkins/workspace/mailiqing-increment/stable/app
mailiqing-app-dev /root/.jenkins/workspace/mailiqing-increment/dev/app-dev</p>
</div>
<div class="paragraph">
<p>wuliu /root/.jenkins/workspace/mailiqing-increment/wuliu-production/tky</p>
</div>
<div class="paragraph">
<p>mailiqing-pc /root/.jenkins/workspace/mailiqing-increment/b2b</p>
</div>
<div class="paragraph">
<p>docker-engine-1.13.1-1.el7.centos.x86_64.rpm</p>
</div>
<div class="paragraph">
<p>svnserve --daemon --foreground --root /svn/</p>
</div>
<div class="paragraph">
<p><a href="http://196.168.1.33:8080/v2-beta" class="bare">http://196.168.1.33:8080/v2-beta</a></p>
</div>
<div class="paragraph">
<p>8EA989955618FC869A2B</p>
</div>
<div class="paragraph">
<p>44UVu61SzCzuNoxsHuAxqEtoE5G6gy4Td4do7Fyz</p>
</div>
<div class="paragraph">
<p>rancher/net:v0.11.2 rancher/net:holder rancher/scheduler:v0.7.5 rancher/healthcheck:v0.2.3 rancher/metadata:v0.9.1 rancher/dns:v0.14.2 rancher/network-manager:v0.6.6 rancher/agent:v1.2.2 rancher/server:v1.5.5</p>
</div>
<div class="paragraph">
<p>#!/bin/bash</p>
</div>
<div class="paragraph">
<p>for var in $@
do
    echo "$var"
    docker pull $var
    docker tag $var mailiqing.com:5000/$var
    docker push mailiqing.com:5000/$var
    docker rmi mailiqing.com:5000/$var
done</p>
</div>
<div class="paragraph">
<p>#!/bin/bash</p>
</div>
<div class="paragraph">
<p>for var in $@
do
  echo "$var"
  docker pull mailiqing.com:5000/$var
  docker tag mailiqing.com:5000/$var $var
  docker rmi mailiqing.com:5000/$var
done</p>
</div>
<div class="paragraph">
<p>tee /etc/docker/daemon.json &lt;&#8592;'EOF'
{
  "registry-mirrors": ["http://0821f5e0.m.daocloud.io"]
}
EOF</p>
</div>
<div class="paragraph">
<p>systemctl daemon-reload &amp;&amp; systemctl restart docker</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>上传日志文件到hdfs</p>
</li>
<li>
<p>日志预处理,日志点击流
.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>command.1=sh log_click.sh ${HADOOP_PRE} ${FILE_NAME}</p>
</div>
<div class="paragraph">
<p>hadoop fs -rm -r /data/weblog/preprocess/valid_output/2017-05-12</p>
</div>
<div class="paragraph">
<p>hadoop fs -ls /data/weblog/preprocess/valid_output/2017-05-12</p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/apt/sources.list &lt;&lt;_EOF_
deb <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty main restricted universe multiverse
deb <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-security main restricted universe multiverse
deb <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-updates main restricted universe multiverse
deb <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-proposed main restricted universe multiverse
deb <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-backports main restricted universe multiverse
deb-src <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty main restricted universe multiverse
deb-src <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-security main restricted universe multiverse
deb-src <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-updates main restricted universe multiverse
deb-src <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-proposed main restricted universe multiverse
deb-src <a href="http://mirrors.aliyun.com/ubuntu/" class="bare">http://mirrors.aliyun.com/ubuntu/</a> trusty-backports main restricted universe multiverse
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/apt/sources.list &lt;&lt;_EOF_
deb <a href="http://mirrors.aliyun.com/debian" class="bare">http://mirrors.aliyun.com/debian</a> wheezy main contrib non-free
deb-src <a href="http://mirrors.aliyun.com/debian" class="bare">http://mirrors.aliyun.com/debian</a> wheezy main contrib non-free
deb <a href="http://mirrors.aliyun.com/debian" class="bare">http://mirrors.aliyun.com/debian</a> wheezy-updates main contrib non-free
deb-src <a href="http://mirrors.aliyun.com/debian" class="bare">http://mirrors.aliyun.com/debian</a> wheezy-updates main contrib non-free
deb <a href="http://mirrors.aliyun.com/debian-security" class="bare">http://mirrors.aliyun.com/debian-security</a> wheezy/updates main contrib non-free
deb-src <a href="http://mirrors.aliyun.com/debian-security" class="bare">http://mirrors.aliyun.com/debian-security</a> wheezy/updates main contrib non-free
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>docker exec hadoop-master /bin/sh -c 'echo 1'</p>
</div>
<div class="paragraph">
<p>/usr/bin/docker exec hadoop-master /usr/local/hadoop/bin/hadoop jar hadoop-demo-1.0-SNAPSHOT.jar wordcount /wordcount/input /wordcount/output</p>
</div>
<div class="paragraph">
<p>hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-2.7.2-sources.jar org.apache.hadoop.examples.WordCount /wordcount/input /wordcount/output</p>
</div>
<div class="paragraph">
<p>相当于一个yarn集群的客户端
需要在此封装我们的mr程序的相关运行参数
指定jar包,最后提交给yarn</p>
</div>
<div class="paragraph">
<p>将job中配置的相关参数,以及job所用的java类所在的jar包,提交给yarn去运行</p>
</div>
<div class="paragraph">
<p>type</p>
</div>
<div class="paragraph">
<p>运营场景
决策场景</p>
</div>
<div class="paragraph">
<p>调度</p>
</div>
<div class="paragraph">
<p>数据仓库</p>
</div>
<div class="paragraph">
<p>数据建模</p>
</div>
<div class="paragraph">
<p>业务场景接口</p>
</div>
<div class="paragraph">
<p>ImmutableListMultimap&lt;String, ?&gt; cktmp = Multimaps.index((List&lt;ZhAsphaltRepertoryModel&gt;)ckList, multiTypeFunction);
ImmutableListMultimap&lt;String, ?&gt; sctmp = Multimaps.index((List&lt;ZhAsphaltRepertoryModel&gt;)scList, multiTypeFunction);
ImmutableListMultimap&lt;String, ?&gt; dgtmp = Multimaps.index((List&lt;ZhAsphaltRepertoryModel&gt;)dgList, multiTypeFunction);
ImmutableListMultimap&lt;String, ?&gt; pdtmp = Multimaps.index((List&lt;ZhAsphaltRepertoryModel&gt;)pdList, multiTypeFunction);
ImmutableListMultimap&lt;String, ?&gt; kctmp = Multimaps.index((List&lt;ZhAsphaltRepertoryModel&gt;)kcList, multiTypeFunction);</p>
</div>
<div class="literalblock">
<div class="content">
<pre>builder.put("rk", rktmp.asMap());
builder.put("ck", cktmp.asMap());
builder.put("sc", sctmp.asMap());
builder.put("dg", dgtmp.asMap());
builder.put("pd", pdtmp.asMap());
builder.put("kc", kctmp.asMap());</pre>
</div>
</div>
<div class="paragraph">
<p>*id {lable:"varchar(32) NOT NULL"}
reservoir_code {lable:"varchar(32) DEFAULT NULL"}
abbreviation {lable:"varchar(64) DEFAULT NULL"}
reservoir_name {lable:"varchar(256) DEFAULT NULL"}</p>
</div>
<div class="paragraph">
<p>id {lable:"varchar(32) NOT NULL"}
storage_code {lable:"varchar(32) DEFAULT NULL"}
storage_name {lable:"varchar(128) DEFAULT NULL"}
reservoir_code {lable:"varchar(32) DEFAULT NULL"}
storage_capacity {lable:"double(8,0) DEFAULT NULL"}</p>
</div>
<div class="literalblock">
<div class="content">
<pre>SELECT   *,   (SELECT     zra.abbreviation   FROM     zh_reservoir_area zra   WHERE zra.reservoir_code = zar.reservoir_code) AS abbreviation,   (SELECT     zs.storage_capacity   FROM     zh_storage zs   WHERE zs.reservoir_code = zar.reservoir_code     AND zs.storage_code = zar.storage_code GROUP BY zar.reservoir_code) AS storageCapacity FROM   zh_asphalt_repertory zar GROUP BY zar.reservoir_code,   zar.storage_code HAVING 1=1 AND zar.type = '00' ORDER BY abbreviation</pre>
</div>
</div>
<div class="paragraph">
<p>cabal sandbox hc-pkg&#8201;&#8212;&#8201;unregister base</p>
</div>
<div class="paragraph">
<p>SELECT
  tranCat (LEFT(cat_code, LENGTH(cat_code) - 1)) AS category,
  (SELECT
    brand_name
  FROM
    mlq_brand
  WHERE id = brand_id) brand_name,
  (SELECT
    brand_name
  FROM
    mlq_brand
  WHERE id = brand_id) brand_name_noa,
  (SELECT
    msi.shop_name
  FROM
    mlq_shop_info msi
  WHERE msi.id = mg.shop_id) new_seller_nick,
  (SELECT
    msi.shop_name
  FROM
    mlq_shop_info msi
  WHERE msi.id = mg.shop_id) new_seller_nick_noa,
  mg.*
FROM
  mlq_goods mg
WHERE mg.gmt_modify &gt; '2017-05-08 10:53:51'
OR mg.gmt_create &gt; '2017-05-08 10:53:51'</p>
</div>
<div class="paragraph">
<p>mklink D:\env\bin\dot.exe D:\env\graphviz-2.38\release\bin\dot.exe</p>
</div>
<div class="paragraph">
<p>%graphvizdot%\bin;%SBT_HOME%\bin;D:\env\code\bin;C:\msys64\mingw64\bin;d:\env\Ruby22\bin;D:\env\cwRsync\bin;%GOROOT%\bin;C:\ProgramData\Oracle\Java\javapath;%MAVEN_HOME%\bin;%JAVA_HOME%\bin;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;%SYSTEMROOT%\System32\WindowsPowerShell\v1.0\;D:\HashiCorp\Vagrant\bin;C:\Program Files (x86)\MySQL\MySQL Server 5.5\bin</p>
</div>
<div class="paragraph">
<p>sssssssss</p>
</div>
<div class="paragraph">
<p>WebRoot/web/storagemanagement/repertory/asphalt_count_jxc.jsp</p>
</div>
<div class="paragraph">
<p>gem install asciidoctor-diagram</p>
</div>
<div class="paragraph">
<p><a href="http://www.graphviz.org/Download_windows.php" class="bare">http://www.graphviz.org/Download_windows.php</a>
images_dir = parent.attr('plantimgdir')</p>
</div>
<div class="paragraph">
<p>#{parent.attr('plantimgdir')}/</p>
</div>
<div class="paragraph">
<p>#title {label: "大物流仓库库存表关系", size: "20"}</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/plantuml/erd-1.png" alt="erd 1" width="1768" height="723">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/plantuml/diagram-classes4.png" alt="diagram classes4" width="317" height="949">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/plantuml/diagram-classes25.svg" alt="diagram classes25" width="314" height="325">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/plantuml/ditaa-diagram.png" alt="ditaa diagram" width="540" height="280">
</div>
</div>
<div class="paragraph">
<p>SELECT zspl.*
FROM zh_sub_plan_launch zspl
WHERE zspl.plan_code IN
(SELECT plan_code
FROM zh_plan_launch zpl
WHERE zpl.state = '01'
AND zpl.table_date &gt;= ?
AND zpl.table_date &#8656; ?)</p>
</div>
<div class="paragraph">
<p>SELECT *
FROM zh_plan zp阿三地方
WHERE plan_code = ?</p>
</div>
<div class="paragraph">
<p>SELECT * FROM zh_plan zp WHERE plan_code = '20170116101801016'</p>
</div>
<div class="paragraph">
<p>$(this).find('<strong>[name="zhPlanCode"]')
$(this).find('</strong>[name="projectName"]')
$(this).find('<strong>[name="reservoiCode"]')
$(this).find('select[name="goodsCode"]')
$(this).find('</strong>[name="pickMode"]')
$(this).find('<strong>[name="shipmentAddress"]')
$(this).find('</strong>[name="shipmentsCount"]')
$(this).find('<strong>[name="receivingAddress"]')
$(this).find('</strong>[name="receivingUnit"]')
$(this).find('<strong>[name="consignee"]')
$(this).find('</strong>[name="receivingPhone"]')
$(this).find('<strong>[name="memo"]')
$(this).find('</strong>[name="contractCode"]')</p>
</div>
<div class="paragraph">
<p>SELECT plan.plan_name,sub.*,obo.number,sub.shipments_count) - (obo.number AS w_count,gi.goods_name,gi.brand,gi.model,ra.abbreviation FROM zh_plan plan,zh_sub_plan sub LEFT JOIN zh_out_bound_order obo ON sub.zh_plan_code = obo.zh_plan_code LEFT JOIN zh_goods_info gi ON sub.goods_code = gi.goods_code LEFT JOIN zh_reservoir_area ra ON sub.shipment_address = ra.reservoir_code WHERE plan.plan_code = sub.plan_code AND plan.plan_code = '20170116154403004'</p>
</div>
<div class="paragraph">
<p>docker run -it --rm --volume-driver=cifs -v 192.168.137.2/note-hugo:/hugo ansible/centos7-ansible:1.7 /bin/bash</p>
</div>
<div class="paragraph">
<p>服务器升级:
1. Rancher(docker容器管理平台)升级
	1.1 rancher/server:v1.2 升级到 v1.3.1
	1.2 rancher/agent:v1.1.1 升级到 v1.1.3
2. CI/CD 持续集成和持续交付
	1.1 Ansible 批量部署操作
	1.2 Jenkins与Ansible结合实现一键部署重启
Bug修复:
发货申请审批:
	1. 审批中的记录-审批状态显示错误-请改为审批中
	2. 查询条件-执行状态下拉值请和审核状态一致
	3. 直销合同新增审批-先保存之后修改时点提交则审批流名称则变为招标合同
	4. 直销合同发货审批流-赊销大于5000万时少了一步营销中心总经理审批
	5. 招标合同货物审批通过后-审批状态依然显示为待审核-没有变为已审核</p>
</div>
<div class="paragraph">
<p>优点：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>1+光佳团队策划流程很到位</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>①活动人员安排：  尽管时间很紧，人员变动比较频繁，整体掌控很到位</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>②活动提前预热：  通过微信+圈子传播能够在短期内报名数60，很到位</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>③活动效果预估：  直播活动预估3万+，最终5万+</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>④活动成本预估：  赚到钱是硬道理</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>⑤活动互动效果：  笪总+美女主持人穿插广告+互动营销+红包形式的互动，提高了互动性</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>⑥活动效果公布：  通过微信+纸质形式通知效果很好</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>2+笪总团队线下配合很到位</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>①线下接待+让嘉宾没有陌生感+得到尊重感，有共同话题才是硬道理</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>②笪总的主持游刃有余，沥青届的老炮</pre>
</div>
</div>
<div class="paragraph">
<p>改善：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>1+直播体验需要提高：</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>1）直播网络稳定性+系统稳定性要提高，导致直播卡顿</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>反省：① 时间维度不够充裕：</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>中午13点到下午17点，共4个小时，时间比较紧凑，配置的设备比较多，容易影响直播效果的因素太多</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>② 技术人员切入不够早：</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>设备问题包括硬件+软件两方面，需要在启动项目时，尽早切入，以备不时之需，工作要交给擅长的人                       去做</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>2）嘉宾直播气氛需要提高</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>反省：① 房间不够大：</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>需要针对不同级别的嘉宾或者企业要有不同的配置，特别针对500强的企业要做的更加符合企业的气质</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>② 观众需要一定量级：</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>对于传统嘉宾来讲更有气氛，需要有人捧场，需要有人鼓掌，才有分享的激情</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>2+活动数据收集差</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>1）5万9的观众，如何收集起来？目前没有方法，即时有，也不够准确；</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>建议：app作为统一报名入口，但需要开发，需要周期</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>3+直播还能做什么？</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>1）广告营销：直播2小时，可以穿插广告（在直播屏幕上，不同时间段穿插广告）</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>2）延长营销：直播仅仅2个小时，如何能够让2个小时的营销效果时间延长，个人认为可以将直播经典内容沉淀下来</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>可以分段营销，在不同的地点+平台均可以</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>3）直播专场：此次是学术界的直播，后期可以做专场，譬如采购+销售+大客户比如中石化+中海油+京博等等</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>建议：提前准备听众</pre>
</div>
</div>
<div class="paragraph">
<p>优点:
	运营部在人员少,资源少,时间紧的情况下办好一场很精彩的直播.</p>
</div>
<div class="paragraph">
<p>改善:
	直播环境准备:
		1. 电脑
			笔记本和台式机都要准备,做好一比一测试,如果其中一台电脑有问题,可以用另一台电脑做备用
		2. 直播过程中可以插播公司广告,公司宣传片,充分利用直播平台
		3. 需要准备足够多的观众,烘托现场气氛</p>
</div>
<div class="paragraph">
<p>SELECT
  mp_tmp.product_name AS product_name_noa,
  mp_tmp.<strong>,
  mpa_tmp.</strong>
FROM
  (SELECT
    *
  FROM
    mlq_product
  WHERE gmt_modify &gt; '2016-07-22'
  ) mp_tmp,
  (SELECT
    mpa.product_id,
    MAX(
      CASE
        mpa.attr_name
        WHEN '销售地区'
        THEN IFNULL(
          tranAddr (mpa.attr_value, '-'),
          CAST(mpa.attr_value AS CHAR(50))
        )
        ELSE NULL
      END
    ) sale_region,
    MAX(
      CASE
        mpa.attr_name
        WHEN '出库地区'
        THEN IFNULL(
          tranAddr (mpa.attr_value, '-'),
          CAST(mpa.attr_value AS CHAR(50))
        )
        ELSE NULL
      END
    ) repository_region,
    MAX(
      CASE
        mpa.attr_name
        WHEN '出库地区'
        THEN IFNULL(
          tranAddr (mpa.attr_value, '-'),
          CAST(mpa.attr_value AS CHAR(50))
        )
        ELSE NULL
      END
    ) repository_region_noa,
    MAX(
      CASE
        mpa.attr_name
        WHEN '最小起订量'
        THEN mpa.attr_value
        ELSE 0
      END
    ) min_quantity,
    MAX(
      CASE
        mpa.attr_name
        WHEN '库存量'
        THEN mpa.attr_value
        ELSE 0
      END
    ) stock_quantity,
    MAX(
      CASE
        mpa.attr_name
        WHEN '单位'
        THEN mpa.attr_value
        ELSE '吨'
      END
    ) unit,
    MAX(
      CASE
        mpa.attr_name
        WHEN '交货天数'
        THEN mpa.attr_value
        ELSE 7
      END
    ) delivery_day,
    MAX(
      CASE
        mpa.attr_name
        WHEN '包装类型'
        THEN mpa.attr_value
        ELSE '散装'
      END
    ) package_type
  FROM
    mlq_product_attr mpa
  WHERE mpa.product_id IN
    (SELECT
      id
    FROM
      mlq_product
    WHERE gmt_modify &gt; '2016-07-22')
  GROUP BY mpa.product_id) mpa_tmp
WHERE mp_tmp.id = mpa_tmp.product_id</p>
</div>
<div class="paragraph">
<p>大物流服务器重新规划部署:
1. CoreOS 系统安装
2. Docker 环境配置
3. Rancher Client 环境配置
4. nginx 反向代理 搭建
5. 大物流数据迁移
  5.1 Web 数据迁移
  5.2 数据库迁移</p>
</div>
<div class="paragraph">
<p>Mai沥青 PC 端 Bug 修复
大物流 PC 端 Bug 修复</p>
</div>
<div class="paragraph">
<p>docker create --volumes-from rancher-server \
 --name rancher-data rancher/server:1.2</p>
</div>
<div class="paragraph">
<p>docker run -d --volumes-from rancher-data \
  -p 9090:8080 rancher/server:stable</p>
</div>
<div class="paragraph">
<p>jw.name("bool");
jw.beginObject();
jw.name("must");
jw.beginArray();
jw.beginObject();
jw.name("match");
jw.beginObject();
jw.name("cat_code");
jw.value("20150914q0asfEw");
jw.endObject();
jw.endObject();
jw.beginObject();
jw.name("match");
jw.beginObject();
jw.name("goods_status");
jw.value("c");
jw.endObject();
jw.endObject();
jw.endArray();
jw.endObject();</p>
</div>
<div class="paragraph">
<p>docker run -d --name=httpd -p 8088:80 --volume-driver=cifs -v 192.168.137.2/note-hugo/public:/usr/local/apache2/htdocs/ httpd:2.2.32-alpine</p>
</div>
<div class="paragraph">
<p>供应商：&lt;input name="new_seller_nick" type="text" value="${param.new_seller_nick }"/&gt;&lt;/span&gt;
商品名称：&lt;input name="title" type="text" value="${param.title }"/&gt;&lt;/span&gt;
商品编号：&lt;input name="id" type="text"/&gt;&lt;/span&gt;
品牌：&lt;select name="brand_id" id="brand_id"&gt;&lt;/select&gt;&lt;/span&gt;
管理类目：&lt;select name="cat_code" id="first_category"&gt;</p>
</div>
<div class="paragraph">
<p>server {
    listen       9090;</p>
</div>
<div class="literalblock">
<div class="content">
<pre>    error_log /var/log/nginx/rancher-error.log
    access_log /var/log/nginx/rancher-access.log
    location / {
        proxy_redirect          off;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header REMOTE-HOST $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass http://192.168.1.129:9090;
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>docker run -d --volumes-from rancher-data -p 9090:8080 --name rancher-server rancher/server:stable</p>
</div>
<div class="paragraph">
<p>docker run -d -p 192.168.1.129:8080:8080 --name rancher-server rancher/server:stable</p>
</div>
<div class="paragraph">
<p>dishui.io:5000/nginx:stable</p>
</div>
<div class="paragraph">
<p>syslog-address               tcp://192.168.137.20:514</p>
</div>
<div class="paragraph">
<p>cat &gt;&gt; /opt/logio/docker-entrypoint.sh &lt;&lt;EOF
if [ "$2" = 'rsyslogd' ]; then
  rsyslogd -n
fi
EOF</p>
</div>
<div class="paragraph">
<p>cat &gt; /etc/nginx/conf.d/default.conf &lt;&lt;EOF
server {
    listen       80;
    access_log /var/log/nginx/test.log;
    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }
}
EOF</p>
</div>
<div class="paragraph">
<p><a href="http://192.168.1.129:8080/v2-beta/schemas" class="bare">http://192.168.1.129:8080/v2-beta/schemas</a>
9FFE6681FF339A1A747D
m2E45BeYUxzr7FSAeNvhiR4R18hQL1n7nCdNQnqi</p>
</div>
<div class="paragraph">
<p>SYSLOG_SERVER=192.168.137.20
SYSLOG_PORT=514
SYSLOG_PROTO=tcp</p>
</div>
<div class="paragraph">
<p>-e 'SYSLOG_SERVER=192.168.137.20'-e 'SYSLOG_PORT=514'-e 'SYSLOG_PROTO=tcp'</p>
</div>
<div class="paragraph">
<p>$ModLoad imfile
$InputFilePollInterval 10
$WorkDirectory /var/spool/rsyslog
$PrivDropToGroup adm</p>
</div>
<div class="paragraph">
<p>$template BiglogFormatTomcat,"%msg%\n"</p>
</div>
<div class="paragraph">
<p>$InputFileName /apache-tomcat-7.0.62/logs/localhost_access_log.2017-02-21.txt
$InputFileTag access-log
$InputFileStateFile stat-access-log
$InputFileSeverity info
$InputFilePersistStateInterval 25000
$InputRunFileMonitor</p>
</div>
<div class="paragraph">
<p>if $programname == 'access-log' then @192.168.137.20:514;BiglogFormatTomcat
if $programname == 'access-log' then ~</p>
</div>
<div class="paragraph">
<p>FROM wuliu/tomcat:1.0</p>
</div>
<div class="paragraph">
<p>ENV SYSLOG_SERVER 192.168.137.20
ENV SYSLOG_PORT 514
ENV SYSLOG_PROTO tcp</p>
</div>
<div class="paragraph">
<p>COPY ./tomcat.conf /etc/supervisord.conf.d/tomcat.conf
RUN yum -y install epel-release \
       &amp;&amp; yum -y install python-pip \
       &amp;&amp; pip install supervisor-logging \
       &amp;&amp; yum remove epel-release python-pip -y \
       &amp;&amp; yum clean all</p>
</div>
<div class="paragraph">
<p>echo "30 22 * * * . /usr/sbin/logrotate /etc/logrotate.conf" &gt;&gt; /var/spool/cron/root</p>
</div>
<div class="paragraph">
<p>SELECT
  zra.reservoir_code,
  zra.abbreviation,
  zs.storage_code,
  zs.storage_capacity,
  CAST(rk.model70_rk AS CHAR) AS model70_rk,
  CAST(rk.model90_rk AS CHAR) AS model90_rk,
  CAST(ck.model70_ck AS CHAR) AS model70_ck,
  CAST(ck.model90_ck AS CHAR) AS model90_ck,
  CAST(ck.modelIC_ck AS CHAR) AS modelIC_ck,
  CAST(ck.modelID_ck AS CHAR) AS modelID_ck,
  CAST(ck.modelgt_ck AS CHAR) AS modelgt_ck,
  CAST(ck.modelgz_ck AS CHAR) AS modelgz_ck,
  CAST(sc.modelIC_sc AS CHAR) AS modelIC_sc,
  CAST(sc.modelID_sc AS CHAR) AS modelID_sc,
  CAST(sc.modelgt_sc AS CHAR) AS modelgt_sc,
  CAST(sc.modelgz_sc AS CHAR) AS modelgz_sc,
  CAST(kc.model70_kc AS CHAR) AS model70_kc,
  CAST(kc.model90_kc AS CHAR) AS model90_kc,
  CAST(kc.modelIC_kc AS CHAR) AS modelIC_kc,
  CAST(kc.modelID_kc AS CHAR) AS modelID_kc,
  CAST(kc.modelgt_kc AS CHAR) AS modelgt_kc,
  CAST(kc.modelgz_kc AS CHAR) AS modelgz_kc,
  CAST(pd.model70_pd AS CHAR) AS model70_pd,
  CAST(pd.model90_pd AS CHAR) AS model90_pd,
  CAST(pd.modelIC_pd AS CHAR) AS modelIC_pd,
  CAST(pd.modelID_pd AS CHAR) AS modelID_pd,
  CAST(pd.modelgt_pd AS CHAR) AS modelgt_pd,
  pd.modelgz_pd,
  pd.model_yk,
  (SELECT
    ait.temp
  FROM
    zh_asphalt_inventory_table ait,
    zh_goods_info gi
  WHERE ait.tank = zs.storage_code
    AND ait.storage_area = zs.reservoir_code
    AND ait.goods_code = gi.goods_code) AS temp
FROM
  zh_storage zs
  LEFT JOIN zh_reservoir_area zra
    ON zs.reservoir_code = zra.reservoir_code
  LEFT JOIN
    (SELECT
      zar.storage_code,
      zar.reservoir_code,
      zar.goods_model,
      (
        CASE
          WHEN zar.goods_model = '70#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model70_rk,
      (
        CASE
          WHEN zar.goods_model = '90#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model90_rk
    FROM
      zh_asphalt_repertory zar,
      zh_goods_info gi
    WHERE zar.goods_code = gi.goods_code
      AND zar.order_type IN ('00')
      AND zar.type = '00'
    GROUP BY zar.storage_code,
      zar.reservoir_code,
      zar.goods_model) rk
    ON zs.reservoir_code = rk.reservoir_code
    AND zs.storage_code = rk.storage_code
  LEFT JOIN
    (SELECT
      zar.storage_code,
      zar.reservoir_code,
      zar.goods_model,
      (
        CASE
          WHEN zar.goods_model = '70#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model70_ck,
      (
        CASE
          WHEN zar.goods_model = '90#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model90_ck,
      (
        CASE
          WHEN zar.goods_model = 'I-C'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelIC_ck,
      (
        CASE
          WHEN zar.goods_model = 'I-D'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelID_ck,
      (
        CASE
          WHEN zar.goods_model = '高弹'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgt_ck,
      (
        CASE
          WHEN zar.goods_model = '高粘'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgz_ck
    FROM
      zh_asphalt_repertory zar,
      zh_goods_info gi
    WHERE zar.goods_code = gi.goods_code
      AND zar.order_type IN ('01', '02')
      AND zar.type = '00'
    GROUP BY zar.storage_code,
      zar.reservoir_code,
      zar.goods_model) ck
    ON zs.reservoir_code = ck.reservoir_code
    AND zs.storage_code = ck.storage_code
  LEFT JOIN
    (SELECT
      zar.storage_code,
      zar.reservoir_code,
      zar.goods_model,
      (
        CASE
          WHEN zar.goods_model = 'I-C'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelIC_sc,
      (
        CASE
          WHEN zar.goods_model = 'I-D'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelID_sc,
      (
        CASE
          WHEN zar.goods_model = '高弹'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgt_sc,
      (
        CASE
          WHEN zar.goods_model = '高粘'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgz_sc
    FROM
      zh_asphalt_repertory zar,
      zh_goods_info gi
    WHERE zar.goods_code = gi.goods_code
      AND zar.order_type IN ('02')
      AND zar.type = '00'
    GROUP BY zar.storage_code,
      zar.reservoir_code,
      zar.goods_model) sc
    ON zs.reservoir_code = sc.reservoir_code
    AND zs.storage_code = sc.storage_code
  LEFT JOIN
    (SELECT
      zar.storage_code,
      zar.reservoir_code,
      zar.goods_model,
      (
        CASE
          WHEN zar.goods_model = '70#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model70_kc,
      (
        CASE
          WHEN zar.goods_model = '90#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model90_kc,
      (
        CASE
          WHEN zar.goods_model = 'I-C'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelIC_kc,
      (
        CASE
          WHEN zar.goods_model = 'I-D'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelID_kc,
      (
        CASE
          WHEN zar.goods_model = '高弹'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgt_kc,
      (
        CASE
          WHEN zar.goods_model = '高粘'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgz_kc
    FROM
      zh_asphalt_repertory zar,
      zh_goods_info gi
    WHERE zar.goods_code = gi.goods_code
      AND zar.order_type IN ('00', '01', '02')
      AND zar.type = '00'
    GROUP BY zar.storage_code,
      zar.reservoir_code,
      zar.goods_model) kc
    ON zs.reservoir_code = kc.reservoir_code
    AND zs.storage_code = kc.storage_code
  LEFT JOIN
    (SELECT
      zar.storage_code,
      zar.reservoir_code,
      zar.goods_model,
      SUM(zar.goods_count) AS model_yk,
      (
        CASE
          WHEN zar.goods_model = '70#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model70_pd,
      (
        CASE
          WHEN zar.goods_model = '90#'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS model90_pd,
      (
        CASE
          WHEN zar.goods_model = 'I-C'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelIC_pd,
      (
        CASE
          WHEN zar.goods_model = 'I-D'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelID_pd,
      (
        CASE
          WHEN zar.goods_model = '高弹'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgt_pd,
      (
        CASE
          WHEN zar.goods_model = '高粘'
          THEN SUM(zar.goods_count)
          ELSE ''
        END
      ) AS modelgz_pd
    FROM
      zh_asphalt_repertory zar,
      zh_goods_info gi
    WHERE zar.goods_code = gi.goods_code
      AND zar.order_type IN ('05')
      AND zar.type = '00'
    GROUP BY zar.storage_code,
      zar.reservoir_code,
      zar.goods_model) pd
    ON zs.reservoir_code = pd.reservoir_code
    AND zs.storage_code = pd.storage_code
WHERE 1 = 1
GROUP BY zs.storage_code,
  zs.reservoir_code
ORDER BY zra.abbreviation DESC</p>
</div>
<div class="paragraph">
<p>WHERE zs.storage_code = 'TKH-03'</p>
</div>
<div class="paragraph">
<p>00入库单
01出库单
02生产单
03结余调整单
04倒灌单
05盘点单号</p>
</div>
<div class="paragraph">
<p>库区  名称  入库的型号(70 90等)
  储罐 罐号 库容</p>
</div>
<div class="paragraph">
<p>" SELECT"<br>
"  zar.reservoir_code,"<br>
"  zar.storage_code,"<br>
"  zar.goods_model,"<br>
"  zar.order_type"<br>
" FROM"<br>
"  zh_asphalt_repertory zar";</p>
</div>
<div class="paragraph">
<p>SELECT  zar.reservoir_code,  zar.storage_code,  zar.goods_model,  zar.order_typeFROM  zh_asphalt_repertory zar</p>
</div>
<div class="paragraph">
<p>{title:'入库数量（吨）',colspan:2},
{title:'出库数量（吨）',colspan:6},
{title:'生产数量（吨）',colspan:4},
{title:'库存数量（吨）',colspan:6},
{title:'盘点数量（吨）',colspan:6},</p>
</div>
<div class="paragraph">
<p>" SELECT "<br>
"   *"<br>
" FROM"<br>
"   zh_asphalt_repertory zar"<br>
" GROUP BY zar.reservoir_code,zar.storage_code"<br></p>
</div>
<div class="paragraph">
<p>" SELECT *"+
" FROM zh_asphalt_repertory zar"+
" WHERE zar.reservoir_code = '001'"+
" AND zar.storage_code = 'T1003'"</p>
</div>
<div class="paragraph">
<p>{id=18b0cef136694001a0849fcb1cee3a7f, reservoirCode=002, orderNo=20170222-A, orderType=00, occurDate=Wed Feb 22 00:00:00 CST 2017, storageCode=TKH-07, goodsCount=500.0000, goodsCode=077, type=00, createDate=Wed Feb 22 16:03:12 CST 2017, goodsModel=70, goodsBatch=, model70rk=500.0000}</p>
</div>
<div class="paragraph">
<p>SELECT
  *,
  (SELECT
    zra.abbreviation
  FROM
    zh_reservoir_area zra
  WHERE zra.reservoir_code = zar.reservoir_code) AS abbreviation,
  (SELECT
    zs.storage_capacity
  FROM
    zh_storage zs
  WHERE zs.reservoir_code = zar.reservoir_code
    AND zs.storage_code = zar.storage_code) AS storage_capacity
FROM
  zh_asphalt_repertory zar
GROUP BY zar.reservoir_code,
  zar.storage_code</p>
</div>
<div class="paragraph">
<p>HAVING 1=1
AND zar.reservoir_code = '001'
AND zar.storage_code = 'T1003'
AND zar.occur_date = '2017-01-17'
ORDER BY abbreviation</p>
</div>
<div class="paragraph">
<p>LIMIT 0, 10</p>
</div>
<div class="paragraph">
<p>周凯(男) 29岁 洛阳师范-生物技术 本科生 现在北京金兆路华电子商务担任Java开发工程师</p>
</div>
<div class="paragraph">
<p>工作经验:
2013-2014 地点:郑州  OA,ERP系统开发
2015-~    地点:北京   电商系统开发</p>
</div>
<div class="paragraph">
<p>喜欢全栈</p>
</div>
<div class="paragraph">
<p>电商系统开发:
  二次开发系统,搜索模块由Lucene迁移到ElasticSearch
  同步Mysql数据到ElasticSearch
  ElasticSearch权重设计</p>
</div>
<div class="paragraph">
<p>服务器部署:
  CoreOS+Docker
  Rancher
  Jenkins+Ansible+Docker
  实现自动化部署</p>
</div>
<div class="paragraph">
<p>喜欢研究技术
希望通过Leader课程,系统的学习</p>
</div>
<div class="paragraph">
<p>" SELECT zas.category"+
" FROM zh_asphalt_storage zas"+
" GROUP BY zas.category"+
" HAVING zas.category IS NOT NULL"</p>
</div>
<div class="paragraph">
<p>" SELECT *"+
" FROM zh_asphalt_storage zas"+
" WHERE zas.category = '01'"+
" GROUP BY zas.model";</p>
</div>
<div class="literalblock">
<div class="content">
<pre>String categorySql =
        " SELECT *"+
        " FROM zh_asphalt_storage zas"+
        " WHERE zas.category = '01'"+
        " GROUP BY zas.model";</pre>
</div>
</div>
<div class="paragraph">
<p>AsphaltStorageServiceImpl</p>
</div>
<div class="paragraph">
<p>" SELECT "+
"   *,"+
"   zas.instruct_type,"+
"   zas.Net_profit_loss,"+
"   zas.Storage_area,"+
"   DATE_FORMAT(zas.in_date, '%Y-%m-%d') AS dat,"+
"   (SELECT "+
"     SUM(zasc.goods_count) "+
"   FROM"+
"     zh_asphalt_storage_count zasc "+
"   WHERE zasc.asphalt_number = zas.asphalt_number) AS goods_count,"+
"   (SELECT "+
"     zra.abbreviation "+
"   FROM"+
"     zh_reservoir_area zra "+
"   WHERE zra.reservoir_code = zas.Storage_area) AS abbreviation "+
" FROM"+
"   zh_asphalt_storage zas "+
" ORDER BY zas.in_date DESC"</p>
</div>
<div class="paragraph">
<p>SELECT
  Storage_area
FROM
  zh_sr_productin
WHERE 1=1</p>
</div>
<div class="paragraph">
<p>" SELECT"<br>
"  *, DATE_FORMAT(storage_date, '%Y-%m-%d') AS dat2"<br>
" FROM"<br>
"   zh_sr_productin"<br>
" WHERE Storage_area = ?"<br></p>
</div>
<div class="paragraph">
<p>SELECT
 *, DATE_FORMAT(out_date, '%Y-%m-%d') AS dat2
FROM
  zh_material_outbound
WHERE Storage_area = '001'</p>
</div>
<div class="paragraph">
<p>" SELECT"<br>
                "  *, DATE_FORMAT(storage_date, '%Y-%m-%d') AS dat2"<br>
                " FROM"<br>
                "   zh_material_outbound"<br>
                " WHERE Storage_area = ?"</p>
</div>
<div class="paragraph">
<p>" SELECT"+
"   zmo.model,"+
"   zmo.number,"+
"   DATE_FORMAT(zmo.out_date, '%Y-%m-%d') AS dat2,"+
"   (SELECT"+
"     zra.abbreviation"+
"   FROM"+
"     zh_reservoir_area zra"+
"   WHERE zra.reservoir_code = zmo.Storage_area) Storage_area"+
" FROM"+
"   zh_material_outbound zmo"+
" WHERE zmo.Storage_area = ?"</p>
</div>
<div class="paragraph">
<p>SELECT
 zar.reservoir_code,
 zar.storage_code,
 zar.goods_model,
 zar.order_type
FROM
 zh_asphalt_repertory zar
WHERE zar.order_type =
GROUP BY zar.goods_model</p>
</div>
<div class="paragraph">
<p>jquery.bigautocomplete.js</p>
</div>
<div class="paragraph">
<p>echo "public" &gt;&gt; .gitignore &amp;&amp; \
echo "themes/mainroad/static/js/app.js" &gt;&gt; .gitignore &amp;&amp; \
echo "themes/mainroad/static/js/jquery.bigautocomplete.js" &gt;&gt; .gitignore &amp;&amp; \
echo "config.toml" &gt;&gt; .gitignore &amp;&amp; \
echo "content/post/base.adoc" &gt;&gt; .gitignore</p>
</div>
<div class="paragraph">
<p>baseurl = "http://dishui.oschina.io/note-hugo/"</p>
</div>
<div class="paragraph">
<p>version: '2'
services:
  zoo1:
    image: zookeeper
    restart: always
    ports:
      - 2181:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zoo1:2888:3888
07.阿里开源分布式框架dubbo</p>
</div>
<div class="paragraph">
<p>9df8e09ee259
cadc21522a4a
e3eb53c850a3
0ec18fcb5f14
dcfb02a0f0c0
1ae259b410a4
9a0db3e1e5fa
a299de9d8b43
2354e58c407f</p>
</div>
<div class="paragraph">
<p>" SELECT"<br>
"   dat.*,"<br>
"   SUM(dat.rksl) AS count_rk,"<br>
"   SUM(dat.cksl) AS count_ck,"<br>
"   (SELECT"<br>
"     SUM(zar.goods_count)"<br>
"   FROM"<br>
"     zh_asphalt_repertory zar"<br>
"   WHERE dat.goods_code = zar.goods_code"<br>
"     AND TYPE = '01') AS count_kc,"<br>
"   SUM(dat.scsl) AS count_sc,"<br>
"   SUM(dat.pdsl) AS count_pdf"<br>
" FROM"<br>
"   (SELECT"<br>
"     DATE_FORMAT(sp.storage_date, '%Y-%m-%d') AS storage_date,"<br>
"     sp.Storage_area,"<br>
"     sp.reservoir_code,"<br>
"     sp.goods_code,"<br>
"     gi.goods_name,"<br>
"     sp.brand,"<br>
"     sp.model,"<br>
"     sp.specifications,"<br>
"     sp.Inventory_quantity AS rksl,"<br>
"     '' AS cksl,"<br>
"     '' AS scsl,"<br>
"     '' AS pdsl"<br>
"   FROM"<br>
"     zh_sr_productin sp,"<br>
"     zh_goods_info gi"<br>
"   WHERE sp.goods_code = gi.goods_code"<br>
"   UNION"<br>
"   ALL"<br>
"   SELECT"<br>
"     mo.start_date,"<br>
"     mo.Storage_area,"<br>
"     ra.abbreviation,"<br>
"     mo.goods_code,"<br>
"     gi.goods_name,"<br>
"     mo.brand,"<br>
"     mo.model,"<br>
"     mo.specifications,"<br>
"     '',"<br>
"     mo.number,"<br>
"     '',"<br>
"     ''"<br>
"   FROM"<br>
"     zh_material_outbound mo,"<br>
"     zh_goods_info gi,"<br>
"     zh_reservoir_area ra"<br>
"   WHERE mo.Storage_area = ra.reservoir_code"<br>
"     AND mo.goods_code = gi.goods_code"<br>
"   UNION"<br>
"   ALL"<br>
"   SELECT"<br>
"     DATE_FORMAT(zps.start_time, '%Y-%m-%d'),"<br>
"     pp.Storage_area,"<br>
"     pp.reservoir_code,"<br>
"     zps.Name_commodity,"<br>
"     gi.goods_name,"<br>
"     zps.brand,"<br>
"     zps.model,"<br>
"     zps.specifications,"<br>
"     '',"<br>
"     '',"<br>
"     zps.Production_quantity,"<br>
"     ''"<br>
"   FROM"<br>
"     zh_production_subsidiary zps,"<br>
"     zh_goods_info gi,"<br>
"     zh_production_processing pp"<br>
"   WHERE pp.Production_order = zps.production_order"<br>
"     AND zps.goods_code = gi.goods_code"<br>
"   UNION"<br>
"   ALL"<br>
"   SELECT"<br>
"     DATE_FORMAT(ait.<code>data</code>, '%Y-%m-%d'),"<br>
"     ra.abbreviation,"<br>
"     ait.storage_area,"<br>
"     ait.accessories_name,"<br>
"     gi.goods_name,"<br>
"     ait.brand,"<br>
"     ait.model,"<br>
"     ait.specifications,"<br>
"     '',"<br>
"     '',"<br>
"     '',"<br>
"     ait.inventory_number"<br>
"   FROM"<br>
"     zh_additive_inventory_table ait,"<br>
"     zh_goods_info gi,"<br>
"     zh_reservoir_area ra"<br>
"   WHERE ait.storage_area = ra.reservoir_code"<br>
"     AND gi.goods_code = ait.accessories_name) dat"<br>
" WHERE 1 = 1";</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>向 namenode 请求上传文件 /a/sss.txt</p>
</li>
<li>
<p>响应,可以上传</p>
</li>
<li>
<p>rpc 请求上传第一个 block(0-128M), 请求返回 datanode</p>
</li>
<li>
<p>返回 (datanode1,datanode2,datanode3)</p>
</li>
<li>
<p>请求建立 block 传输通道 channel
5.1. 请求建立通道
5.2. 请求建立通道
6.1. 应答成功
6.2. 应答成功</p>
</li>
<li>
<p>请求建立通道</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>考虑因素: 空间/距离</p>
</div>
<div class="paragraph">
<p>上传数据时, datanode 的选择策略
1. 第一个副本先考虑跟 client 离最近的 (同机架)
2. 第二个副本再考虑跨机架挑选一个 datanode, 增加副本的可靠性
3. 第三个副本就在第一个副本同机架另外挑选一台 datanode 存放</p>
</div>
<div class="paragraph">
<p>SELECT
  dat.*,
  SUM(dat.rksl) AS count_rk,
  SUM(dat.cksl) AS count_ck,
  (SELECT
    SUM(zar.goods_count)
  FROM
    zh_asphalt_repertory zar
  WHERE dat.goods_code = zar.goods_code
    AND TYPE = '01') AS count_kc,
  SUM(dat.scsl) AS count_sc,
  SUM(dat.pdsl) AS count_pdf
FROM
  (SELECT
    DATE_FORMAT(sp.storage_date, '%Y-%m-%d') AS storage_date,
    sp.Storage_area,
    sp.reservoir_code,
    sp.goods_code,
    gi.goods_name,
    sp.brand,
    sp.model,
    sp.specifications,
    sp.Inventory_quantity AS rksl,
    '' AS cksl,
    '' AS scsl,
    '' AS pdsl
  FROM
    zh_sr_productin sp,
    zh_goods_info gi
  WHERE sp.goods_code = gi.goods_code
  UNION
  ALL
  SELECT
    mo.start_date,
    mo.Storage_area,
    ra.abbreviation,
    mo.goods_code,
    gi.goods_name,
    mo.brand,
    mo.model,
    mo.specifications,
    '' AS rksl,
    mo.number AS cksl,
    '' AS scsl,
    '' AS pdsl
  FROM
    zh_material_outbound mo,
    zh_goods_info gi,
    zh_reservoir_area ra
  WHERE mo.Storage_area = ra.reservoir_code
    AND mo.goods_code = gi.goods_code
  UNION
  ALL
  SELECT
    DATE_FORMAT(zps.start_time, '%Y-%m-%d'),
    pp.Storage_area,
    pp.reservoir_code,
    zps.Name_commodity,
    gi.goods_name,
    zps.brand,
    zps.model,
    zps.specifications,
    '' AS rksl,
    '' AS cksl,
    zps.Production_quantity AS scsl,
    '' AS pdsl
  FROM
    zh_production_subsidiary zps,
    zh_goods_info gi,
    zh_production_processing pp
  WHERE pp.Production_order = zps.production_order
    AND zps.goods_code = gi.goods_code
  UNION
  ALL
  SELECT
    DATE_FORMAT(ait.<code>data</code>, '%Y-%m-%d'),
    ra.abbreviation,
    ait.storage_area,
    ait.accessories_name,
    gi.goods_name,
    ait.brand,
    ait.model,
    ait.specifications,
    '' AS rksl,
    '' AS cksl,
    '' AS scsl,
    ait.inventory_number AS pdsl
  FROM
    zh_additive_inventory_table ait,
    zh_goods_info gi,
    zh_reservoir_area ra
  WHERE ait.storage_area = ra.reservoir_code
    AND gi.goods_code = ait.accessories_name) dat
WHERE 1 = 1
GROUP BY dat.goods_code
ORDER BY dat.storage_date DESC</p>
</div>
<div class="paragraph">
<p>" SELECT"<br>
"   dat.*,"<br>
"   SUM(dat.rksl) AS count_rk,"<br>
"   SUM(dat.cksl) AS count_ck,"<br>
"   (SELECT"<br>
"     SUM(zar.goods_count)"<br>
"   FROM"<br>
"     zh_asphalt_repertory zar"<br>
"   WHERE dat.goods_code = zar.goods_code"<br>
"     AND TYPE = '01') AS count_kc,"<br>
"   SUM(dat.scsl) AS count_sc,"<br>
"   SUM(dat.pdsl) AS count_pdf"<br>
" FROM"<br>
"   (SELECT"<br>
"     DATE_FORMAT(sp.storage_date, '%Y-%m-%d') AS storage_date,"<br>
"     sp.Storage_area,"<br>
"     sp.reservoir_code,"<br>
"     sp.goods_code,"<br>
"     gi.goods_name,"<br>
"     sp.brand,"<br>
"     sp.model,"<br>
"     sp.specifications,"<br>
"     sp.Inventory_quantity AS rksl,"<br>
"     '' AS cksl,"<br>
"     '' AS scsl,"<br>
"     '' AS pdsl"<br>
"   FROM"<br>
"     zh_sr_productin sp,"<br>
"     zh_goods_info gi"<br>
"   WHERE sp.goods_code = gi.goods_code"<br>
"   UNION"<br>
"   ALL"<br>
"   SELECT"<br>
"     mo.start_date,"<br>
"     ra.abbreviation AS Storage_area,"<br>
"     mo.Storage_area AS reservoir_code,"<br>
"     mo.goods_code,"<br>
"     gi.goods_name,"<br>
"     mo.brand,"<br>
"     mo.model,"<br>
"     mo.specifications,"<br>
"     '' AS rksl,"<br>
"     mo.number AS cksl,"<br>
"     '' AS scsl,"<br>
"     '' AS pdsl"<br>
"   FROM"<br>
"     zh_material_outbound mo,"<br>
"     zh_goods_info gi,"<br>
"     zh_reservoir_area ra"<br>
"   WHERE mo.Storage_area = ra.reservoir_code"<br>
"     AND mo.goods_code = gi.goods_code"<br>
"   UNION"<br>
"   ALL"<br>
"   SELECT"<br>
"     DATE_FORMAT(zps.start_time, '%Y-%m-%d'),"<br>
"     pp.Storage_area,"<br>
"     pp.reservoir_code,"<br>
"     zps.goods_code,"<br>
"     zps.Name_commodity AS goods_name,"<br>
"     zps.brand,"<br>
"     zps.model,"<br>
"     zps.specifications,"<br>
"     '' AS rksl,"<br>
"     '' AS cksl,"<br>
"     zps.Production_quantity AS scsl,"<br>
"     '' AS pdsl"<br>
"   FROM"<br>
"     zh_production_subsidiary zps,"<br>
"     zh_goods_info gi,"<br>
"     zh_production_processing pp"<br>
"   WHERE pp.Production_order = zps.production_order"<br>
"     AND zps.goods_code = gi.goods_code"<br>
"   UNION"<br>
"   ALL"<br>
"   SELECT"<br>
"     DATE_FORMAT(ait.<code>data</code>, '%Y-%m-%d'),"<br>
"     ra.abbreviation,"<br>
"     ait.storage_area,"<br>
"     ait.accessories_name AS goods_code,"<br>
"     gi.goods_name,"<br>
"     ait.brand,"<br>
"     ait.model,"<br>
"     ait.specifications,"<br>
"     '' AS rksl,"<br>
"     '' AS cksl,"<br>
"     '' AS scsl,"<br>
"     ait.inventory_number AS pdsl"<br>
"   FROM"<br>
"     zh_additive_inventory_table ait,"<br>
"     zh_goods_info gi,"<br>
"     zh_reservoir_area ra"<br>
"   WHERE ait.storage_area = ra.reservoir_code"<br>
"     AND gi.goods_code = ait.accessories_name) dat"<br>
" GROUP BY dat.reservoir_code,"<br>
"   dat.goods_code"<br></p>
</div>
<div class="paragraph">
<p>GRANT ALL PRIVILEGES ON <strong>.</strong> TO 'root'@'%' IDENTIFIED BY '111111' WITH GRANT OPTION;
mysql&gt; flush privileges;</p>
</div>
<div class="paragraph">
<p>docker run -it --rm \
  --net=hadoop \
  --volume-driver=cifs \
  -v 192.168.137.2/hadoop:/hadoop \
  --hostname hadoop-master \
  kiwenlau/hadoop:1.0</p>
</div>
<div class="paragraph">
<p>&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
    &lt;value&gt;jdbc:mysql://mysql:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;
    &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;
  &lt;/property&gt;</p>
</div>
<div class="literalblock">
<div class="content">
<pre>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
&lt;/property&gt;</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
  &lt;value&gt;root&lt;/value&gt;
  &lt;description&gt;username to use against metastore database&lt;/description&gt;
&lt;/property&gt;</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
    &lt;value&gt;111111&lt;/value&gt;
    &lt;description&gt;password to use against metastore database&lt;/description&gt;
  &lt;/property&gt;
&lt;/configuration&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>create database shizhan03;</p>
</div>
<div class="paragraph">
<p>use shizhan03;</p>
</div>
<div class="paragraph">
<p>create table t_sz01(id int,name string);</p>
</div>
<div class="paragraph">
<p>drop table t_sz01;</p>
</div>
<div class="paragraph">
<p>create table t_sz01(id int,name string) row format delimited fields terminated by ',';</p>
</div>
<div class="paragraph">
<p>vi /sz.dat</p>
</div>
<div class="paragraph">
<p>1,zhangsan
2,lisi
3,fengjie
4,chunge
5,shizi
6,koukjj</p>
</div>
<div class="paragraph">
<p>hadoop fs -put /sz.dat /user/hive/warehouse/shizhan03.db/t_sz01</p>
</div>
<div class="paragraph">
<p>select * from t_sz01;</p>
</div>
<div class="paragraph">
<p>select count(1) from t_sz01;</p>
</div>
<div class="paragraph">
<p>select id,name from t_sz01 where id&gt;3;</p>
</div>
<div class="paragraph">
<p>show tables;</p>
</div>
<div class="paragraph">
<p>create exte</p>
</div>
<div class="paragraph">
<p>sed -i 's/dishui.oschina.io\/note-hugo/localhost:1313/g' themes/mainroad/static/js/app.js content/post/base.adoc config.toml</p>
</div>
<div class="paragraph">
<p>git checkout&#8201;&#8212;&#8201;themes/mainroad/static/js/app.js content/post/base.adoc config.toml</p>
</div>
<div class="paragraph">
<p>cat &lt;&lt;&lt; 'FLUME_CLASSPATH="/opt/flume/lib"' &gt; flume-env.sh</p>
</div>
<div class="paragraph">
<p>curl <a href="https://raw.githubusercontent.com/burnettk/delete-docker-registry-image/master/delete_docker_registry_image.py" class="bare">https://raw.githubusercontent.com/burnettk/delete-docker-registry-image/master/delete_docker_registry_image.py</a> | sudo tee /opt/bin/delete_docker_registry_image &gt;/dev/null</p>
</div>
<div class="paragraph">
<p>sudo chmod a+x /opt/bin/delete_docker_registry_image</p>
</div>
<div class="paragraph">
<p>export REGISTRY_DATA_DIR=/home/core/registry/docker/registry/v2</p>
</div>
<div class="paragraph">
<p>{
    "server":"0.0.0.0",
    "server_port":8888,
    "local_address": "127.0.0.1",
    "local_port":1080,
    "password":"111111",
    "timeout":300,
    "method":"aes-256-cfb",
    "fast_open": false,
    "workers": 1
}</p>
</div>
<div class="paragraph">
<p>SELECT zspl.*
FROM zh_sub_plan_launch zspl,
zh_send_goods_check zsgc
WHERE zspl.plan_code IN
(SELECT plan_code
FROM zh_plan_launch zpl
WHERE zpl.state = '01'
AND zpl.table_date &gt;= '2017-03-24 14:44:19'
AND zpl.table_date &#8656; '2017-03-24 23:44:25')
AND zspl.project_name = zsgc.project_name
AND zsgc.make_time = '2017-03-24'
AND zsgc.status  = '4'</p>
</div>
<div class="paragraph">
<p>storm jar examples/storm-starter/storm-starter-topologies-0.9.6.jar org.apache.storm.starter.WordCountTopology wordcount</p>
</div>
<div class="paragraph">
<p>2017-03-28_163004
2017-03-28_163014
2017-03-28_163023
2017-03-28_163035
2017-03-28_163042
2017-03-28_163050
2017-03-28_163058
2017-03-28_163734
2017-03-28_163743
2017-03-28_163751
2017-03-28_163757
2017-03-28_163804
2017-03-28_163811</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/src/img/storm/.png" alt=".png">
</div>
</div>
<div class="paragraph">
<p>docker run -d -p 8888:1984 oddrationale/docker-shadowsocks -s 0.0.0.0 -p 1984 -k 111111 -m aes-256-cfb</p>
</div>
<div class="paragraph">
<p>/v2/tutum/influxdb/manifests/0.9</p>
</div>
<div class="paragraph">
<p>SELECT zspl.* FROM zh_sub_plan_launch zspl, zh_send_goods_check zsgc WHERE zspl.plan_code IN (SELECT plan_code FROM zh_plan_launch zpl WHERE zpl.state = '01' AND zpl.table_date &gt;= '2017-03-29 00:35:07' AND zpl.table_date &#8656; '2017-03-29 23:35:14') AND zspl.project_name = zsgc.project_name AND zsgc.make_time = '2017-03-29' AND zspl.goods_code = zsgc.goods_name AND zsgc.status  = '4'</p>
</div>
<div class="paragraph">
<p>hi 陈经理:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>大物流服务器配置(高-中-低),在附件的三个sheet里,请下载查看</pre>
</div>
</div>
<div class="paragraph">
<p>谢谢</p>
</div>
<div class="paragraph">
<p>version: '2'
services:
  registry2:
    image: dishui.io:5000/registry:2.5
    container_name: registry2
    ports:
      - "5000:5000"
    environment:
      REGISTRY_HTTP_TLS_CERTIFICATE: /certs/registry.crt
      REGISTRY_HTTP_TLS_KEY: /certs/registry.key
    volumes:
      - /home/core/registrydata:/var/lib/registry
      - /home/core/registry/certs:/certs</p>
</div>
<div class="paragraph">
<p>2017-04-01_104025
2017-04-01_104135
2017-04-01_104143
2017-04-01_104152
2017-04-01_104159
2017-04-01_104213</p>
</div>
<div class="paragraph">
<p>val lines = List("hello tom hello jerry","hello tom kitty hello hello")</p>
</div>
<div class="paragraph">
<p>lines.flatMap(<em>.split(" ")).map</em>,1.groupBy(<em>._1).map(t &#8658; (t._1,t._2.size)).toList.sortBy(</em>._2)</p>
</div>
<div class="paragraph">
<p>io.dishui.test.construct</p>
</div>
<div class="paragraph">
<p>2017-04-07_145546.png
2017-04-07_145555.png
2017-04-07_145603.png
2017-04-07_145612.png
2017-04-07_145620.png
2017-04-07_145627.png</p>
</div>
<div class="paragraph">
<p>2017-04-07_151513.png
2017-04-07_151523.png</p>
</div>
<div class="paragraph">
<p>bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://master:7077 \
--executor-memory 512M \
--total-executor-cores 1 \
lib/spark-examples-1.5.2-hadoop2.2.0.jar \
10</p>
</div>
<div class="paragraph">
<p>bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode client \
--executor-memory 512M \
--total-executor-cores 1 \
lib/spark-examples-1.5.2-hadoop2.2.0.jar \
10</p>
</div>
<div class="literalblock">
<div class="title">/bin/spark-submit \</div>
<div class="content">
<pre>--class org.apache.spark.examples.SparkPi \
--master spark://master:7077 \
--executor-memory 1g \
--total-executor-cores 2 \
/usr/local/spark-1.5.2/lib/spark-examples-1.5.2-hadoop2.2.0.jar \
10</pre>
</div>
</div>
<div class="paragraph">
<p>bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 1g --total-executor-cores 2 /usr/local/spark-1.5.2/lib/spark-examples-1.5.2-hadoop2.2.0.jar 1</p>
</div>
<div class="paragraph">
<p>cd $SPARK_HOME</p>
</div>
<div class="paragraph">
<p>bin/spark-shell --master spark://master:7077</p>
</div>
<div class="paragraph">
<p>cat &gt; log4j.properties &lt;&lt;_EOF_
# Set everything to be logged to the console
log4j.rootCategory=ERROR, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n</p>
</div>
<div class="paragraph">
<p># Settings to quiet third party logs that are too verbose
log4j.logger.org.spark-project.jetty=WARN
log4j.logger.org.spark-project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR</p>
</div>
<div class="paragraph">
<p># SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>'2017-04-11 00:26:06'
'2017-04-11 23:26:06'</p>
</div>
<div class="paragraph">
<p>SELECT zpl.* FROM zh_plan_launch zpl WHERE zpl.state = '01' AND zpl.table_date &gt;= '2017-04-10 00:26:06' AND zpl.table_date &#8656; '2017-04-10 23:26:06'</p>
</div>
<div class="paragraph">
<p>SELECT zspl.* FROM zh_sub_plan_launch zspl, zh_send_goods_check zsgc WHERE zspl.plan_code IN (SELECT plan_code FROM zh_plan_launch zpl WHERE zpl.state = '01' AND zpl.table_date &gt;= '2017-04-10 00:26:06' AND zpl.table_date &#8656; '2017-04-10 23:26:06') AND zspl.project_name = zsgc.project_name AND zsgc.make_time = '2017-04-10' AND zspl.goods_code = zsgc.goods_name AND zsgc.status  = '4' GROUP BY zspl.reservoir_code</p>
</div>
<div class="paragraph">
<p>SELECT zspl.* FROM zh_sub_plan_launch zspl, zh_send_goods_check zsgc WHERE zspl.plan_code IN (SELECT plan_code FROM zh_plan_launch zpl WHERE zpl.state = '01' AND zpl.table_date &gt;= '2017-04-10 00:26:06' AND zpl.table_date &#8656; '2017-04-10 23:26:06') AND zspl.project_name = zsgc.project_name AND zsgc.make_time = '2017-04-10 AND zspl.goods_code = zsgc.goods_name AND zsgc.status  = '4'</p>
</div>
<div class="paragraph">
<p>SELECT zspl.* FROM zh_sub_plan_launch zspl, zh_send_goods_check zsgc WHERE zspl.plan_code IN (SELECT plan_code FROM zh_plan_launch zpl WHERE zpl.state = '01' AND zpl.table_date &gt;= '2017-04-10 00:26:06' AND zpl.table_date &#8656; '2017-04-10 23:26:06') AND zspl.project_name = zsgc.project_name AND zsgc.make_time = '2017-04-10' AND zspl.goods_code = zsgc.goods_name AND zsgc.status  = '4&#8217;GROUP BY id</p>
</div>
<div class="paragraph">
<p>"SELECT "<br>
"  zpl.* "<br>
"FROM "<br>
"  zh_plan_launch zpl "<br>
"WHERE zpl.state = '01' "<br>
"  AND zpl.plan_code IN "<br>
"  (SELECT "<br>
"    zspl.plan_code "<br>
"  FROM "<br>
"    zh_sub_plan_launch zspl, "<br>
"    zh_send_goods_check zsgc "<br>
"  WHERE zspl.plan_code IN "<br>
"    (SELECT "<br>
"      plan_code "<br>
"    FROM "<br>
"      zh_plan_launch zpl "<br>
"    WHERE zpl.state = '01' "<br>
"      AND zpl.table_date &gt;= ? "<br>
"      AND zpl.table_date &#8656; ?) "<br>
"    AND zspl.project_name = zsgc.project_name "<br>
"    AND zsgc.make_time = ? "<br>
"    AND zspl.goods_code = zsgc.goods_name "<br>
"    AND zsgc.status = '4' "<br>
"    AND zspl.plan_code NOT IN "<br>
"    (SELECT DISTINCT "<br>
"      (zspl.plan_code) "<br>
"    FROM "<br>
"      zh_sub_plan_launch zspl "<br>
"    WHERE zspl.plan_code IN "<br>
"      (SELECT "<br>
"        plan_code "<br>
"      FROM "<br>
"        zh_plan_launch zpl "<br>
"      WHERE zpl.state = '01' "<br>
"        AND zpl.table_date &gt;= ? "<br>
"        AND zpl.table_date &#8656; ?)) "<br>
"  GROUP BY zspl.plan_code) "<br></p>
</div>
<div class="paragraph">
<p>String subPlanLanchSql = "SELECT zspl.* "<br>
        "FROM zh_sub_plan_launch zspl, "<br>
        "zh_send_goods_check zsgc "<br>
        "WHERE zspl.plan_code IN "<br>
        "(SELECT plan_code "<br>
        "FROM zh_plan_launch zpl "<br>
        "WHERE zpl.state = '01' "<br>
        <span class="menuseq"><span class="menu">AND zpl.table_date</span>&#160;&#9656; <span class="menuitem">= ?</span></span><br>
        "AND zpl.table_date &#8656; ?) "<br>
        "AND zspl.project_name = zsgc.project_name "<br>
        "AND zsgc.make_time = ? "+
        "AND zspl.goods_code = zsgc.goods_name "+
        "AND zsgc.status  = '4'"<br>
        "GROUP BY id";
    String difPlanLanchSql = "SELECT "<br>
        "  zpl.* "<br>
        "FROM "<br>
        "  zh_plan_launch zpl "<br>
        "WHERE zpl.state = '01' "<br>
        "  AND zpl.plan_code IN "<br>
        "  (SELECT "<br>
        "    zspl.plan_code "<br>
        "  FROM "<br>
        "    zh_sub_plan_launch zspl, "<br>
        "    zh_send_goods_check zsgc "<br>
        "  WHERE zspl.plan_code IN "<br>
        "    (SELECT "<br>
        "      plan_code "<br>
        "    FROM "<br>
        "      zh_plan_launch zpl "<br>
        "    WHERE zpl.state = '01' "<br>
        "      AND zpl.table_date &gt;= ? "<br>
        "      AND zpl.table_date &#8656; ?) "<br>
        "    AND zspl.project_name = zsgc.project_name "<br>
        "    AND zsgc.make_time = ? "<br>
        "    AND zspl.goods_code = zsgc.goods_name "<br>
        "    AND zsgc.status = '4' "<br>
        "    AND zspl.plan_code IN "<br>
        "    (SELECT DISTINCT "<br>
        "      (zspl.plan_code) "<br>
        "    FROM "<br>
        "      zh_sub_plan_launch zspl "<br>
        "    WHERE zspl.plan_code IN "<br>
        "      (SELECT "<br>
        "        plan_code "<br>
        "      FROM "<br>
        "        zh_plan_launch zpl "<br>
        "      WHERE zpl.state = '01' "<br>
        "        AND zpl.table_date &gt;= ? "<br>
        "        AND zpl.table_date &#8656; ?)) "<br>
        "  GROUP BY zspl.plan_code) ";
    String planLanchSql = "SELECT zpl.* "<br>
        "FROM zh_plan_launch zpl "<br>
        "WHERE zpl.state = '01' "<br>
        <span class="menuseq"><span class="menu">AND zpl.table_date</span>&#160;&#9656; <span class="menuitem">= ?</span></span><br>
        "AND zpl.table_date &#8656; ? ";
    String reservoirCodeSql = subPlanLanchSql + " ,zspl.reservoir_code";</p>
</div>
<div class="literalblock">
<div class="content">
<pre>    Object[] args1 = new Object[]{DateUtil2.getCurDayStart(),DateUtil2.getCurDayEnd(),DateUtil2.getDate()};
    Object[] args2 = new Object[]{DateUtil2.getCurDayStart(),DateUtil2.getCurDayEnd()};
    Object[] args3 = new Object[]{DateUtil2.getCurDayStart(),DateUtil2.getCurDayEnd(),DateUtil2.getDate(),DateUtil2.getCurDayStart(),DateUtil2.getCurDayEnd()};
    List&lt;?&gt; subPlanLanchs = deliveryPlanService.integratePlan(subPlanLanchSql, args1, new SubPlanLaunchModel());
    List&lt;?&gt; diffPlanLanchs = deliveryPlanService.integratePlan(difPlanLanchSql, args3, new PlanLaunchModel());
//    List&lt;?&gt; planLanchs =  deliveryPlanService.integratePlan(planLanchSql, args2, new PlanLaunchModel());
    List&lt;?&gt; reservoirs = deliveryPlanService.integratePlan(reservoirCodeSql, args1,new SubPlanLaunchModel());</pre>
</div>
</div>
<div class="paragraph">
<p>cat &gt; /person.txt &lt;&lt;_EOF_
1,a,23
2,hello,34
3,xxxx,12
<em>EOF</em></p>
</div>
<div class="paragraph">
<p>val rdd1 = sc.textFile("hdfs://master:9000/word/").flatMap(<em>.split(" ")).map</em>, 1</p>
</div>
<div class="paragraph">
<p>scala&gt; sc.textFile("hdfs://master:8020/word/")
res2: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[9] at textFile at &lt;console&gt;:22</p>
</div>
<div class="paragraph">
<p>scala&gt; sc.textFile("hdfs://master:8020/word/").collect
res3: Array[String] = Array(hello tom, hello xixi, hello xxxxooo, hello tom, hello xixi, hello xxxxooo, hello tom, hello xixi, hello xxxxooo)</p>
</div>
<div class="paragraph">
<p>scala&gt; val rdd1 = sc.textFile("hdfs://master:8020/word/").flatMap(_.split(" ")).collect
rdd1: Array[String] = Array(hello, tom, hello, xixi, hello, xxxxooo, hello, tom, hello, xixi, hello, xxxxooo, hello, tom, hello, xixi, hello, xxxxooo)</p>
</div>
<div class="paragraph">
<p>" SELECT "<br>
"   * "<br>
" FROM "<br>
"   (SELECT "<br>
"     *, "<br>
"     DATE_FORMAT(zas.out_date, '%Y-%m-%d') AS dat, "<br>
"     (SELECT "<br>
"       SUM(zasc.goods_count) "<br>
"     FROM "<br>
"       zh_asphalt_storage_count zasc "<br>
"     WHERE zasc.asphalt_number = zas.out_order_no) AS goods_count, "<br>
"     (SELECT "<br>
"       zra.abbreviation "<br>
"     FROM "<br>
"       zh_reservoir_area zra "<br>
"     WHERE zra.reservoir_code = zas.Storage_area) AS abbreviation "<br>
"   FROM "<br>
"     zh_out_bound_order zas "<br>
"   ORDER BY zas.out_date DESC) AS tmp1 "<br>
" GROUP BY tmp1.Storage_area,tmp1.dat "<br>
" HAVING 1 = 1 "</p>
</div>
<div class="paragraph">
<p>" SELECT "<br>
"   *, "<br>
"   (SELECT "<br>
"     SUM(zasc.goods_count) "<br>
"   FROM "<br>
"     zh_asphalt_storage_count zasc "<br>
"   WHERE zasc.asphalt_number = zas.out_order_no) AS goods_count "<br>
" FROM "<br>
"   zh_out_bound_order AS zas "<br>
" WHERE DATE_FORMAT(zas.out_date, '%Y-%m-%d') = '2017-04-13' "<br></p>
</div>
<div class="paragraph">
<p>bin/spark-submit \
--class StreamingWordCount \
--master spark://master:7077 \
/streaming-1.0-SNAPSHOT.jar \
worker \
10010 \
hdfs://master:8020/nc</p>
</div>
<div class="paragraph">
<p>netsh interface portproxy add v4tov4 listenport=3333 connectaddress=192.168.137.15 connectport=6066</p>
</div>
<div class="paragraph">
<p>101.40.208.232:22</p>
</div>
<div class="paragraph">
<p>docker run --name shadow -d -p 80:1984 oddrationale/docker-shadowsocks -s 0.0.0.0 -p 1984 -k 111111 -m aes-256-cfb</p>
</div>
<div class="paragraph">
<p>101.40.208.232
80
111111</p>
</div>
</div>
</div>
<div class="paragraph">
<p>环境:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">版本</th>
<th class="tableblock halign-left valign-top">地址</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hadoop2.6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://pan.baidu.com/s/1nvJkKeH">密码：roxm</a></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf -g 'daemon off;'</p>
</div>
<div class="paragraph">
<p>(function () {
    var params = {};
    //Document对象数据
    if(document) {
        params.domain = document.domain || '';
        params.url = document.URL || '';
        params.title = document.title || '';
        params.referrer = document.referrer || '';
    }
    //Window对象数据
    if(window &amp;&amp; window.screen) {
        params.sh = window.screen.height || 0;
        params.sw = window.screen.width || 0;
        params.cd = window.screen.colorDepth || 0;
    }
    //navigator对象数据
    if(navigator) {
        params.lang = navigator.language || '';
    }
    //解析_maq配置
    if(_maq) {
        for(var i in _maq) {
            switch(_maq[i][0]) {
                case '_setAccount':
                    params.account = _maq[i][1];
                    break;
                default:
                    break;
            }
        }
    }
    //拼接参数串
    var args = '';
    for(var i in params) {
        if(args != '') {
            args += '&amp;';
        }
        args += i + '=' + encodeURIComponent(params[i]);
    }</p>
</div>
<div class="literalblock">
<div class="content">
<pre>    //通过Image对象请求后端脚本
    var img = new Image(1, 1);
    img.src = '192.168.137.15/log.gif?' + args;
})();</pre>
</div>
</div>
<div class="paragraph">
<p>docker pull wurstmeister/kafka</p>
</div>
<div class="paragraph">
<p>if [[ -z "$a" ]]; then
  echo "a"
else
  echo "b"
fi</p>
</div>
<div class="paragraph">
<p>input {
  file {
    path &#8658; "/var/nginx_logs/*.log"
    discover_interval &#8658; 5
    start_position &#8658; "beginning"
  }
}</p>
</div>
<div class="paragraph">
<p>output {
  kafka {
    topic_id &#8658; "tracklog"
    codec &#8658; plain {
      format &#8658; "%{message}"
      charset &#8658; "UTF-8"
    }
    bootstrap_servers &#8658; "kafka:9092,kafka2:9092"
  }
}</p>
</div>
<div class="paragraph">
<p>INSERT INTO zh_asphalt_repertory (id,reservoir_code,storage_code,goods_code,goods_count,goods_batch,order_no,order_type,type,occur_date,goods_model)VALUES('a54a38c44cb4417aa975c3581879e41a','002','TKH-ZHIQU2','003','-4351.72','null','20170422389','03','00','2017-04-22 00:00:00','70#')</p>
</div>
<div class="paragraph">
<p>UPDATE <code>wuliu</code>.<code>zh_contract_info</code> SET <code>execute_state</code> = '01' WHERE <code>contract_code</code> IN('35900000-17-MY0635-0006&#8212;&#8203;03','35900000-17-MY0635-0006&#8212;&#8203;05','35900000-17-MY0635-0006&#8212;&#8203;04');</p>
</div>
<div class="paragraph">
<p>UPDATE
  <code>wuliu</code>.<code>zh_contract_info</code>
SET
  <code>execute_state</code> = '01'
WHERE <code>contract_code</code> IN (
    '35900000-17-MY0635-0006&#8212;&#8203;03',
    '35900000-17-MY0635-0006&#8212;&#8203;05',
    '35900000-17-MY0635-0006&#8212;&#8203;04'
  ) ;</p>
</div>
<div class="paragraph">
<p>SELECT
  *,
  zas.Storage_area,
  zas.project_name,
  DATE_FORMAT(zas.out_date, '%Y-%m-%d') AS dat,
  (SELECT
    SUM(zasc.goods_count)
  FROM
    zh_asphalt_storage_count zasc
  WHERE zasc.asphalt_number = zas.out_order_no) AS goods_count,
  (SELECT
    zra.abbreviation
  FROM
    zh_reservoir_area zra
  WHERE zra.reservoir_code = zas.Storage_area) AS abbreviation
FROM
  zh_out_bound_order zas
WHERE 1 = 1
GROUP BY dat,zas.Storage_area
ORDER BY zas.out_date DESC</p>
</div>
<div class="paragraph">
<p>" SELECT "+
"   zas.Storage_area, "+
"   zas.goods_code, "+
"   zas.model, "+
"   zas.category, "+
"   DATE_FORMAT(zas.out_date, '%Y-%m-%d') AS dat, "+
"   SUMSELECT "+ "     SUM(zasc.goods_count) "+ "   FROM "+ "     zh_asphalt_storage_count zasc "+ "   WHERE zasc.asphalt_number = zas.out_order_no AS goods_count "+
" FROM "+
"   zh_out_bound_order zas "+
" WHERE 1 = 1 "+
" AND DATE_FORMAT(zas.out_date, '%Y-%m-%d') = '2017-03-02' "+
" AND zas.category = '00' "+
" AND zas.Storage_area = '002' "+
" GROUP BY zas.goods_code "</p>
</div>
<div class="paragraph">
<p>hi 陈经理:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>服务器系统
CentOS-7-x86_64-Minimal-1611.iso</p>
</li>
<li>
<p>大物流正式服务器,配置双网卡(内,外网)
大物流测试服务器,配置双网卡(内,外网)
其余的服务器,配置内网网卡
服务器之间走内网通信</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>谢谢</p>
</div>
<div class="paragraph">
<p>echo "4|2016年2月1日,星期一,10:04:14|10.117.45.20|DongKe小雨|法师|女|7|0|588/800000000" &gt; game_logs/1.log</p>
</div>
<div class="paragraph">
<p>echo "4|2016年2月1日,星期一,10:04:16|10.168.8.103|潮流哥|法师|男|9|0|517/800000000" &gt;&gt; game_logs/1.log
echo "4|2016年2月1日,星期一,10:04:16|10.168.8.103|潮流锅|武士|男|9|0|779/800000000" &gt;&gt; game_logs/1.log</p>
</div>
<div class="paragraph">
<p>A&#8592;-] : RequestCreated
deactivate A
[&#8592; A: Done
deactivate A</p>
</div>
<div class="paragraph">
<p>Schedules tasks for multiple types of clusters by acting through a SchedulerBackend.
It can also work with a local setup by using a LocalBackend and setting isLocal to true.
It handles common logic, like determining a scheduling order across jobs, waking up to launch speculative tasks, etc.</p>
</div>
<div class="paragraph">
<p>Clients should first call initialize() and start(), then submit task sets through the
runTasks method.</p>
</div>
<div class="paragraph">
<p>THREADING: SchedulerBackends and task-submitting clients can call this class from multiple
threads, so it needs locks in public API methods to maintain its state. In addition, some
SchedulerBackends synchronize on themselves when they want to send events here, and then
acquire a lock on us, so we need to make sure that we don&#8217;t try to lock the backend while
we are holding a lock on ourselves.</p>
</div>
<div class="paragraph">
<p><a href="http://www.mailiqing.com/program/admin/mlqcategory/admin_goods/goodsList.jsp?menu_id=20150914j018W0M" class="bare">http://www.mailiqing.com/program/admin/mlqcategory/admin_goods/goodsList.jsp?menu_id=20150914j018W0M</a></p>
</div>
<div class="paragraph">
<p>#local
public: <a href="http://maven.aliyun.com/nexus/content/groups/public/#这个maven" class="bare">http://maven.aliyun.com/nexus/content/groups/public/#这个maven</a>
typesafe:http://dl.bintray.com/typesafe/ivy-releases/ , [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly#这个ivy
ivy-sbt-plugin:http://dl.bintray.com/sbt/sbt-plugin-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext]#这个ivy
sonatype-oss-releases</p>
</div>
<div class="paragraph">
<p>sonatype-oss-snapshots</p>
</div>
<div class="paragraph">
<p>进销存报表
采购执行报表
销售执行报表</p>
</div>

		</div>
		
	</article>
	
<div class="mr-author-box clearfix">
	<figure class="mr-author-box-avatar">
		<img alt="dishui avatar" src="/src/img/dishui.png" class="avatar avatar-90 photo" height="90" width="90">
	</figure>
	<div class="mr-author-box-header">
		<span class="mr-author-box-name">About dishui</span>
	</div>
	<div class="mr-author-box-bio">
		辛勤的搬运工!!!
	</div>
</div>

	

	<nav class="mr-post-nav mr-row clearfix" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-prev">
			<a href="/tmp/graphv/" rel="prev"><span>«Previous</span><p></p></a>
		</div>
		
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-next">
			<a href="/tmp/wuliuxiugai/" rel="next"><span>Next»</span><p></p></a>
		</div>
		
	</nav>


	
</div>

<aside class="mr-sidebar" itemscope="itemscope" itemtype="http://schema.org/WPSideBar">
<div class="mr-widget widget_search navbar-wrapper" >
    <div class="search-form">
        <label>
            <span class="screen-reader-text">Search for:</span>
            <input id="lanren" type="text" class="search-field" placeholder="Search..." value="" name="q">
        </label>
        <div id="list-container" class="bdsug" style="height: auto; display: block;">
        </div>
    </div>
    <div id="side-toc" class="entry-content">

    </div>
</div>
</aside>
	</div>
		<div class="mr-copyright-wrap">
			<div class="mr-container mr-container-inner clearfix">
				<p class="mr-copyright">&copy; 2017 零零散散. <a href="https://git.oschina.net/dishui/dishui" target="_blank" rel="nofollow noopener noreferrer">dishui</a>.</p>
			</div>
		</div>
	</div>

<script>
	var navigation = responsiveNav(".menu", {
		navClass: "menu--collapse",
	});
</script>
<script src="/js/asciinema-player.js"></script>
<script data-main="/js/app.js" src="/js/require.js"></script>


</body>
</html>