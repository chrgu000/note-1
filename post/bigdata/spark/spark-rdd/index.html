<!DOCTYPE html>
<html lang="zh-cn">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>spark-rdd</title>
<meta name="description" content=" John Doe&#39;s Personal blog about everything">
<meta name="generator" content="Hugo 0.17" />
<meta property="og:title" content="spark-rdd" />
<meta property="og:description" content="spark rdd1. mapPartitionsWithIndex2. aggregate3. aggregateByKey4. checkpoint5. combineByKey6. countByKey7. filterByRange8. foldByKey9. foreachPartition10. keys valuestmp1. mapPartitionsWithIndexmap是对每个元素操作, mapPartitions是对其中的每个partition操作mapPartitionsWithIndex : 把每个partition中的分区号和对应的值拿出来, 看源码val func = (index: Int, iter: Iterator[(Int)]) =&gt; {iter.toList.map(x =&gt; &#34;[partID:&#34; &#43; index &#43; &#34;, val: &#34; &#43; x &#43; &#34;]&#34;).iterator}val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8,9), 2)rdd1.mapPartitionsWithIndex(func).collect2. aggregatedef func1(index: Int, iter: Iterator[(Int)]) : Iterator[String] = {iter." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/bigdata/spark/spark-rdd/" />


<meta property="og:updated_time" content="2017-04-08T18:42:52&#43;00:00"/>











<link rel="stylesheet" href="/css/google-font.css?family=Open+Sans:400,400italic,700,600" type="text/css" media="all" />

<link rel="stylesheet" href="/css/railscasts.css">
<link rel="stylesheet" href="/css/style.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/custom.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/jquery.bigautocomplete.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/asciinema-player.css" type="text/css" media="all" />
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/fonts/fontawesome-webfont.svg" rel="stylesheet">

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript" src="/js/scripts.js"></script>
<!--[if lt IE 9]>
	<script src="/js/css3-mediaqueries.js"></script>
<![endif]-->

</head>
<body id="mr-mobile" class="home blog mr-right-sb" itemscope="itemscope" itemtype="http://schema.org/WebPage">
	<div class="mr-container mr-container-outer">
		<div class="mr-header-mobile-nav clearfix"></div>
			<header class="mr-header" itemscope="itemscope" itemtype="http://schema.org/WPHeader">
				<div class="mr-container mr-container-inner mr-row clearfix">
					<div class="mr-custom-header clearfix">
						<div class="mr-site-identity">
							<div class="mr-site-logo" role="banner" itemscope="itemscope" itemtype="http://schema.org/Brand">
								<div class="mr-header-text">
									<a class="mr-header-text-link" href="/" title="零零散散" rel="home">
										<h1 class="mr-header-title">零零散散</h1>
										<h2 class="mr-header-tagline">点滴记录</h2>
									</a>
								</div>
							</div>
						</div>
					</div>
				</div>
				<div class="mr-main-nav-wrap">
					<nav class="menu" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
	<ul class="menu__list">
        
            <li class="menu__item"><a class="menu__link" href="/categories/docker">docker</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/hadoop">hadoop</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/scala">scala</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/spark">spark</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/storm">storm</a></li>
        
	</ul>
</nav>
				</div>
			</header>
		<div class="mr-wrapper clearfix">


<div class="mr-content" id="main-content" role="main" itemprop="mainContentOfPage">
	<article class="post">
		<header class="entry-header clearfix">
			<h1 class="entry-title">spark-rdd</h1>
			<p class="mr-meta entry-meta">
				<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
				<time class="entry-meta-date updated" datetime="2017-04-08 18:42:52 &#43;0000 UTC">April 08, 2017</time>
				<span class="entry-meta-categories">
					<svg class="icon icon-category" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
					<a class="meta-categories" href="/categories/spark" rel="category">spark</a></span>
			</p>
		</header>
		<div class="entry-content clearfix">
			
			<div id="toc" class="toc">
<div id="toctitle">spark rdd</div>
<ul class="sectlevel1">
<li><a href="#_mappartitionswithindex">1. mapPartitionsWithIndex</a></li>
<li><a href="#_aggregate">2. aggregate</a></li>
<li><a href="#_aggregatebykey">3. aggregateByKey</a></li>
<li><a href="#_checkpoint">4. checkpoint</a></li>
<li><a href="#_combinebykey">5. combineByKey</a></li>
<li><a href="#_countbykey">6. countByKey</a></li>
<li><a href="#_filterbyrange">7. filterByRange</a></li>
<li><a href="#_foldbykey">8. foldByKey</a></li>
<li><a href="#_foreachpartition">9. foreachPartition</a></li>
<li><a href="#_keys_values">10. keys values</a></li>
<li><a href="#_tmp">tmp</a></li>
</ul>
</div>
<div class="sect1">
<h2 id="_mappartitionswithindex">1. mapPartitionsWithIndex</h2>
<div class="sectionbody">
<asciinema-player src="/src/records/spark/2017-04-10.json" cols="95" rows="22" speed="2"></asciinema-player>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>map是对每个元素操作, mapPartitions是对其中的每个partition操作

mapPartitionsWithIndex : 把每个partition中的分区号和对应的值拿出来, 看源码
val func = (index: Int, iter: Iterator[(Int)]) =&gt; {
  iter.toList.map(x =&gt; "[partID:" +  index + ", val: " + x + "]").iterator
}
val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8,9), 2)
rdd1.mapPartitionsWithIndex(func).collect</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_aggregate">2. aggregate</h2>
<div class="sectionbody">
<asciinema-player src="/src/records/spark/aggregate.json" cols="95" rows="22" speed="2"></asciinema-player>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>def func1(index: Int, iter: Iterator[(Int)]) : Iterator[String] = {
  iter.toList.map(x =&gt; "[partID:" +  index + ", val: " + x + "]").iterator
}
val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8,9), 2)
rdd1.mapPartitionsWithIndex(func1).collect
###是action操作, 第一个参数是初始值, 二:是2个函数[每个函数都是2个参数(第一个参数:先对个个分区进行合并, 第二个:对个个分区合并后的结果再进行合并), 输出一个参数]
###0 + (0+1+2+3+4   +   0+5+6+7+8+9)
rdd1.aggregate(0)(_+_, _+_)
rdd1.aggregate(0)(math.max(_, _), _ + _)
###5和1比, 得5再和234比得5 --&gt; 5和6789比,得9 --&gt; 5 + (5+9)
rdd1.aggregate(5)(math.max(_, _), _ + _)


val rdd2 = sc.parallelize(List("a","b","c","d","e","f"),2)
def func2(index: Int, iter: Iterator[(String)]) : Iterator[String] = {
  iter.toList.map(x =&gt; "[partID:" +  index + ", val: " + x + "]").iterator
}
rdd2.aggregate("")(_ + _, _ + _)
rdd2.aggregate("=")(_ + _, _ + _)

val rdd3 = sc.parallelize(List("12","23","345","4567"),2)
rdd3.aggregate("")((x,y) =&gt; math.max(x.length, y.length).toString, (x,y) =&gt; x + y)

val rdd4 = sc.parallelize(List("12","23","345",""),2)
rdd4.aggregate("")((x,y) =&gt; math.min(x.length, y.length).toString, (x,y) =&gt; x + y)

val rdd5 = sc.parallelize(List("12","23","","345"),2)
rdd5.aggregate("")((x,y) =&gt; math.min(x.length, y.length).toString, (x,y) =&gt; x + y)</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_aggregatebykey">3. aggregateByKey</h2>
<div class="sectionbody">
<asciinema-player src="/src/records/spark/aggregateByKey.json" cols="95" rows="22" speed="2"></asciinema-player>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>val pairRDD = sc.parallelize(List( ("cat",2), ("cat", 5), ("mouse", 4),("cat", 12), ("dog", 12), ("mouse", 2)), 2)
def func2(index: Int, iter: Iterator[(String, Int)]) : Iterator[String] = {
  iter.toList.map(x =&gt; "[partID:" +  index + ", val: " + x + "]").iterator
}
pairRDD.mapPartitionsWithIndex(func2).collect
pairRDD.aggregateByKey(0)(math.max(_, _), _ + _).collect
pairRDD.aggregateByKey(100)(math.max(_, _), _ + _).collect</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_checkpoint">4. checkpoint</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sc.setCheckpointDir("hdfs://node-1.itcast.cn:9000/ck")
val rdd = sc.textFile("hdfs://node-1.itcast.cn:9000/wc").flatMap(_.split(" ")).map((_, 1)).reduceByKey(_+_)
rdd.checkpoint
rdd.isCheckpointed
rdd.count
rdd.isCheckpointed
rdd.getCheckpointFile

coalesce, repartition
val rdd1 = sc.parallelize(1 to 10, 10)
val rdd2 = rdd1.coalesce(2, false)
rdd2.partitions.length

collectAsMap : Map(b -&gt; 2, a -&gt; 1)
val rdd = sc.parallelize(List(("a", 1), ("b", 2)))
rdd.collectAsMap</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_combinebykey">5. combineByKey</h2>
<div class="sectionbody">
<asciinema-player src="/src/records/spark/combineByKey.json" cols="95" rows="22" speed="2"></asciinema-player>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>和reduceByKey是相同的效果
###第一个参数x:原封不动取出来, 第二个参数:是函数, 局部运算, 第三个:是函数, 对局部运算后的结果再做运算
###每个分区中每个key中value中的第一个值, (hello,1)(hello,1)(good,1)--&gt;(hello(1,1),good(1))--&gt;x就相当于hello的第一个1, good中的1



val rdd1 = sc.textFile("hdfs://master:9000/wordcount/input/").flatMap(_.split(" ")).map((_, 1))
val rdd2 = rdd1.combineByKey(x =&gt; x, (a: Int, b: Int) =&gt; a + b, (m: Int, n: Int) =&gt; m + n)
rdd1.collect
rdd2.collect

###当input下有3个文件时(有3个block块, 不是有3个文件就有3个block, ), 每个会多加3个10
val rdd3 = rdd1.combineByKey(x =&gt; x + 10, (a: Int, b: Int) =&gt; a + b, (m: Int, n: Int) =&gt; m + n)
rdd3.collect


val rdd4 = sc.parallelize(List("dog","cat","gnu","salmon","rabbit","turkey","wolf","bear","bee"), 3)
val rdd5 = sc.parallelize(List(1,1,2,2,2,1,2,2,2), 3)

val rdd7 = rdd6.combineByKey(List(_), (x: List[String], y: String) =&gt; x :+ y, (m: List[String], n: List[String]) =&gt; m ++ n)</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_countbykey">6. countByKey</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>val rdd1 = sc.parallelize(List(("a", 1), ("b", 2), ("b", 2), ("c", 2), ("c", 1)))
rdd1.countByKey
rdd1.countByValue</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_filterbyrange">7. filterByRange</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>val rdd1 = sc.parallelize(List(("e", 5), ("c", 3), ("d", 4), ("c", 2), ("a", 1)))
val rdd2 = rdd1.filterByRange("b", "d")
rdd2.collect

flatMapValues  :  Array((a,1), (a,2), (b,3), (b,4))
val rdd3 = sc.parallelize(List(("a", "1 2"), ("b", "3 4")))
val rdd4 = rdd3.flatMapValues(_.split(" "))
rdd4.collect</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_foldbykey">8. foldByKey</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>val rdd1 = sc.parallelize(List("dog", "wolf", "cat", "bear"), 2)
val rdd2 = rdd1.map(x =&gt; (x.length, x))
val rdd3 = rdd2.foldByKey("")(_+_)

val rdd = sc.textFile("hdfs://node-1.itcast.cn:9000/wc").flatMap(_.split(" ")).map((_, 1))
rdd.foldByKey(0)(_+_)</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_foreachpartition">9. foreachPartition</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>val rdd1 = sc.parallelize(List(1, 2, 3, 4, 5, 6, 7, 8, 9), 3)
rdd1.foreachPartition(x =&gt; println(x.reduce(_ + _)))

keyBy : 以传入的参数做key
val rdd1 = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"), 3)
val rdd2 = rdd1.keyBy(_.length)
rdd2.collect</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_keys_values">10. keys values</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>val rdd1 = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther", "eagle"), 2)
val rdd2 = rdd1.map(x =&gt; (x.length, x))
rdd2.keys.collect
rdd2.values.collect</code></pre>
</div>
</div>
</div>
</div>
<h1 id="_tmp" class="sect0">tmp</h1>
<div class="listingblock">
<div class="content">
<pre>ssh root@196.168.1.34

docker exec -it spark-master /bin/bash

cd $SPARK_HOME \
&amp;&amp; bin/spark-shell --master spark://master:7077</pre>
</div>
</div>
<div class="paragraph">
<p>(1,(CompactBuffer(b, b),CompactBuffer(c, c))),
(3,(CompactBuffer(b),CompactBuffer(c))),
(2,(CompactBuffer(b),CompactBuffer(c)))</p>
</div>

		</div>
		
	</article>
	
<div class="mr-author-box clearfix">
	<figure class="mr-author-box-avatar">
		<img alt="dishui avatar" src="/src/img/dishui.png" class="avatar avatar-90 photo" height="90" width="90">
	</figure>
	<div class="mr-author-box-header">
		<span class="mr-author-box-name">About dishui</span>
	</div>
	<div class="mr-author-box-bio">
		辛勤的搬运工!!!
	</div>
</div>

	

	<nav class="mr-post-nav mr-row clearfix" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-prev">
			<a href="/post/bigdata/spark/spark-rdd-api/" rel="prev"><span>«Previous</span><p>Zhen He spark rdd api</p></a>
		</div>
		
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-next">
			<a href="/post/bigdata/spark/spark-%E5%9F%BA%E7%A1%80/" rel="next"><span>Next»</span><p>spark-基础</p></a>
		</div>
		
	</nav>


	
</div>

<aside class="mr-sidebar" itemscope="itemscope" itemtype="http://schema.org/WPSideBar">
<div class="mr-widget widget_search navbar-wrapper" >
    <form class="search-form" role="search" >
        <label>
            <span class="screen-reader-text">Search for:</span>
            <input id="lanren" type="search" class="search-field" placeholder="Search..." value="" name="q">
        </label>
        <div id="list-container" class="bdsug" style="height: auto; display: block;">
        </div>
    </form>
    <div id="side-toc" class="entry-content">
    
    </div>
</div>
</aside>
	</div>
		<div class="mr-copyright-wrap">
			<div class="mr-container mr-container-inner clearfix">
				<p class="mr-copyright">&copy; 2017 零零散散. <a href="https://git.oschina.net/dishui/dishui" target="_blank" rel="nofollow noopener noreferrer">dishui</a>.</p>
			</div>
		</div>
	</div>

<script>
	var navigation = responsiveNav(".menu", {
		navClass: "menu--collapse",
	});
</script>
<script src="/js/asciinema-player.js"></script>
<script data-main="/js/app.js" src="/js/require.js"></script>


</body>
</html>