#! /bin/bash
# set -x

BIN_HOME="$(cd "`dirname "$0"`"; pwd)"
source $BIN_HOME/env.sh

# 参数截取  先转数组然后截取
OLD_IFS="$IFS"
IFS=" "
ARGS=($@)
IFS="$OLD_IFS"
COUNT=${#ARGS[@]}
# echo ${ARGS[@]:2:$COUNT}

function usage(){
  if [[ "$@" = *--help ]] || [[ "$@" = *-h ]] || [[ "$#" = 0 ]] || [[ "$#" < 3 ]]; then
    pattern="Usage:\n"
    pattern+=" run-spark jar class\n"
    pattern+=" run-spark jar lib_dir class"
    echo -e $pattern
    exit 1
  fi
}

function nolib(){
  echo "$SPARK_HOME/bin/spark-submit --class ${ARGS[@]:1:$COUNT} $1"
  exec $SPARK_HOME/bin/spark-submit --class ${ARGS[@]:2:$COUNT} $1
}

function withlib(){
  CP_ENV=
  # $2 不为空并且为目录
  if [ "$2" != "$LIB_HOME" ] && [ -d $2 ]; then
    LIB_HOME="`pwd`/$2"
    JARS=`find $LIB_HOME -name "*.jar"`
    for JAR in $JARS
    do
      if [ "$CP_ENV" = "" ];then
        CP_ENV=$JAR
      else
        CP_ENV=$CP_ENV,$JAR
      fi
    done
  fi

  echo "$SPARK_HOME/bin/spark-submit --jars $CP_ENV --class ${ARGS[@]:2:$COUNT}"
  exec $SPARK_HOME/bin/spark-submit --jars $CP_ENV --class ${ARGS[@]:2:$COUNT} $1
}

case $COUNT in
  (2)
  echo "=== Start Spark! ==="
  nolib $@
  ;;
#
  (3)
  echo "=== Start Spark! ==="
  withlib $@
  ;;
#
  (stop)
  echo "=== Stop Spark! ==="
  stop
  ;;
#
  (log)
  echo "=== Log Spark! ==="
  tail -f "$LOG_HOME/`hostname`-spark.log"
  ;;
#
  (*)
  usage
  ;;
esac