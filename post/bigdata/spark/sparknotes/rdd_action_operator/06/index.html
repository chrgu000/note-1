<!DOCTYPE html>
<html lang="zh-cn">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title></title>
<meta name="description" content=" John Doe&#39;s Personal blog about everything">
<meta name="generator" content="Hugo 0.17" />
<meta property="og:title" content="" />
<meta property="og:description" content="saveAsHadoopFile、saveAsHadoopDataset saveAsHadoopFile def saveAsHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[_, ]], codec: Class[ &lt;: CompressionCodec]): Unit
def saveAsHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[_, ]], conf: JobConf = …, codec: Option[Class[ &lt;: CompressionCodec]] = None): Unit
saveAsHadoopFile是讲RDD存储在HDFS上的文件中，支持老版本Hadoop API。
每个分区输出一个文件。
var rdd1 = sc.makeRDD(Array((&quot;A&quot;,2),(&quot;A&quot;,1),(&quot;B&quot;,6),(&quot;B&quot;,3),(&quot;B&quot;,7))) import org.apache.hadoop.mapred.TextOutputFormat import org.apache.hadoop.io.Text import org.apache.hadoop.io.IntWritable rdd1.saveAsHadoopFile(&quot;/tmp/lxw1234.com/&quot;,classOf[Text],classOf[IntWritable],classOf[TextOutputFormat[Text,IntWritable]]) rdd1.saveAsHadoopFile(&quot;/tmp/lxw1234.com/&quot;,classOf[Text],classOf[IntWritable],classOf[TextOutputFormat[Text,IntWritable]], classOf[com.hadoop.compression.lzo.LzopCodec])  saveAsHadoopDataset def saveAsHadoopDataset(conf: JobConf): Unit
saveAsHadoopDataset用于将RDD保存到除了HDFS的其他存储中，比如HBase。
在JobConf中，通常需要关注或者设置五个参数：
 文件的保存路劲 key值的class类型 value值的class类型 RDD的输出格式（OutputFormat） 压缩的相关参数  使用saveAsHadoopDataset将RDD保存到HDFS中" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/bigdata/spark/sparknotes/rdd_action_operator/06/" />














<link rel="stylesheet" href="/css/google-font.css?family=Open+Sans:400,400italic,700,600" type="text/css" media="all" />

<link rel="stylesheet" href="/css/railscasts.css">
<link rel="stylesheet" href="/css/style.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/custom.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/jquery.bigautocomplete.css" type="text/css" media="all" />
<link rel="stylesheet" href="/css/asciinema-player.css" type="text/css" media="all" />
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/fonts/fontawesome-webfont.svg" rel="stylesheet">

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript" src="/js/scripts.js"></script>
<!--[if lt IE 9]>
	<script src="/js/css3-mediaqueries.js"></script>
<![endif]-->

</head>
<body id="mr-mobile" class="home blog mr-right-sb" itemscope="itemscope" itemtype="http://schema.org/WebPage">
	<div class="mr-container mr-container-outer">
		<div class="mr-header-mobile-nav clearfix"></div>
			<header class="mr-header" itemscope="itemscope" itemtype="http://schema.org/WPHeader">
				<div class="mr-container mr-container-inner mr-row clearfix">
					<div class="mr-custom-header clearfix">
						<div class="mr-site-identity">
							<div class="mr-site-logo" role="banner" itemscope="itemscope" itemtype="http://schema.org/Brand">
								<div class="mr-header-text">
									<a class="mr-header-text-link" href="/" title="零零碎碎" rel="home">
										<h1 class="mr-header-title">零零碎碎</h1>
										<h2 class="mr-header-tagline">点滴记录</h2>
									</a>
								</div>
							</div>
						</div>
					</div>
				</div>
				<div class="mr-main-nav-wrap">
					<nav class="menu" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
	<ul class="menu__list">
        
            <li class="menu__item"><a class="menu__link" href="/categories/docker">docker</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/hadoop">hadoop</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/scala">scala</a></li>
        
            <li class="menu__item"><a class="menu__link" href="/categories/spark">spark</a></li>
        
	</ul>
</nav>
				</div>
			</header>
		<div class="mr-wrapper clearfix">


<div class="mr-content" id="main-content" role="main" itemprop="mainContentOfPage">
	<article class="post">
		<header class="entry-header clearfix">
			<h1 class="entry-title"></h1>
			<p class="mr-meta entry-meta">
				<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
				<time class="entry-meta-date updated" datetime="0001-01-01 00:00:00 &#43;0000 UTC">January 01, 0001</time>
			</p>
		</header>
		<div class="entry-content clearfix">
			
			

<h2 id="saveashadoopfile-saveashadoopdataset">saveAsHadoopFile、saveAsHadoopDataset</h2>

<h3 id="saveashadoopfile">saveAsHadoopFile</h3>

<p>def saveAsHadoopFile(path: String, keyClass: Class[<em>], valueClass: Class[</em>], outputFormatClass: Class[_ &lt;: OutputFormat[_, <em>]], codec: Class[</em> &lt;: CompressionCodec]): Unit</p>

<p>def saveAsHadoopFile(path: String, keyClass: Class[<em>], valueClass: Class[</em>], outputFormatClass: Class[_ &lt;: OutputFormat[_, <em>]], conf: JobConf = …, codec: Option[Class[</em> &lt;: CompressionCodec]] = None): Unit</p>

<p>saveAsHadoopFile是讲RDD存储在HDFS上的文件中，支持老版本Hadoop API。</p>

<p>每个分区输出一个文件。</p>

<pre><code>var rdd1 = sc.makeRDD(Array((&quot;A&quot;,2),(&quot;A&quot;,1),(&quot;B&quot;,6),(&quot;B&quot;,3),(&quot;B&quot;,7)))
 
import org.apache.hadoop.mapred.TextOutputFormat
import org.apache.hadoop.io.Text
import org.apache.hadoop.io.IntWritable
 
rdd1.saveAsHadoopFile(&quot;/tmp/lxw1234.com/&quot;,classOf[Text],classOf[IntWritable],classOf[TextOutputFormat[Text,IntWritable]])
 
rdd1.saveAsHadoopFile(&quot;/tmp/lxw1234.com/&quot;,classOf[Text],classOf[IntWritable],classOf[TextOutputFormat[Text,IntWritable]],                     classOf[com.hadoop.compression.lzo.LzopCodec])
</code></pre>

<h3 id="saveashadoopdataset">saveAsHadoopDataset</h3>

<p>def saveAsHadoopDataset(conf: JobConf): Unit</p>

<p>saveAsHadoopDataset用于将RDD保存到除了HDFS的其他存储中，比如HBase。</p>

<p>在JobConf中，通常需要关注或者设置五个参数：</p>

<ul>
<li>文件的保存路劲</li>
<li>key值的class类型</li>
<li>value值的class类型</li>
<li>RDD的输出格式（OutputFormat）</li>
<li>压缩的相关参数</li>
</ul>

<p>使用saveAsHadoopDataset将RDD保存到HDFS中</p>

<pre><code>import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import SparkContext._
import org.apache.hadoop.mapred.TextOutputFormat
import org.apache.hadoop.io.Text
import org.apache.hadoop.io.IntWritable
import org.apache.hadoop.mapred.JobConf
 
 
 
var rdd1 = sc.makeRDD(Array((&quot;A&quot;,2),(&quot;A&quot;,1),(&quot;B&quot;,6),(&quot;B&quot;,3),(&quot;B&quot;,7)))
var jobConf = new JobConf()
jobConf.setOutputFormat(classOf[TextOutputFormat[Text,IntWritable]])
jobConf.setOutputKeyClass(classOf[Text])
jobConf.setOutputValueClass(classOf[IntWritable])
jobConf.set(&quot;mapred.output.dir&quot;,&quot;/tmp/lxw1234/&quot;)
rdd1.saveAsHadoopDataset(jobConf)
 
结果：
hadoop fs -cat /tmp/lxw1234/part-00000
A       2
A       1
hadoop fs -cat /tmp/lxw1234/part-00001
B       6
B       3
B       7
</code></pre>

<p>保存数据到HBASE</p>

<p>HBase建表：</p>

<p>create ‘lxw1234′,{NAME =&gt; ‘f1′,VERSIONS =&gt; 1},{NAME =&gt; ‘f2′,VERSIONS =&gt; 1},{NAME =&gt; ‘f3′,VERSIONS =&gt; 1}</p>

<pre><code>import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import SparkContext._
import org.apache.hadoop.mapred.TextOutputFormat
import org.apache.hadoop.io.Text
import org.apache.hadoop.io.IntWritable
import org.apache.hadoop.mapred.JobConf
import org.apache.hadoop.hbase.HBaseConfiguration
import org.apache.hadoop.hbase.mapred.TableOutputFormat
import org.apache.hadoop.hbase.client.Put
import org.apache.hadoop.hbase.util.Bytes
import org.apache.hadoop.hbase.io.ImmutableBytesWritable
 
var conf = HBaseConfiguration.create()
    var jobConf = new JobConf(conf)
    jobConf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;zkNode1,zkNode2,zkNode3&quot;)
    jobConf.set(&quot;zookeeper.znode.parent&quot;,&quot;/hbase&quot;)
    jobConf.set(TableOutputFormat.OUTPUT_TABLE,&quot;lxw1234&quot;)
    jobConf.setOutputFormat(classOf[TableOutputFormat])
    
    var rdd1 = sc.makeRDD(Array((&quot;A&quot;,2),(&quot;B&quot;,6),(&quot;C&quot;,7)))
    rdd1.map(x =&gt; 
      {
        var put = new Put(Bytes.toBytes(x._1))
        put.add(Bytes.toBytes(&quot;f1&quot;), Bytes.toBytes(&quot;c1&quot;), Bytes.toBytes(x._2))
        (new ImmutableBytesWritable,put)
      }
    ).saveAsHadoopDataset(jobConf)
 
##结果：
hbase(main):005:0&gt; scan 'lxw1234'
ROW     COLUMN+CELL                                                                                                
 A       column=f1:c1, timestamp=1436504941187, value=\x00\x00\x00\x02                                              
 B       column=f1:c1, timestamp=1436504941187, value=\x00\x00\x00\x06                                              
 C       column=f1:c1, timestamp=1436504941187, value=\x00\x00\x00\x07                                              
3 row(s) in 0.0550 seconds
</code></pre>

<p>保存到HBase，运行时候需要在SPARK_CALSSPATH中加入相关的jar包</p>

		</div>
		
	</article>
	
<div class="mr-author-box clearfix">
	<figure class="mr-author-box-avatar">
		<img alt="dishui avatar" src="/src/img/dishui.png" class="avatar avatar-90 photo" height="90" width="90">
	</figure>
	<div class="mr-author-box-header">
		<span class="mr-author-box-name">About dishui</span>
	</div>
	<div class="mr-author-box-bio">
		辛勤的搬运工!!!
	</div>
</div>

	

	<nav class="mr-post-nav mr-row clearfix" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-prev">
			<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/05/" rel="prev"><span>«Previous</span><p></p></a>
		</div>
		
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-next">
			<a href="/post/bigdata/spark/sparknotes/rdd_action_operator/07/" rel="next"><span>Next»</span><p></p></a>
		</div>
		
	</nav>


	
</div>

<aside class="mr-sidebar" itemscope="itemscope" itemtype="http://schema.org/WPSideBar">
<div class="mr-widget widget_search navbar-wrapper" >
    <div class="search-form">
        <label>
            <span class="screen-reader-text">Search for:</span>
            <input id="lanren" type="text" class="search-field" placeholder="Search..." value="" name="q">
        </label>
        <div id="list-container" class="bdsug" style="height: auto; display: block;">
        </div>
    </div>
    <div id="side-toc" class="entry-content">

    </div>
</div>
</aside>
	</div>
		<div class="mr-copyright-wrap">
			<div class="mr-container mr-container-inner clearfix">
				<p class="mr-copyright">&copy; 2018 零零碎碎. <a href="https://git.oschina.net/dishui/dishui" target="_blank" rel="nofollow noopener noreferrer">dishui</a>.</p>
			</div>
		</div>
	</div>

<script>
	var navigation = responsiveNav(".menu", {
		navClass: "menu--collapse",
	});
</script>
<script src="/js/asciinema-player.js"></script>
<script data-main="/js/app.js" src="/js/require.js"></script>


</body>
</html>