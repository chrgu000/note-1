a1.sources = r1
a1.channels = c1
a1.sinks = k1

a1.sources.r1.type = avro
a1.sources.r1.channels = c1
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = 3333
a1.sources.r1.fileHeader = true
a1.sources.r1.basenameHeader = true
a1.sources.r1.basenameHeaderKey = basename
a1.sources.r1.interceptors = i1 i2
a1.sources.r1.interceptors.i1.type = host
a1.sources.r1.interceptors.i1.hostHeader = hostname
a1.sources.r1.interceptors.i2.type = com.djt.flume.iterceptor.SetDayIterceptor$SetDayIterceptorBuilder

a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /home/hadoop/data/flume/checkpoint
a1.channels.c1.dataDirs = /home/hadoop/data/flume/dataDir
a1.channels.c1.maxFileSize = 104857600
a1.channels.c1.capacity = 9000000
a1.channels.c1.keep-alive = 60

a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = /flume/events/%{year}-%{month}-%{day}
a1.sinks.k1.hdfs.filePrefix = %{hostname}
a1.sinks.k1.hdfs.inUseSuffix = .tmp
a1.sinks.k1.hdfs.writeFormat = Text
#128M 滚动一个文件
a1.sinks.k1.hdfs.rollSize = 67108864
#a1.sinks.k1.hdfs.rollSize = 0
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.rollInterval = 0
#a1.sinks.k1.hdfs.round = true
#a1.sinks.k1.hdfs.roundUnit = minute
#a1.sinks.k1.hdfs.roundValue = 5
a1.sinks.k1.hdfs.idleTimeout = 900
a1.sinks.k1.hdfs.batchSize = 10000
a1.sinks.k1.hdfs.fileType = SequenceFile

#a1.sinks.k1.type = logger
#a1.sinks.k1.channel = c1