a1.sources = r1
a1.channels = ch1
a1.sinks = k1

a1.sources.r1.channels = ch1
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/hadoop/1

#a1.sources.r1.type = spooldir
#a1.sources.r1.spoolDir = /home/hadoop/flume/nginxlog
a1.sources.r1.ignorePattern = #event(_\d{4}\-\d{2}\-\d{2}_\d{2}_\d{2})?\.log(\.COMPLETED)?
#a1.sources.r1.deserializer.maxLineLength = 10240

a1.sources.r1.fileHeader = true
a1.sources.r1.basenameHeader = true
a1.sources.r1.basenameHeaderKey = basename

a1.sources.r1.interceptors = addBizType
a1.sources.r1.interceptors.addBizType.type = static
a1.sources.r1.interceptors.addBizType.key = bizType
a1.sources.r1.interceptors.addBizType.value = s0
a1.sources.r1.interceptors.addBizType.preserveExisting = true

a1.channels.ch1.type = file
a1.channels.ch1.checkpointDir = /home/hadoop/data/flume/is-checkpoint
a1.channels.ch1.dataDirs = /home/hadoop/data/flume/is-dataDir



a1.sinks.k1.type = logger
a1.sinks.k1.channel = ch1
