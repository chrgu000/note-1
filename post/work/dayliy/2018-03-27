

docker run --name mysql-5.7 \
  -v /root/tmp/mysql-conf:/etc/mysql/conf.d \
  -e MYSQL_USER=develop \
  -e MYSQL_PASSWORD=develop1234! \
  -e MYSQL_DATABASE=volte \
  -e MYSQL_ROOT_PASSWORD=123456 \
  -p 3308:3308 \
  -d mysql:5.7.20


GRANT ALL PRIVILEGES ON *.* TO 'develop'@'%' IDENTIFIED BY 'develop1234!' WITH GRANT OPTION;
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;
FLUSH PRIVILEGES;

mysql -h172.17.0.2 -P3308 -uroot -p

mysql -h172.17.0.2 -P3308 -udevelop -p
mysql -h192.168.168.105 -P3308 -udevelop -p

mysql> source /root/tmp/mysql-ddl/mysql-sv.sql;


curl http://192.168.168.105:8899/c/c/Toolbox/datasource.properties

http://localhost:8080/c/c?s=1&r=Toolbox-YUNNAN/datasource.properties
curl http://192.168.168.105:8899/c/c?s=1&r=Toolbox/datasource.properties
curl http://localhost:8890/c/c?s=1&r=Toolbox/datasource.properties

mysql1.source-type=MYSQL-NORMAL
mysql1.type=MYSQL-NORMAL
mysql1.title=CMDI MySQL
mysql1.arg.host=10.254.201.233
mysql1.arg.port=3306
mysql1.arg.database=volte
mysql1.arg.username=develop
mysql1.arg.password=develop1234!
mysql1.arg.data_dir=/opt/do/Toolbox/data
mysql1.arg.charset=utf-8




ALTER TABLE "public"."tbx_report_plan" ADD COLUMN "message_topic" varchar(64);
ALTER TABLE "public"."tbx_report_plan" ADD COLUMN "send_trigger" varchar(64);



volte_sv:SUCCESS



- F_VOLTE_SIP_SV_H_SUMMARY
- F_VOLTE_SIP_SV_ALL_H_SUMMARY
- F_VOLTE_SIP_SV_TERMINAL_H_SUMMARY
- F_VOLTE_SIP_SV_CITY_AREA_VD_H_SUMMARY
- F_VOLTE_SIP_SV_CITY_VD_H_SUMMARY
- F_VOLTE_SIP_SV_CITY_AREA_H_SUMMARY
- F_VOLTE_SIP_SV_CITY_H_SUMMARY
- F_VOLTE_SIP_SV_PROV_AREA_VD_H_SUMMARY
- F_VOLTE_SIP_SV_PROV_VD_H_SUMMARY
- F_VOLTE_SIP_SV_PROV_AREA_H_SUMMARY
- F_VOLTE_SIP_SV_PROV_H_SUMMARY
- F_VOLTE_SIP_SV_NAT_AREA_VD_H_SUMMARY
- F_VOLTE_SIP_SV_NAT_VD_H_SUMMARY
- F_VOLTE_SIP_SV_NAT_AREA_H_SUMMARY
- F_VOLTE_SIP_SV_NAT_H_SUMMARY



select
  T.ID id, T.PROGRAM_ID programId, T.USER_ID userId, T.PLAN_TYPE planType,
  T.DATA_START dataStart, T.DATA_END dataEnd, T.EXECUTE_START executeStart,
  T.EXECUTE_END executeEnd, T.REPEATE_TYPE repeateType,T.SEND_TRIGGER sendTrigger,T.MESSAGE_TOPIC messageTopic
from TBX_REPORT_PLAN T
where id = 1501;

datasources=spark1,oracle,hdfs,hive

hdfs.source-type=HDFS-NORMAL
hdfs.type=HDFS
hdfs.title=HDFS for CMDI
hdfs.arg.location=hdfs://bjmcc-hdp-cluster-node-06.do:8020/output

hive.source-type=HIVE-NORMAL
hive.type=HIVE
hive.title=Hive for CMDI
hive.arg.database=result
hive.arg.location=/output/result




问题：
  1. Main方法中，每个result会请求一次callback



EXTRA_OPTION=" -Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"




<!--union
select distinct phour as sdate,province,scity,ci
  from ${F_V_BXDR_DROP_PROV_CITY_CI_D}
union
select distinct phour as sdate,province,scity,ci
  from ${F_V_BXDR_SRVCC_PROV_CITY_CI_D}
union
select distinct phour as sdate,province,scity,ci
  from ${F_VOLTE_SIP_MW_CI_D}
union
select distinct phour as sdate,province,scity,ci
  from ${F_V_BXDR_VTV_CI_D}-->


0,1,5,6,16,17,13,14,15,20,21,2,3,4,18,19,7,8,9,10,11,12,22,23,14,15,20,21,2,3,4,18







3 4 7 12

MessageDriver


curl http://n06:8899/tbox/callback?token=volte_widetable&result=VD_NAT_VDNET_D&window=20171222000000-20171222000000&table=VD_NAT_VDNET_D&id=6781


{
  event: "volte_sv_day",
  executed:
}


docker exec --user postgres -it postgresql-9.4 psql

docker run --name postgresql-9.4 \
  -v /data/postgresql9.4_db:/var/lib/postgresql/data \
  -e POSTGRES_PASSWORD=password \
  -p 5432:5432 \
  -d postgres:9.4.15



docker run --name mysql-5.7 \
  -v /root/tmp/cnf:/etc/mysql/conf.d \
  -e MYSQL_USER=develop \
  -e MYSQL_PASSWORD=develop1234! \
  -e MYSQL_DATABASE=volte \
  -e MYSQL_ROOT_PASSWORD=123456 \
  -p 3308:3308 \
  -d mysql:5.7.20







  2018-04-03 18:24:48.638:FINE:framework:SystemShellUtil:Execute [/usr/bin/spark-submit  --master yarn --deploy-mode client --driver-memory 12G --driver-cores 5 --executor-memory 8G --executor-cores 5 --num-executors 10 --conf spark.sql.shuffle.partitions=20 --class com.nsn.datamining.spark.launcher.Main  --conf spark.ui.port=7785 --jars lib/commons-codec-1.9.jar,lib/commons-lang3-3.1.jar,lib/commons-logging-1.2.jar,lib/fluent-hc-4.4.1.jar,lib/httpclient-4.4.1.jar,lib/httpcore-4.4.1.jar,lib/commons-io-2.4.jar,lib/quartz-2.2.3.jar,lib/slf4j-api-1.7.25.jar,lib/slf4j-jdk14-1.7.25.jar,lib/commons-codec.jar,lib/commons-net-3.4.jar,lib/commons-pool-1.3.jar,lib/jsch-0.1.52.jar,lib/commons-io-2.1.jar,lib/commons-pool2-2.4.2.jar,lib/guava-18.0.jar,lib/log4j-1.2.16.jar,lib/mina-core-2.0.13.jar,lib/mina-filter-compression-2.0.13.jar,lib/netty-all-5.0.0.jar,lib/slf4j-api-1.6.1.jar,lib/slf4j-log4j12-1.6.1.jar,lib/zookeeper-3.4.6.jar,lib/commons-codec.jar,lib/commons-compress-1.13.jar,lib/commons-dbcp-1.2.2.jar,lib/commons-dbcp2-2.1.1.jar,lib/commons-lang3-3.1.jar,lib/commons-logging.jar,lib/commons-net-3.1.jar,lib/commons-pool-1.3.jar,lib/commons-pool2-2.4.2.jar,lib/ibatis-2.3.4.726.jar,lib/ojdbc6.jar,lib/spring-2.5.6.jar,lib/commons-math3-3.4.1.jar,lib/ojdbc6.jar,lib/poi-3.11-20141221.jar,lib/poi-ooxml-3.11-20141221.jar,lib/poi-ooxml-schemas-3.11-20141221.jar,lib/postgresql-9.4.1211.jar,lib/weka.jar,lib/xmlbeans-2.6.0.jar,lib/commons-collections-3.2.2.jar,lib/commons-io-2.1.jar,lib/hadoop-hdfs-2.7.3.jar,lib/org.apache.felix.main-5.6.2.jar,lib/activemq-all-5.9.0.jar,plugins/com.nsn.configurator.jar,plugins/com.nsn.logger.jar,plugins/com.nsn.util.jar,plugins/com.nsn.io.jar,plugins/com.nsn.executer.jar,plugins/com.nsn.task.jar,plugins/com.nsn.merger.jar,plugins/com.nsn.alarm.jar,plugins/com.nsn.scheduler.jar,plugins/com.nsn.scanner.jar,plugins/com.nsn.cluster.jar,plugins/com.nsn.framework.jar,plugins/com.nsn.datamining.jar,plugins/com.nsn.datamining.spark.jar,plugins/com.nsn.datamining.support.xdr.cmcc.jar,plugins/com.nsn.datamining.support.xdr.cmcc.cmdi.jar,plugins/com.nsn.messages.client.jar,plugins/com.nsn.messages.driver.jar,plugins/com.nsn.do.tbox.cmcc.spark.volte.jar main.jar  hive.title="" spark1.arg.hiveSetting="mapred.input.dir.recursive=true" datamining.callback="http://n06:8899/tbox/callback" arg.location="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" spark1.arg.hdfs="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" hdfs.type="HDFS" spark1.source-type="XDR-CMCC-SPARK" arg.report.date="20171222" arg.spark.options="--master yarn --deploy-mode client --driver-memory 12G --driver-cores 5 --executor-memory 8G --executor-cores 5 --num-executors 10 --conf spark.sql.shuffle.partitions=20" spark1.arg.home="/opt/do/spark-2.2.0" hdfs.source-type="HDFS-NORMAL" arg.spark1="spark1" hive.type="HIVE" report.program="volte_sv" arg.report-id="6761" spark1.type="XDR-CMCC-SPARK" arg.hive="hive" hive.arg.location="/output/result" spark1.arg.hivedb="result" spark1.arg.staging="hdfs://vm73:8020/user/hdfs/.sparkStaging/" hive.source-type="HIVE-NORMAL" arg.home="/opt/do/spark-2.2.0" arg.staging="hdfs://vm73:8020/user/hdfs/.sparkStaging/" arg.hiveSetting="mapred.input.dir.recursive=true" arg.report.hour="00" spark1.arg.configuration="/opt/do/spark-2.2.0/conf1" report.end="20171223000000" report.start="20171222000000" arg.short-id="TBX_100_0" datasources="hive,spark1,hdfs" spark1.title="" arg.name="Toolbox-nokia" arg.hdfs="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" hdfs.arg.location="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" arg.configuration="/opt/do/spark-2.2.0/conf1" report.id="6761" hdfs.title="" arg.database="result" hive.arg.database="result" arg.hivedb="result" spark1.arg.name="Toolbox-nokia" arg.planId="1762"] SUCCESS.





  SystemShellUtil:Execute [/usr/bin/spark-submit  --master yarn --deploy-mode client --driver-memory 12G --driver-cores 5 --executor-memory 8G --executor-cores 5 --num-executors 10 --conf spark.sql.shuffle.partitions=20 --class com.nsn.datamining.spark.launcher.Main  --conf spark.ui.port=7785 --jars lib/commons-codec-1.9.jar,lib/commons-lang3-3.1.jar,lib/commons-logging-1.2.jar,lib/fluent-hc-4.4.1.jar,lib/httpclient-4.4.1.jar,lib/httpcore-4.4.1.jar,lib/commons-io-2.4.jar,lib/quartz-2.2.3.jar,lib/slf4j-api-1.7.25.jar,lib/slf4j-jdk14-1.7.25.jar,lib/commons-codec.jar,lib/commons-net-3.4.jar,lib/commons-pool-1.3.jar,lib/jsch-0.1.52.jar,lib/commons-io-2.1.jar,lib/commons-pool2-2.4.2.jar,lib/guava-18.0.jar,lib/log4j-1.2.16.jar,lib/mina-core-2.0.13.jar,lib/mina-filter-compression-2.0.13.jar,lib/netty-all-5.0.0.jar,lib/slf4j-api-1.6.1.jar,lib/slf4j-log4j12-1.6.1.jar,lib/zookeeper-3.4.6.jar,lib/commons-codec.jar,lib/commons-compress-1.13.jar,lib/commons-dbcp-1.2.2.jar,lib/commons-dbcp2-2.1.1.jar,lib/commons-lang3-3.1.jar,lib/commons-logging.jar,lib/commons-net-3.1.jar,lib/commons-pool-1.3.jar,lib/commons-pool2-2.4.2.jar,lib/ibatis-2.3.4.726.jar,lib/ojdbc6.jar,lib/spring-2.5.6.jar,lib/commons-math3-3.4.1.jar,lib/ojdbc6.jar,lib/poi-3.11-20141221.jar,lib/poi-ooxml-3.11-20141221.jar,lib/poi-ooxml-schemas-3.11-20141221.jar,lib/postgresql-9.4.1211.jar,lib/weka.jar,lib/xmlbeans-2.6.0.jar,lib/commons-collections-3.2.2.jar,lib/commons-io-2.1.jar,lib/hadoop-hdfs-2.7.3.jar,lib/org.apache.felix.main-5.6.2.jar,lib/activemq-all-5.9.0.jar,plugins/com.nsn.configurator.jar,plugins/com.nsn.logger.jar,plugins/com.nsn.util.jar,plugins/com.nsn.io.jar,plugins/com.nsn.executer.jar,plugins/com.nsn.task.jar,plugins/com.nsn.merger.jar,plugins/com.nsn.alarm.jar,plugins/com.nsn.scheduler.jar,plugins/com.nsn.scanner.jar,plugins/com.nsn.cluster.jar,plugins/com.nsn.framework.jar,plugins/com.nsn.datamining.jar,plugins/com.nsn.datamining.spark.jar,plugins/com.nsn.datamining.support.xdr.cmcc.jar,plugins/com.nsn.datamining.support.xdr.cmcc.cmdi.jar,plugins/com.nsn.messages.client.jar,plugins/com.nsn.messages.driver.jar,plugins/com.nsn.do.tbox.cmcc.spark.volte.jar main.jar  hive.title="" spark1.arg.hiveSetting="mapred.input.dir.recursive=true" datamining.callback="http://n06:8899/tbox/callback" arg.location="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" spark1.arg.hdfs="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" hdfs.type="HDFS" spark1.source-type="XDR-CMCC-SPARK" arg.report.date="20171222" arg.spark.options="--master yarn --deploy-mode client --driver-memory 12G --driver-cores 5 --executor-memory 8G --executor-cores 5 --num-executors 10 --conf spark.sql.shuffle.partitions=20" spark1.arg.home="/opt/do/spark-2.2.0" hdfs.source-type="HDFS-NORMAL" arg.spark1="spark1" hive.type="HIVE" report.program="volte_sv" arg.report-id="6761" spark1.type="XDR-CMCC-SPARK" arg.hive="hive" hive.arg.location="/output/result" spark1.arg.hivedb="result" spark1.arg.staging="hdfs://vm73:8020/user/hdfs/.sparkStaging/" hive.source-type="HIVE-NORMAL" arg.home="/opt/do/spark-2.2.0" arg.staging="hdfs://vm73:8020/user/hdfs/.sparkStaging/" arg.hiveSetting="mapred.input.dir.recursive=true" arg.report.hour="00" spark1.arg.configuration="/opt/do/spark-2.2.0/conf1" report.end="20171223000000" report.start="20171222000000" arg.short-id="TBX_100_0" datasources="hive,spark1,hdfs" spark1.title="" arg.name="Toolbox-nokia" arg.hdfs="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" hdfs.arg.location="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" arg.configuration="/opt/do/spark-2.2.0/conf1" report.id="6761" hdfs.title="" arg.database="result" hive.arg.database="result" arg.hivedb="result" spark1.arg.name="Toolbox-nokia" arg.planId="1762"] BEGIN......







  2018-04-03 18:25:49.699:FINE:framework:SystemShellUtil:Execute [/usr/bin/spark-submit  --master yarn --deploy-mode client --driver-memory 12G --driver-cores 5 --executor-memory 8G --executor-cores 5 --num-executors 20 --conf spark.sql.shuffle.partitions=20 --class com.nsn.datamining.spark.launcher.Main  --conf spark.ui.port=7786 --jars lib/commons-codec-1.9.jar,lib/commons-lang3-3.1.jar,lib/commons-logging-1.2.jar,lib/fluent-hc-4.4.1.jar,lib/httpclient-4.4.1.jar,lib/httpcore-4.4.1.jar,lib/commons-io-2.4.jar,lib/quartz-2.2.3.jar,lib/slf4j-api-1.7.25.jar,lib/slf4j-jdk14-1.7.25.jar,lib/commons-codec.jar,lib/commons-net-3.4.jar,lib/commons-pool-1.3.jar,lib/jsch-0.1.52.jar,lib/commons-io-2.1.jar,lib/commons-pool2-2.4.2.jar,lib/guava-18.0.jar,lib/log4j-1.2.16.jar,lib/mina-core-2.0.13.jar,lib/mina-filter-compression-2.0.13.jar,lib/netty-all-5.0.0.jar,lib/slf4j-api-1.6.1.jar,lib/slf4j-log4j12-1.6.1.jar,lib/zookeeper-3.4.6.jar,lib/commons-codec.jar,lib/commons-compress-1.13.jar,lib/commons-dbcp-1.2.2.jar,lib/commons-dbcp2-2.1.1.jar,lib/commons-lang3-3.1.jar,lib/commons-logging.jar,lib/commons-net-3.1.jar,lib/commons-pool-1.3.jar,lib/commons-pool2-2.4.2.jar,lib/ibatis-2.3.4.726.jar,lib/ojdbc6.jar,lib/spring-2.5.6.jar,lib/commons-math3-3.4.1.jar,lib/ojdbc6.jar,lib/poi-3.11-20141221.jar,lib/poi-ooxml-3.11-20141221.jar,lib/poi-ooxml-schemas-3.11-20141221.jar,lib/postgresql-9.4.1211.jar,lib/weka.jar,lib/xmlbeans-2.6.0.jar,lib/commons-collections-3.2.2.jar,lib/commons-io-2.1.jar,lib/hadoop-hdfs-2.7.3.jar,lib/org.apache.felix.main-5.6.2.jar,plugins/com.nsn.configurator.jar,plugins/com.nsn.logger.jar,plugins/com.nsn.util.jar,plugins/com.nsn.io.jar,plugins/com.nsn.executer.jar,plugins/com.nsn.task.jar,plugins/com.nsn.merger.jar,plugins/com.nsn.alarm.jar,plugins/com.nsn.scheduler.jar,plugins/com.nsn.scanner.jar,plugins/com.nsn.cluster.jar,plugins/com.nsn.framework.jar,plugins/com.nsn.datamining.jar,plugins/com.nsn.datamining.spark.jar,plugins/com.nsn.datamining.support.xdr.cmcc.jar,plugins/com.nsn.datamining.support.xdr.cmcc.cmdi.jar,plugins/com.nsn.do.tbox.cmcc.spark.volte.day.jar main.jar  hive.title="" spark1.arg.hiveSetting="mapred.input.dir.recursive=true" datamining.callback="http://n06:8899/tbox/callback" arg.location="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" spark1.arg.hdfs="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" hdfs.type="HDFS" spark1.source-type="XDR-CMCC-SPARK" arg.report.date="20171222" arg.spark.options="--master yarn --deploy-mode client --driver-memory 12G --driver-cores 5 --executor-memory 8G --executor-cores 5 --num-executors 20 --conf spark.sql.shuffle.partitions=20" spark1.arg.home="/opt/do/spark-2.2.0" hdfs.source-type="HDFS-NORMAL" arg.spark1="spark1" hive.type="HIVE" report.program="volte_sv_day" arg.report-id="6762" spark1.type="XDR-CMCC-SPARK" arg.hive="hive" hive.arg.location="/output/result" spark1.arg.hivedb="result" spark1.arg.staging="hdfs://vm73:8020/user/hdfs/.sparkStaging/" hive.source-type="HIVE-NORMAL" arg.home="/opt/do/spark-2.2.0" arg.staging="hdfs://vm73:8020/user/hdfs/.sparkStaging/" arg.hiveSetting="mapred.input.dir.recursive=true" arg.report.hour="00" spark1.arg.configuration="/opt/do/spark-2.2.0/conf1" report.end="20171222000000" report.start="20171222000000" arg.short-id="TBX_100_0" datasources="hive,spark1,hdfs" spark1.title="" arg.name="Toolbox-nokia" arg.hdfs="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" hdfs.arg.location="hdfs://bjmcc-hdp-cluster-node-06.do:8020/output/" arg.configuration="/opt/do/spark-2.2.0/conf1" report.id="6762" hdfs.title="" arg.database="result" hive.arg.database="result" arg.hivedb="result" spark1.arg.name="Toolbox-nokia" arg.planId="1761"] BEGIN......