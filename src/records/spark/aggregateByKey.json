{
  "duration": 106.144794,
  "version": 1,
  "command": "bash",
  "height": 22,
  "stdout": [
    [
      0.141762,
      "\r\nscala> "
    ],
    [
      0.963912,
      "val pairRDD"
    ],
    [
      0.008499,
      " = sc.parallelize(List( (\"cat\",2), (\"cat\", 5), (\"mouse\", 4),(\"cat\", 12), (\" \rdog\", "
    ],
    [
      0.002884,
      "12),"
    ],
    [
      0.005193,
      " (\"mouse\", 2)), 2)"
    ],
    [
      0.974534,
      "\r\n"
    ],
    [
      0.767311,
      "pairRDD: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[0] at parallelize at <console>:21\r\n\r\nscala> "
    ],
    [
      0.266094,
      "de"
    ],
    [
      0.002531,
      "f func2"
    ],
    [
      0.007642,
      "(ind"
    ],
    [
      0.005414,
      "ex: Int, iter: Iterator[(Strin"
    ],
    [
      0.006242,
      "g, Int)]) : Iterator[String] = {\r\n"
    ],
    [
      0.010078,
      "     |   i"
    ],
    [
      0.002982,
      "ter.toList."
    ],
    [
      0.000405,
      "ma"
    ],
    [
      0.00466,
      "p(x => \"[partID:\""
    ],
    [
      0.000445,
      " +  in"
    ],
    [
      0.000937,
      "dex + \""
    ],
    [
      0.000516,
      ", val:"
    ],
    [
      0.00137,
      " \""
    ],
    [
      0.000648,
      " +"
    ],
    [
      0.001758,
      " x "
    ],
    [
      0.000141,
      "+ \"]\")."
    ],
    [
      0.00217,
      "iterato"
    ],
    [
      0.009616,
      "r\r\n"
    ],
    [
      0.001018,
      "     | "
    ],
    [
      0.001733,
      "}"
    ],
    [
      0.89192,
      "\r\n"
    ],
    [
      0.667231,
      "func2: (index: Int, iter: Iterator[(String, Int)])Iterator[String]\r\n\r\nscala> "
    ],
    [
      6.861148,
      "pairRDD.mapPar"
    ],
    [
      0.005022,
      "titionsWithIndex(func2).collect"
    ],
    [
      0.921252,
      "\r\n"
    ],
    [
      0.925914,
      "\r[Stage 0:>                                                          (0 + 0) / 2]"
    ],
    [
      0.590739,
      "\r[Stage 0:>                                                          (0 + 1) / 2]"
    ],
    [
      0.716585,
      "\r                                                                                \r"
    ],
    [
      0.015133,
      "res0: Array[String] = Array([partID:0, val: (cat,2)], [partID:0, val: (cat,5)], [partID:0, val: (mouse,4)], [partID:1, val: (cat,12)], [partID:1, val: (dog,12)], [partID:1, val: (mouse,2)])"
    ],
    [
      0.007359,
      "\r\n\r\nscala> "
    ],
    [
      11.097842,
      "pairR"
    ],
    [
      0.001167,
      "DD."
    ],
    [
      0.004632,
      "aggregateByKey"
    ],
    [
      0.002486,
      "(0)(math"
    ],
    [
      0.00094,
      ".max(_, _), _ + _).col"
    ],
    [
      0.0151,
      "lect"
    ],
    [
      1.338937,
      "\r\n"
    ],
    [
      1.373549,
      "res1: Array[(String, Int)] = Array((dog,12), (cat,17), (mouse,6))\r\n\r\nscala> "
    ],
    [
      5.991891,
      "pairRDD.aggregateByKey(100)(math.max(_, _), _ + _).collect"
    ],
    [
      1.066364,
      "\r\n"
    ],
    [
      0.910567,
      "res2: Array[(String, Int)] = Array((dog,100), (cat,200), (mouse,200))\r\n\r\nscala> "
    ],
    [
      7.745956,
      "Stopping spark context.\r\n"
    ],
    [
      0.462539,
      "root@master:/usr/local/spark-1.5.2# "
    ],
    [
      0.260718,
      "exit\r\n"
    ],
    [
      0.018542,
      "\u001b]0;root@localhost:~\u0007[root@localhost ~]# "
    ],
    [
      0.633576,
      "logout\r\nConnection to 196.168.1.34 closed.\r\r\n"
    ],
    [
      0.000321,
      "\u001b]0;@d2d9acf07561:/\u0007[root@d2d9acf07561 /]# "
    ]
  ],
  "title": null,
  "width": 93,
  "env": {
    "SHELL": null,
    "TERM": "xterm"
  }
}